<!-- build time:Wed Jul 23 2025 00:53:31 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" href="http://amentiraz.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" href="http://amentiraz.github.io/atom.xml"><link rel="alternate" type="application/json" href="http://amentiraz.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="生物,学习笔记类,算法"><link rel="canonical" href="http://amentiraz.github.io/article/STAGATE/"><title>STAGATE - 论文 | Amentiraz =</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">STAGATE</h1><div class="meta"><span class="item" title="创建时间：2024-11-21 09:49:02"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2024-11-21T09:49:02+08:00">2024-11-21</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>25k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>23 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Amentiraz</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925162829.png"></li><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925162923.png"></li><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925124604.jpg"></li><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925124438.jpg"></li><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925162917.png"></li><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925162904.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/article/" itemprop="item" rel="index" title="分类于 论文"><span itemprop="name">论文</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://amentiraz.github.io/article/STAGATE/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Lemon Sour"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content=""></span><div class="body md" itemprop="articleBody"><p>STAGATE: Deciphering spatial domains from spatially resolved transcriptomics with an adaptive graph attention auto-encoder</p><p>主要利用了 Graph Attention Network 里面的方法，创建 3D SNN 时假设不同切片同一位置具有连续性减轻了批次效应。</p><span id="more"></span><h1 id="摘要"><a class="anchor" href="#摘要">#</a> 摘要</h1><p>STAGATE: a graph attention auto-encoder framework accurately identify spatial domains by learning low-dimensional latent embeddings via integrating spatial information and gene expression profiles.</p><p>STAGATE adopts an attention mechanism to adaptively learn the similarity of neighboring spots, and an optional cell type-aware module through ingrating the pre-clustering of gene expressions.</p><p>We validate STAGATE on diverse spatial transcriptomics datasets generated by different platforms with different spatial resolution</p><p>STAGATE could substantially improve the identification accuracy of spatial domains, and denoise the data while preserving spatial expression patterns.</p><p>STAGATE could be extended to multiple consecutive sections to reduce batch effects between sections and extracting three-dimensional(3D) expression domains from the reconstructed 3D tissue effectively.</p><h1 id="introduction"><a class="anchor" href="#introduction">#</a> introduction</h1><p>non-spatial clustering methods:<br>1.k-means and Louvain algorithm.<br>- limited to the small number of spotis or the sparsity according to the different resolutions of ST technologies, and clustering results may be discontinuous in the tissue section<br>2. utilizes the cell type signatures defined by single-cell RNA-seq to deconvolute the spots.<br>- They are not applicable to ST data at a resolution of cellular or subcellular levels.<br>- 例如，某些 ST 技术能够以更高的分辨率直接捕获单个细胞甚至亚细胞层面的基因表达信息。在这种情况下，解卷积的方法可能不适用或没有意义，因为数据本身已经具有高分辨率，能够直接提供细胞级别的信息。</p><p>介绍了几个现有的方法：</p><ul><li>BayesSpace is a Bayesian statistical method that encourages neighboring spots to belong to the same cluster by introducing spatial neighbor structure into the prior/</li><li>Giotto identifies spatial domains by implementing a hidden Markov random field(HMRF) model with the spatial neighbor prior.</li><li>stLearn defines the morphological distance based on features extracted from a histology image and utilizes such distances as well as spatial neibor structure to smooth gene expressions.</li><li>SEDR employs a deep auto-encoder network for learning gene respresentations and uses a variational graph auto-encoder to simultaneously embed spatial information.</li><li>SpaGCN also applies the graph convolutional network to integrate gene expression and spatial location, and further coupled with a self supervised module to identify domains.</li><li>RESEPT leverages the supervised image segmentation method to perform tissue structure identification.</li></ul><p>STAGATE 全称：Spatially resolved Transcriptomics with an Adaptive Graph ATtention auto-Encoder</p><h1 id="results"><a class="anchor" href="#results">#</a> Results</h1><h2 id="overview-of-stagate"><a class="anchor" href="#overview-of-stagate">#</a> Overview of STAGATE</h2><p><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE1.png" alt=""><br>图上面的流程解释的比文字清楚</p><p>STAGATE with the cell type-aware module could better learn the spatial similarity.</p><p>利用 UMAP 来可视化，利用聚类算法如：mclust 和 Louvain</p><h2 id="stagate-improves-the-identification-of-known-layers-on-the-human-dorsolateral-prefrontal-cortex"><a class="anchor" href="#stagate-improves-the-identification-of-known-layers-on-the-human-dorsolateral-prefrontal-cortex">#</a> STAGATE improves the identification of known layers on the human dorsolateral prefrontal cortex</h2><p><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE3.png" alt=""></p><p><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE2.png" alt=""><br>进一步测试了 STAGATE 的鲁棒性，通过利用不同的 hyper-parameters 对比聚类的准确性，发现这个模型对 encoder structure 和 latent dimension 很敏感</p><p><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE4.png" alt=""></p><p>depict the spatial trajectory</p><h2 id="stagate-enables-the-identification-of-tissue-structures-from-st-data-of-different-spatial-resolutions"><a class="anchor" href="#stagate-enables-the-identification-of-tissue-structures-from-st-data-of-different-spatial-resolutions">#</a> STAGATE enables the identification of tissue structures from ST data of different spatial resolutions.</h2><p><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE6.png" alt=""><br>STAGATE can well characterize the tissue structures and uncover the spatial domains, while the clusters identified by SCANPY and SEDR lack clear spatial separation.<br><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE5.png" alt=""></p><p>the expressions of many known gene markers also verified the cluster partition of STAGATE.</p><p>These results demonstrated that STAGATE can dissect spatial heterogeneity and further uncover spatial expression patterns.</p><p>STAGATE depicted the known tissue structures wll except CA2sp on the Slide-seq data(e) and 10x Visium data(f) respectively.</p><p>The performance of STAGATE for identifying tissue structures on the mouse olfactory bulb:<br><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE7.png" alt=""><br>STAGATE recognized the narrow tissue structure MCL clearly, which was validated by the expression of mitral cell marker GABRA1.<br>Fig b dataset is generated by Stereo-seq<br>Fig d dataset is generated by Slide-seqV2<br><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE8.png" alt=""><br>特别的是 STAGATE 检测出了两种先前并未检测出来的空间域：AOB 和 AOBgr<br>作为佐证，Atp2b4 和 Fxyd6 展现了很强的表达能力。</p><p><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE9.png" alt=""></p><p>STAGATE delineated the spatial trajectory among the mouse plots as well as the PAGA graphs.</p><p>Collectively, these results illustrated the ability of STAGATE to identify tissue structures and reveal their organization from ST data of different spatial resolutions.</p><h2 id="attention-mechanism-and-cell-type-aware-module-help-to-better-charaterize-the-similarity-between-neighboring-spots"><a class="anchor" href="#attention-mechanism-and-cell-type-aware-module-help-to-better-charaterize-the-similarity-between-neighboring-spots">#</a> Attention mechanism and cell type-aware module help to better charaterize the similarity between neighboring spots.</h2><p><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE10.png" alt=""></p><p>Specifically, in the hippocampal region, STAGATE without the cell type-aware module identified the field CA1(domain7) and CA3(domain8) of Ammon's horn, but did not depict the dentate gyrus structure.</p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\alpha=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.0037em">α</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\alpha=0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.0037em">α</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span></span></span></span> 说明了 STAGATE 是否使用了 cell type-aware module.</p><p>在 c 图中也能发现，使用了 cell type-aware 模块的 STAGATE 对于 UMAP plot 的操作，更进一步分割了组织结构</p><p><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE11.png" alt=""></p><p>Combining the attention mechanism and the cell type-aware module enhanced the delineation of structure boundaries, and further revealed the spatial similarity within small spatial domains.</p><p>Collectively, these results indicated the importance of the attention mechanism and the cell type-aware module for defpicting the similarity between neighboring spots.</p><h2 id="stagate-denoises-gene-expressions-for-better-characterizing-spatial-expression-patterns"><a class="anchor" href="#stagate-denoises-gene-expressions-for-better-characterizing-spatial-expression-patterns">#</a> STAGATE denoises gene expressions for better characterizing spatial expression patterns.</h2><p>STAGATE could denoise and impute gene expressiong.</p><p><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE12.png" alt=""><br>the denoised ones by STAGATE exhibited the laminar enrichment of these layer-marker genes clearly. For example, after denoising, the ATP2B4 gene showed differential expressions in layer 2 and 6, which is consistent with previously reported results, while its raw spatial expression is completely messy.</p><p>b 图表示了这些基因通过 in situ hybridization 的方法得到的图像，其实也就是通过染色判断这些基因的位置。</p><p><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE13.png" alt=""></p><p><strong>Violin plots</strong> 是一种数据可视化工具，结合了 <strong>箱线图（box plot）</strong> 和 <strong>核密度估计图（kernel density plot）</strong> 的优点，用来展示数据的分布特性和统计信息。它们通常用于比较多个组的分布情况。</p><hr><h3 id="violin-plot-的结构"><a class="anchor" href="#violin-plot-的结构">#</a> <strong>Violin Plot 的结构</strong></h3><ol><li><p><strong>核密度图（Density Plot）</strong>：</p><ul><li>Violin plot 的主要部分是左右对称的密度曲线，表示数据分布的概率密度。</li><li>宽度反映了该值区域的数据密度 —— 越宽表示数据点越集中，越窄表示数据稀疏。</li></ul></li><li><p><strong>中轴和统计信息</strong>：</p><ul><li>Violin plot 的中间可能有类似箱线图的组件：<ul><li><strong>中位数</strong>：通常用一条线标出。</li><li><strong>四分位范围（IQR）</strong>：即数据的 25% 和 75% 分位点，可能用矩形或线段表示。</li><li><strong>异常值</strong>：可能用点表示（视具体绘图工具而定）。</li></ul></li></ul></li><li><p><strong>对称性</strong>：</p><ul><li>Violin plot 通常是左右对称的，但在某些特殊情况下，也可以单边绘制。</li></ul></li></ol><hr><h3 id="violin-plot-的用途"><a class="anchor" href="#violin-plot-的用途">#</a> <strong>Violin Plot 的用途</strong></h3><ul><li><strong>分布比较</strong>：适用于多个组数据的分布比较，比箱线图更清晰地显示数据的形状（如是否偏态、双峰分布）。</li><li><strong>异常值检测</strong>：可以观察分布中是否存在异常值或稀疏区域。</li><li><strong>多组数据对比</strong>：适合分析多组数据在同一变量上的差异。</li></ul><hr><h3 id="violin-plot-与其他图的区别"><a class="anchor" href="#violin-plot-与其他图的区别">#</a> <strong>Violin Plot 与其他图的区别</strong></h3><table><thead><tr><th>特性</th><th>Violin Plot</th><th>Box Plot</th><th>Histogram / 密度图</th></tr></thead><tbody><tr><td>显示数据分布形状</td><td>是</td><td>部分</td><td>是</td></tr><tr><td>统计信息</td><td>中位数、四分位数等</td><td>中位数、四分位数、异常值</td><td>不包含</td></tr><tr><td>多组数据比较</td><td>是</td><td>是</td><td>较难</td></tr><tr><td>数据密度信息</td><td>明确（通过宽度）</td><td>不包含</td><td>是</td></tr></tbody></table><hr><p>Collectively, these results demonstrated the ability of STAGATE to reduce noises and enhance spatial expression patterns.</p><p><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE14.png" alt=""></p><p>showedits superior in both imputation efficiency and preservation of spatial expression patterns.</p><h2 id="the-usage-of-3d-snn-leads-to-better-extrction-of-3d-sptial-patterns"><a class="anchor" href="#the-usage-of-3d-snn-leads-to-better-extrction-of-3d-sptial-patterns">#</a> The usage of 3D SNN leads to better extrction of 3D sptial patterns</h2><p><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE15.png" alt=""><br>由于数据的稀疏性，SCANPY 的聚类结果是混合的<br><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE16.png" alt=""><br><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE17.png" alt=""><br>由于批次效应，STAGATE 未能成功识别出 CA2sp 区域</p><p>These results illustrated that STAGATE could help to reconstruct 3D tissue models and accurately extract 3D expression patterns by incorporating 3D spatial information.</p><h1 id="discussion"><a class="anchor" href="#discussion">#</a> Discussion</h1><p>说明了一些杂七杂八的问题</p><ol><li>对前文工作的总结</li><li>没有加入 histological image features</li><li>对于 single-cell resolution 数据的检测仍然有优越性</li><li>STAGATE performs better for ST data of cellular or subcellular resolutions due to the high similarity between neighboring spots</li><li>A potential limitation of STAGATE is that it trears neighboring spots from one section the same as those belonging to different sections.</li><li>虽然目前在时间方面仍然有优越性，但是终将陷入瓶颈，未来的目标是通过子图的训练策略提升 STAGATE 的可扩展性</li><li>STAGATE enables the detection of spatially variable genes within spatial domains.</li></ol><h1 id="methods"><a class="anchor" href="#methods">#</a> Methods</h1><h2 id="construction-of-snn"><a class="anchor" href="#construction-of-snn">#</a> Construction of SNN</h2><p>我们预先定义一个半径<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.02778em">r</span></span></span></span><br>Let <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="bold">A</mtext></mrow><annotation encoding="application/x-tex">\textbf{A}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68611em;vertical-align:0"></span><span class="mord text"><span class="mord textbf">A</span></span></span></span></span> be the adjacency matrix of the SNN, then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext mathvariant="bold">A</mtext><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\textbf{A}_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.972218em;vertical-align:-.286108em"></span><span class="mord"><span class="mord text"><span class="mord textbf">A</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span> if and only if the Euclidean distance between spot <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.65952em;vertical-align:0"></span><span class="mord mathnormal">i</span></span></span></span> and spot <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.85396em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span></span></span></span> is less than <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.02778em">r</span></span></span></span><br>对于 10x visium data, 我们直接选择最近的 6 个邻居，对于其它的数据，我们根据经验选择<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.02778em">r</span></span></span></span>，让这个范围内包括 6-15 个邻居。<br><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE18.png" alt=""></p><h2 id="construction-of-cell-type-aware-snnoptional"><a class="anchor" href="#construction-of-cell-type-aware-snnoptional">#</a> Construction of cell type-aware SNN(optional)</h2><p>Specifically, the pre-clustering of gene expressions is conducted by the Louvain algorithm with a small resolution value (set as 0.2 by default) on the PCA embeddings, and STAGATE prunes the edge if the spots of it belong to different clusters.</p><p>do not recommend using it to technologies at a resolution of cellular or subcellular levels.Because in this scenario, the similarity between adjacent sites is relatively homogeneous.<br>而且 technical 本身的噪音也容易被引入。</p><p><em>Encoder:</em></p>\begin{equation} \textbf{h}_i^{(k)} = \sigma(\sum_{j\in{S_i}}\textbf{att}_{ij}^{(k)}(\textbf{W}_k\textbf{h}_j^{(k-1)})). \end{equation}<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><msubsup><mi>h</mi><mi>i</mi><mrow><mo stretchy="false">(</mo><mn>0</mn><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">x_i=h_i^{(0)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.321664em;vertical-align:-.27686399999999994em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4231360000000004em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.2198em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">0</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.27686399999999994em"><span></span></span></span></span></span></span></span></span></span> 其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 是标准化后的 spot <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.65952em;vertical-align:0"></span><span class="mord mathnormal">i</span></span></span></span> 的的表达值（应该是基因表达值），<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal">L</span></span></span></span> 是 encoder 层的数量，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span></span></span></span> 代表第几层。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="bold">W</mtext></mrow><annotation encoding="application/x-tex">\textbf{W}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68611em;vertical-align:0"></span><span class="mord text"><span class="mord textbf">W</span></span></span></span></span> 是可训练的权重矩阵。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="bold">att</mtext></mrow><annotation encoding="application/x-tex">\textbf{att}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.63492em;vertical-align:0"></span><span class="mord text"><span class="mord textbf">att</span></span></span></span></span> is the edge weight between spot <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.65952em;vertical-align:0"></span><span class="mord mathnormal">i</span></span></span></span> and spot <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.85396em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span></span></span></span> in the output of the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span></span></span></span>-th garph attention layer</p><p>第 L 层的 encoder layer：</p>\begin{equation} \textbf{h}_i^{(L)} = \sigma(\textbf{W}_L\textbf{h}_i^{(L-1)}). \end{equation}<p><em>Decoder:</em></p>\begin{equation} \hat{\textbf{h}_i}^{(k)} = \sigma(\sum_{j\in{S_i}}\hat{\textbf{att}_{ij}}^{(k)}(\hat{\textbf{W}_k}\hat{\textbf{h}_j}^{(k-1)})). \end{equation}<p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mover accent="true"><mtext mathvariant="bold">h</mtext><mo>^</mo></mover><mi>i</mi><mrow><mo stretchy="false">(</mo><mi>L</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><msubsup><mtext mathvariant="bold">h</mtext><mi>i</mi><mrow><mo stretchy="false">(</mo><mi>L</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\hat{\textbf{h}}_i^{(L)} = \textbf{h}_i^{(L)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.4827799999999995em;vertical-align:-.247em"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.9578799999999998em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord textbf">h</span></span></span></span><span style="top:-3.26344em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.25em"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2357799999999997em"><span style="top:-2.4530000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.41078em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">L</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.321664em;vertical-align:-.27686399999999994em"></span><span class="mord"><span class="mord text"><span class="mord textbf">h</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.4231360000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.2198em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">L</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.27686399999999994em"><span></span></span></span></span></span></span></span></span></span><br>最后一层 decoder：</p>\begin{equation} \hat{\textbf{h}_i}^{(0)} = \sigma(\hat{\textbf{W}_1}\hat{\textbf{h}_i}^{(1)}). \end{equation}<p>To avoid overfitting, STAGATE sets <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mtext mathvariant="bold">W</mtext><mo>^</mo></mover><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><msup><mtext mathvariant="bold">W</mtext><mrow><mo stretchy="false">(</mo><mi>k</mi><msup><mo stretchy="false">)</mo><mi>T</mi></msup></mrow></msup></mrow><annotation encoding="application/x-tex">\hat{\textbf{W}}^{(k)} = \textbf{W}^{(k)^T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.22745em;vertical-align:0"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.9495499999999999em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord textbf">W</span></span></span></span><span style="top:-3.25511em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.25em"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.22745em"><span style="top:-3.40245em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.082375em;vertical-align:0"></span><span class="mord"><span class="mord text"><span class="mord textbf">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.082375em"><span style="top:-3.13901em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.9190928571428572em"><span style="top:-2.931em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mtext mathvariant="bold">att</mtext><mo>^</mo></mover><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><msup><mtext mathvariant="bold">att</mtext><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\hat{\textbf{att}}^{(k)} = \textbf{att}^{(k)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.17626em;vertical-align:0"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.89836em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord textbf">att</span></span></span></span><span style="top:-3.20392em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.25em"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.17626em"><span style="top:-3.35126em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.91282em;vertical-align:0"></span><span class="mord"><span class="mord text"><span class="mord textbf">att</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.91282em"><span style="top:-3.0878200000000002em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span> respectively.</p><p>att 不是转置其实是因为它本身就是对称的</p><p>在 Graph Attention Auto-Encoder (GATE) 的设计中，对于解码器参数设置 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mtext mathvariant="bold">W</mtext><mo>^</mo></mover><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><msup><mtext mathvariant="bold">W</mtext><mrow><mo stretchy="false">(</mo><mi>k</mi><msup><mo stretchy="false">)</mo><mi>T</mi></msup></mrow></msup></mrow><annotation encoding="application/x-tex">\hat{\textbf{W}}^{(k)} = \textbf{W}^{(k)^T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.22745em;vertical-align:0"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.9495499999999999em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord textbf">W</span></span></span></span><span style="top:-3.25511em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.25em"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.22745em"><span style="top:-3.40245em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.082375em;vertical-align:0"></span><span class="mord"><span class="mord text"><span class="mord textbf">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.082375em"><span style="top:-3.13901em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.9190928571428572em"><span style="top:-2.931em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mtext mathvariant="bold">att</mtext><mo>^</mo></mover><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><msup><mtext mathvariant="bold">att</mtext><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\hat{\textbf{att}}^{(k)} = \textbf{att}^{(k)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.17626em;vertical-align:0"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.89836em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord textbf">att</span></span></span></span><span style="top:-3.20392em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.25em"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.17626em"><span style="top:-3.35126em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.91282em;vertical-align:0"></span><span class="mord"><span class="mord text"><span class="mord textbf">att</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.91282em"><span style="top:-3.0878200000000002em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>，这是为了避免过拟合并简化模型的参数学习过程。具体原因如下：</p><hr><h3 id="1-参数共享减少了模型的自由度"><a class="anchor" href="#1-参数共享减少了模型的自由度">#</a> 1. <strong>参数共享减少了模型的自由度</strong></h3><p>通过设置 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mtext mathvariant="bold">W</mtext><mo>^</mo></mover><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><msup><mtext mathvariant="bold">W</mtext><mrow><mo stretchy="false">(</mo><mi>k</mi><msup><mo stretchy="false">)</mo><mi>T</mi></msup></mrow></msup></mrow><annotation encoding="application/x-tex">\hat{\textbf{W}}^{(k)} = \textbf{W}^{(k)^T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.22745em;vertical-align:0"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.9495499999999999em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord textbf">W</span></span></span></span><span style="top:-3.25511em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.25em"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.22745em"><span style="top:-3.40245em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.082375em;vertical-align:0"></span><span class="mord"><span class="mord text"><span class="mord textbf">W</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.082375em"><span style="top:-3.13901em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.9190928571428572em"><span style="top:-2.931em;margin-right:.07142857142857144em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mtext mathvariant="bold">att</mtext><mo>^</mo></mover><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msup><mo>=</mo><msup><mtext mathvariant="bold">att</mtext><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\hat{\textbf{att}}^{(k)} = \textbf{att}^{(k)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.17626em;vertical-align:0"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.89836em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord text"><span class="mord textbf">att</span></span></span></span><span style="top:-3.20392em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-.25em"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.17626em"><span style="top:-3.35126em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.91282em;vertical-align:0"></span><span class="mord"><span class="mord text"><span class="mord textbf">att</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.91282em"><span style="top:-3.0878200000000002em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>，解码器的权重不再单独学习，而是与编码器的权重共享。这样可以：</p><ul><li><strong>减少模型参数数量</strong>：减小需要学习的参数规模，降低了模型复杂度，从而减少了过拟合的风险。</li><li><strong>强制正则化</strong>：通过共享权重，模型在编码和解码时被约束为一种对称映射，提高了泛化能力。</li></ul><hr><h3 id="2-对称性假设"><a class="anchor" href="#2-对称性假设">#</a> 2. <strong>对称性假设</strong></h3><ul><li><strong>对称的邻接信息重构</strong>：在图数据中，邻接信息通常是对称的。共享参数可以更好地适应图结构的这一特性。</li><li><strong>对偶性设计</strong>：编码器将原始图嵌入到一个潜在空间，解码器再将该潜在空间的表示恢复为原始空间。权重共享实际上保证了解码器对编码器的 “反演” 能力。</li></ul><hr><h3 id="3-理论支持"><a class="anchor" href="#3-理论支持">#</a> 3. <strong>理论支持</strong></h3><p>将解码器权重设为编码器权重的转置，在数学上等价于假设潜在表示空间的映射是线性可逆的：</p>\begin{equation} \textbf{Z} = f(\textbf{X}, \textbf{A}; \textbf{W}, \textbf{att}), \hat{\textbf{A}} = g(\textbf{Z}; \hat{\textbf{W}}, \hat{\textbf{att}}), \end{equation}<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">g</span></span></span></span> 是解码器。如果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi></mrow><annotation encoding="application/x-tex">g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">g</span></span></span></span> 的参数由 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span></span></span></span> 的参数直接确定，模型更倾向于在权重共享的限制下寻找稳定的表示。</p><hr><h3 id="4-实践效果"><a class="anchor" href="#4-实践效果">#</a> 4. <strong>实践效果</strong></h3><p>在实际操作中，权重共享可以显著提升训练效率和模型性能：</p><ul><li>避免了过拟合引起的解码器参数冗余。</li><li>保持了训练的稳定性，尤其是在小数据集或稀疏图上表现明显。</li></ul><hr><h3 id="5-stagate-的特殊性"><a class="anchor" href="#5-stagate-的特殊性">#</a> 5. <strong>STAGATE 的特殊性</strong></h3><p>在 STAGATE 中（针对空间转录组学），数据通常具有显著的稀疏性和局部性。权重共享在这种高噪声数据下尤为重要，因为它降低了解码器单独学习复杂模式的风险，确保模型专注于全局结构和局部关联的核心信息。</p><p><em>Graph attention layer:</em></p>\begin{equation} e_{ij}^k = Sigmoid(\textbf{v}_s^{(K)^T}(\textbf{W}_k\textbf{h}_i^{(k-1)})+\textbf{v}_r^{(K)^T}(\textbf{W}_k\textbf{h}_j^{(k-1)})). \end{equation}<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mtext mathvariant="bold">v</mtext><mi>s</mi><mrow><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\textbf{v}_s^{(K)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.161392em;vertical-align:-.11659199999999997em"></span><span class="mord"><span class="mord text"><span class="mord textbf">v</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.5834080000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span><span style="top:-3.2198em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.11659199999999997em"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mtext mathvariant="bold">v</mtext><mi>r</mi><mrow><mo stretchy="false">(</mo><mi>K</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\textbf{v}_r^{(K)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.161392em;vertical-align:-.11659199999999997em"></span><span class="mord"><span class="mord text"><span class="mord textbf">v</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.5834080000000004em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span></span></span><span style="top:-3.2198em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.07153em">K</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.11659199999999997em"><span></span></span></span></span></span></span></span></span></span> are the trainable weight vectors and Sigmoid represents the sigmoid activation function.</p><p>下面是标准化：</p>\begin{equation} att_{ij}^{(k)} = \frac{exp(e_{ij}^{(k)})}{\sum\limits_{i\in\Upsilon_i}exp(e_{ij}^{(k)})}. \end{equation}<p>cell type-aware 模块的使用：</p>\begin{equation} \textbf{att}_{ij} = (1-\alpha)\textbf{att}_{ij}^{spatial}+\alpha\textbf{att}_{ij}^{aware}. \end{equation}<p>损失函数：</p>\begin{equation} \sum\limits^{N}_{i=1}\| x_i-\hat{h}_i^0\|_2. \end{equation}<h2 id="identifying-differential-expressed-genes"><a class="anchor" href="#identifying-differential-expressed-genes">#</a> Identifying differential expressed genes</h2><p><strong>Benjamin-Hochberg 调整</strong>（Benjamini-Hochberg Adjustment，简称 BH 调整）是一种用于多重假设检验的统计方法，旨在控制<strong>假发现率（False Discovery Rate, FDR）</strong>。FDR 是指被拒绝的零假设中实际为真假设的比例。</p><p>在进行多重假设检验时，由于同时进行多个检验，直接使用原始的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span> - 值会导致较高的错误发现概率（如大量的第一类错误）。BH 调整通过对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span> - 值进行排序和阈值校正，来控制 FDR，使研究者能在多个检验中更有信心地拒绝零假设。</p><hr><h3 id="算法步骤"><a class="anchor" href="#算法步骤">#</a> <strong>算法步骤</strong></h3><p>假设我们有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">m</span></span></span></span> 个假设检验，计算得到对应的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span> - 值为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>p</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>p</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">p_1, p_2, \ldots, p_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">…</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>：</p><ol><li><p><strong>排序 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span> - 值</strong>：</p><ul><li>对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span> - 值进行升序排序，得到排序后的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span> - 值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><mo>≤</mo><msub><mi>p</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></msub><mo>≤</mo><mo>⋯</mo><mo>≤</mo><msub><mi>p</mi><mrow><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo></mrow></msub></mrow><annotation encoding="application/x-tex">p_{(1)} \leq p_{(2)} \leq \cdots \leq p_{(m)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.9911699999999999em;vertical-align:-.3551999999999999em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.9911699999999999em;vertical-align:-.3551999999999999em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.7719400000000001em;vertical-align:-.13597em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.7857599999999999em;vertical-align:-.3551999999999999em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">m</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span></span></span></span>，对应的原始假设分别为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><mo separator="true">,</mo><msub><mi>H</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>H</mi><mrow><mo stretchy="false">(</mo><mi>m</mi><mo stretchy="false">)</mo></mrow></msub></mrow><annotation encoding="application/x-tex">H_{(1)}, H_{(2)}, \ldots, H_{(m)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.03853em;vertical-align:-.3551999999999999em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:-.08125em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:-.08125em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">…</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:-.08125em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">m</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span></span></span></span>。</li></ul></li><li><p><strong>设定目标 FDR</strong>：</p><ul><li>选择一个目标 FDR，记为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span></span></span></span>（通常是 0.05 或 0.10）。</li></ul></li><li><p><strong>计算调整后的阈值</strong>：</p><ul><li>对每个排序后的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span> - 值计算阈值：\begin{equation} p_{\text{threshold}, (i)} = \frac{i}{m} q \end{equation} 其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.65952em;vertical-align:0"></span><span class="mord mathnormal">i</span></span></span></span> 是排序中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msub></mrow><annotation encoding="application/x-tex">p_{(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7857599999999999em;vertical-align:-.3551999999999999em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span></span></span></span> 的位置，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">m</span></span></span></span> 是假设检验总数。</li></ul></li><li><p><strong>确定显著性水平</strong>：</p><ul><li>找到最大的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span></span></span></span> 使得：\begin{equation} p_{(k)} \leq p_{\text{threshold}, (k)} \end{equation}</li><li>记 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>H</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><mo separator="true">,</mo><msub><mi>H</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>H</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msub></mrow><annotation encoding="application/x-tex">H_{(1)}, H_{(2)}, \ldots, H_{(k)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.03853em;vertical-align:-.3551999999999999em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:-.08125em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:-.08125em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="minner">…</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:-.08125em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span></span></span></span> 为显著假设，即可拒绝对应的零假设。</li></ul></li><li><p><strong>调整 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span> - 值</strong>（可选）：</p><ul><li>计算调整后的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span> - 值，用于更直观地评估显著性：\begin{equation} p'_{(i)} = \min\left( \frac{m}{i} p_{(i)}, 1 \right) \end{equation}</li></ul></li></ol><hr><h3 id="核心思想"><a class="anchor" href="#核心思想">#</a> <strong>核心思想</strong></h3><ul><li>BH 调整通过动态的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span> - 值阈值来控制 FDR，使得拒绝的假设数量尽量多，但整体错误率保持在目标范围内。</li><li>相比更严格的 Bonferroni 校正，BH 调整更宽松，因此在实际应用中拒绝的假设通常更多，但仍然具有较高的置信度。</li></ul><hr><h3 id="适用场景"><a class="anchor" href="#适用场景">#</a> <strong>适用场景</strong></h3><ol><li><p><strong>基因组学和多组学数据分析</strong>：</p><ul><li>例如 RNA-seq 或微阵列数据分析中，往往需要同时对成千上万的基因表达水平进行显著性检验。</li></ul></li><li><p><strong>机器学习和深度学习</strong>：</p><ul><li>当对多个特征或模型进行假设检验时，BH 调整可用于选择显著性特征或结果。</li></ul></li><li><p><strong>临床研究</strong>：</p><ul><li>当研究多个治疗变量或药物反应的显著性时，BH 调整有助于减少假发现的风险。</li></ul></li></ol><hr><h3 id="与其他方法的比较"><a class="anchor" href="#与其他方法的比较">#</a> <strong>与其他方法的比较</strong></h3><ol><li><p><strong>Bonferroni 校正</strong>：</p><ul><li>控制的是<strong>整体第一类错误率（FWER）</strong>。</li><li>更严格，显著性检测结果通常较少。</li><li>适用于较少假设检验。</li></ul></li><li><p><strong>Benjamini-Hochberg 校正</strong>：</p><ul><li>控制的是<strong>假发现率（FDR）</strong>。</li><li>更宽松，显著性检测结果更多。</li><li>适用于大量假设检验。</li></ul></li></ol><hr><h3 id="示例"><a class="anchor" href="#示例">#</a> <strong>示例</strong></h3><p>假设有 5 个假设检验，得到的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span> - 值为：$$\begin {equation} 0.01, 0.03, 0.05, 0.10, 0.20 \end {equation}$$，设目标 FDR <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo>=</mo><mn>0.10</mn></mrow><annotation encoding="application/x-tex">q = 0.10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mord">0</span></span></span></span>：</p><ol><li>排序 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span> - 值：$$\begin {equation} 0.01, 0.03, 0.05, 0.10, 0.20 \end {equation}$$</li><li>计算阈值：$$\begin {equation} \frac {1}{5} \cdot 0.10, \frac {2}{5} \cdot 0.10, \frac {3}{5} \cdot 0.10, \frac {4}{5} \cdot 0.10, \frac {5}{5} \cdot 0.10 \end {equation}$$，即 $$\begin {equation} 0.02, 0.04, 0.06, 0.08, 0.10 \end {equation}$$</li><li>找到最大 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span></span></span></span> 使 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msub><mo>≤</mo><msub><mi>p</mi><mrow><mtext>threshold</mtext><mo separator="true">,</mo><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msub></mrow><annotation encoding="application/x-tex">p_{(k)} \leq p_{\text{threshold}, (k)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.9911699999999999em;vertical-align:-.3551999999999999em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.7857599999999999em;vertical-align:-.3551999999999999em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">threshold</span></span><span class="mpunct mtight">,</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span></span></span></span>：只有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mn>0.01</mn></mrow><annotation encoding="application/x-tex">p_{(1)} = 0.01</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7857599999999999em;vertical-align:-.3551999999999999em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">1</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></msub><mo>=</mo><mn>0.03</mn></mrow><annotation encoding="application/x-tex">p_{(2)} = 0.03</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7857599999999999em;vertical-align:-.3551999999999999em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.34480000000000005em"><span style="top:-2.5198em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3551999999999999em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">3</span></span></span></span> 满足条件，因此拒绝对应的 2 个假设。</li></ol><h3 id="结论"><a class="anchor" href="#结论">#</a> <strong>结论</strong></h3><p>BH 调整是一种平衡严格性和敏感性的校正方法，尤其适合大规模多重检验问题。</p><h2 id="identification-of-3d-spatial-domains-using-stagate"><a class="anchor" href="#identification-of-3d-spatial-domains-using-stagate">#</a> Identification of 3D spatial domains using STAGATE</h2><p>the batch effect between sections hinders the extraction of 3D spatial patterns. Here we introduced a 3D SNN by incorporating the 2D SNN of each section and the SNN between adjacent sections to alleviate the batch effect between consecutive sections.</p><p>The key idea of the usage of 3D SNN is that the biological differences between consecutive sections should be continuous, so we can enhance the similarity between adjacent sections to eliminate the discontinuous independent technical noises.</p><h1 id="代码"><a class="anchor" href="#代码">#</a> 代码</h1><p>安装 pyG 时遇到 torch-sparse 报错：</p><p>在这个<span class="exturl" data-url="aHR0cHM6Ly9kYXRhLnB5Zy5vcmcvd2hsL3RvcmNoLTEuMTIuMSUyQmNwdS5odG1s">网站</span>上找对应的版本</p><p>照搬代码也没意思，就记录一下自己觉得有价值、可以学习的地方吧。</p><p>这里面的方法其实主体是 Graph Attention Network，然后在此基础上进行操作。看来是有必要去阅读一下这篇论文，毕竟也不是主要工作，近期去泛读一下吧，就下篇文章先看<span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE3MTAuMTA5MDM=">这个</span>再去看 MENDER 那篇文章。</p><p>参数和方法：</p>\begin{equation} \mathbf{x}^{\prime}_i = \alpha_{i,i}\mathbf{\Theta}\mathbf{x}_{i} + \sum_{j \in \mathcal{N}(i)} \alpha_{i,j}\mathbf{\Theta}\mathbf{x}_{j}, \end{equation}<p>where the attention coefficients <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\alpha_{i,j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.716668em;vertical-align:-.286108em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.0037em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.286108em"><span></span></span></span></span></span></span></span></span></span> are computed as</p>\begin{equation} \alpha_{i,j} = \frac{ \exp\left(\mathrm{LeakyReLU}\left(\mathbf{a}^{\top} [\mathbf{\Theta}\mathbf{x}_i \, \Vert \, \mathbf{\Theta}\mathbf{x}_j] \right)\right)} {\sum_{k \in \mathcal{N}(i) \cup \{ i \}} \exp\left(\mathrm{LeakyReLU}\left(\mathbf{a}^{\top} [\mathbf{\Theta}\mathbf{x}_i \, \Vert \, \mathbf{\Theta}\mathbf{x}_k] \right)\right)}. \end{equation}<p>Args:</p><ul><li>in_channels (int or tuple): Size of each input sample, or <code>-1</code> to derive the size from the first input(s) to the forward method. A tuple corresponds to the sizes of source and target dimensionalities.</li><li>out_channels (int): Size of each output sample.</li><li>heads (int, optional): Number of multi-head-attentions.(default: <code>1</code> )</li><li>concat (bool, optional): If set to : <code>False</code> , the multi-head<br>attentions are averaged instead of concatenated.<br>(default: <code>True</code> )</li><li>negative_slope (float, optional): LeakyReLU angle of the negative<br>slope. (default: <code>0.2</code> )</li><li>dropout (float, optional): Dropout probability of the normalized<br>attention coefficients which exposes each node to a stochastically<br>sampled neighborhood during training. (default: :obj: <code>0</code> )</li><li>add_self_loops (bool, optional): If set to :obj: <code>False</code> , will not add<br>self-loops to the input graph. (default: :obj: <code>True</code> )</li><li>bias (bool, optional): If set to :obj: <code>False</code> , the layer will not learn<br>an additive bias. (default: :obj: <code>True</code> )</li><li>kwargs (optional): Additional arguments of :class: <code>torch_geometric.nn.conv.MessagePassing</code> .</li></ul><p>Dropout 是一种正则化技术，用于神经网络训练过程中，帮助防止模型过拟合（overfitting）。它的核心思想是，在每次训练迭代中，随机地将一些神经元的输出值置为零，从而削弱神经元间的依赖性，提高模型的泛化能力</p><p><strong><code>nn.init.xavier_normal_</code> </strong>是 PyTorch 中的一个函数，用于对神经网络层的权重进行初始化。它实现了 <strong>Xavier initialization</strong> 的一种变体，采用正态分布来初始化权重。其目的是保证神经网络的输入和输出的方差在前向传播和反向传播中尽量保持一致，避免梯度爆炸或消失的问题。</p><hr><h3 id="xavier-initialization"><a class="anchor" href="#xavier-initialization">#</a> <strong>Xavier Initialization</strong></h3><p>Xavier 初始化方法来源于论文 <em>&quot;Understanding the difficulty of training deep feedforward neural networks&quot;</em>（Glorot &amp; Bengio, 2010）。它的核心思想是：</p><ul><li><strong>初始化权重时的分布方差</strong>依赖于输入和输出的神经元个数：\begin{equation} \text{Var}(w) = \frac{2}{\text{fan\_in} + \text{fan\_out}} \end{equation} 其中：<ul><li><strong>fan_in</strong> 是该层输入的神经元个数。</li><li><strong>fan_out</strong> 是该层输出的神经元个数。</li></ul></li></ul><p>Xavier 初始化有两种实现方式：</p><ol><li><strong>均匀分布（Xavier Uniform）：</strong> 从区间 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mo>−</mo><mi>a</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[-a, a]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">[</span><span class="mord">−</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">a</span><span class="mclose">]</span></span></span></span> 中采样，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><msqrt><mfrac><mn>6</mn><mrow><mtext>fan_in</mtext><mo>+</mo><mtext>fan_out</mtext></mrow></mfrac></msqrt></mrow><annotation encoding="application/x-tex">a = \sqrt{\frac{6}{\text{fan\_in} + \text{fan\_out}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.8399999999999999em;vertical-align:-.7134459999999999em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.126554em"><span class="svg-align" style="top:-3.8em"><span class="pstrut" style="height:3.8em"></span><span class="mord" style="padding-left:1em"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.845108em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">fan_in</span></span><span class="mbin mtight">+</span><span class="mord text mtight"><span class="mord mtight">fan_out</span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">6</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.5619999999999999em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.086554em"><span class="pstrut" style="height:3.8em"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em"><svg width="400em" height="1.8800000000000001em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.7134459999999999em"><span></span></span></span></span></span></span></span></span>。</li><li><strong>正态分布（Xavier Normal）：</strong> 从均值为 0，标准差为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><mfrac><mn>2</mn><mrow><mtext>fan_in</mtext><mo>+</mo><mtext>fan_out</mtext></mrow></mfrac></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{\frac{2}{\text{fan\_in} + \text{fan\_out}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.8399999999999999em;vertical-align:-.7134459999999999em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.126554em"><span class="svg-align" style="top:-3.8em"><span class="pstrut" style="height:3.8em"></span><span class="mord" style="padding-left:1em"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.845108em"><span style="top:-2.6550000000000002em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">fan_in</span></span><span class="mbin mtight">+</span><span class="mord text mtight"><span class="mord mtight">fan_out</span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.5619999999999999em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.086554em"><span class="pstrut" style="height:3.8em"></span><span class="hide-tail" style="min-width:1.02em;height:1.8800000000000001em"><svg width="400em" height="1.8800000000000001em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.7134459999999999em"><span></span></span></span></span></span></span></span></span> 的正态分布中采样。</li></ol><hr><h3 id="nninitxavier_normal_-的工作原理"><a class="anchor" href="#nninitxavier_normal_-的工作原理">#</a> <strong><code>nn.init.xavier_normal_</code> 的工作原理</strong></h3><ul><li>它基于正态分布来初始化权重。</li><li>对于权重张量中的每个值，按照以下公式采样：\begin{equation} w \sim \mathcal{N}\left(0, \sqrt{\frac{2}{\text{fan\_in} + \text{fan\_out}}}\right) \end{equation}</li></ul><hr><h3 id="函数签名"><a class="anchor" href="#函数签名">#</a> <strong>函数签名</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.init.xavier_normal_(tensor, gain=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure><h4 id="参数"><a class="anchor" href="#参数">#</a> <strong>参数</strong></h4><ol><li><strong><code>tensor</code> </strong>: 要初始化的权重张量。</li><li><strong><code>gain</code> </strong>: 一个缩放因子，用于调整初始化分布的标准差。通常用 1（默认值）或非线性激活函数的导数相关值（例如对于 ReLU 激活，可以设置为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><mn>2</mn></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.04em;vertical-align:-.13278em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.90722em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:.833em"><span class="mord">2</span></span></span><span style="top:-2.86722em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:.853em;height:1.08em"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.13278em"><span></span></span></span></span></span></span></span></span>）。</li></ol><hr><h3 id="使用示例"><a class="anchor" href="#使用示例">#</a> <strong>使用示例</strong></h3><p>以下示例展示如何使用 <code>nn.init.xavier_normal_</code> 初始化权重：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个权重张量</span></span><br><span class="line">weights = torch.empty(<span class="number">3</span>, <span class="number">5</span>)  <span class="comment"># 假设是一个 3x5 的线性层权重矩阵</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 xavier_normal_ 初始化权重</span></span><br><span class="line">nn.init.xavier_normal_(weights)</span><br><span class="line"><span class="built_in">print</span>(weights)</span><br></pre></td></tr></table></figure><hr><h3 id="在模型中的应用"><a class="anchor" href="#在模型中的应用">#</a> <strong>在模型中的应用</strong></h3><p>通常在构造自定义神经网络时，我们可以用 <code>xavier_normal_</code> 对权重进行初始化。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyModel, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(<span class="number">10</span>, <span class="number">5</span>)  <span class="comment"># 全连接层</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset_parameters</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 初始化全连接层的权重</span></span><br><span class="line">        nn.init.xavier_normal_(<span class="variable language_">self</span>.fc.weight)</span><br><span class="line"></span><br><span class="line">model = MyModel()</span><br><span class="line">model.reset_parameters()</span><br></pre></td></tr></table></figure><hr><h3 id="xavier-initialization-的优势"><a class="anchor" href="#xavier-initialization-的优势">#</a> <strong>Xavier Initialization 的优势</strong></h3><ol><li>平衡了输入和输出的方差，使得前向传播和反向传播的梯度不会过大或过小。</li><li>提高训练的收敛速度和稳定性，尤其是深层网络中。</li></ol><hr><p>对于代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_src = x_dst = torch.mm(x, <span class="variable language_">self</span>.lin_src).view(-<span class="number">1</span>, H, C)</span><br></pre></td></tr></table></figure><p>其中 H 和 C 代表</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">H, C = <span class="variable language_">self</span>.heads, <span class="variable language_">self</span>.out_channels</span><br></pre></td></tr></table></figure><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi><mo>→</mo><mi mathvariant="bold">Θ</mi><mi mathvariant="bold">x</mi><mo>→</mo><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi>s</mi><mo separator="true">,</mo><mi>o</mi><mi>u</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>c</mi><mi>h</mi><mi>a</mi><mi>n</mi><mi>n</mi><mi>e</mi><mi>l</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}\to\mathbf{\Theta}\mathbf{x}\to heads, out\_channels</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.44444em;vertical-align:0"></span><span class="mord"><span class="mord mathbf">x</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">→</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.68611em;vertical-align:0"></span><span class="mord"><span class="mord mathbf">Θ</span></span><span class="mord"><span class="mord mathbf">x</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">→</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-.31em"></span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mord" style="margin-right:.02778em">_</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal">a</span><span class="mord mathnormal">n</span><span class="mord mathnormal">n</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:.01968em">l</span><span class="mord mathnormal">s</span></span></span></span></p><h3 id="拆解解析"><a class="anchor" href="#拆解解析">#</a> <strong>拆解解析：</strong></h3><ol><li><p><strong><code>torch.mm(x, self.lin_src)</code></strong></p><ul><li><strong>功能</strong>：矩阵乘法。对输入特征 <code>x</code> 应用权重矩阵 <code>self.lin_src</code> ，完成线性变换。</li><li><strong>参数：</strong><ul><li><code>x</code> 是输入节点的特征矩阵，形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><msub><mi>F</mi><mtext>in</mtext></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, F_{\text{in}})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31750199999999995em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">in</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，其中：<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span></span></span></span> 是节点的数量。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mtext>in</mtext></msub></mrow><annotation encoding="application/x-tex">F_{\text{in}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31750199999999995em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">in</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 是每个节点的输入特征维度。</li></ul></li><li><code>self.lin_src</code> 是权重矩阵，形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>F</mi><mtext>in</mtext></msub><mo separator="true">,</mo><mi>H</mi><mo>⋅</mo><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(F_{\text{in}}, H \cdot C)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31750199999999995em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">in</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mclose">)</span></span></span></span>，其中：<ul><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi></mrow><annotation encoding="application/x-tex">H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span></span></span></span> 是多头注意力的头数（ <code>heads</code> ）。</li><li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span></span></span></span> 是每个注意力头的输出特征维度。</li></ul></li></ul></li><li><strong>结果</strong>：矩阵乘法的输出形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>H</mi><mo>⋅</mo><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, H \cdot C)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mclose">)</span></span></span></span>，即所有节点的特征经过线性变换后的新表示。</li></ul></li><li><p><strong><code>.view(-1, H, C)</code></strong></p><ul><li><strong>功能</strong>：对上述结果重新调整形状，便于后续的多头处理。</li><li><strong>参数：</strong><ul><li><code>-1</code> 表示保持第一个维度的大小（即节点数量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span></span></span></span>）。</li><li><code>H</code> 表示多头注意力的头数。</li><li><code>C</code> 表示每个头的输出特征维度。</li></ul></li><li><strong>结果</strong>：输出形状变为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>H</mi><mo separator="true">,</mo><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, H, C)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mclose">)</span></span></span></span>，即每个节点特征被拆分为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi></mrow><annotation encoding="application/x-tex">H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span></span></span></span> 个注意力头，每个头有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span></span></span></span> 个维度的特征。</li></ul></li><li><p><strong><code>x_src = x_dst = ...</code></strong></p><ul><li><strong>功能</strong>：将线性变换的结果赋值给 <code>x_src</code> 和 <code>x_dst</code> ，分别代表源节点特征和目标节点特征。</li><li><strong>场景</strong>：<ul><li>在无向图或默认情况下，源节点和目标节点特征是相同的，所以 <code>x_src</code> 和 <code>x_dst</code> 被赋值为同一个结果。</li><li>在二部图（bipartite graph）中， <code>x_src</code> 和 <code>x_dst</code> 可以分别代表不同的特征。</li></ul></li></ul></li></ol><hr><h3 id="直观示例"><a class="anchor" href="#直观示例">#</a> <strong>直观示例：</strong></h3><p>假设：</p><ul><li><p>输入特征矩阵 <code>x</code> 为：</p>\begin{equation} x = \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{bmatrix}, \quad \text{形状: } (2, 3) \end{equation}<p>（2 个节点，每个节点有 3 维特征）。</p></li><li><p>权重矩阵 <code>self.lin_src</code> 为：</p>\begin{equation} \text{self.lin_src} = \begin{bmatrix} 0.1 & 0.2 & 0.3 & 0.4 \\ 0.5 & 0.6 & 0.7 & 0.8 \\ 0.9 & 1.0 & 1.1 & 1.2 \end{bmatrix}, \quad \text{形状: } (3, 4) \end{equation}<p>（输入维度 3，输出维度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>⋅</mo><mi>C</mi><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">H \cdot C = 4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">4</span></span></span></span>）。</p></li></ul><h4 id="计算过程"><a class="anchor" href="#计算过程">#</a> <strong>计算过程：</strong></h4><ol><li><p><strong>矩阵乘法：</strong></p>\begin{equation} \text{torch.mm}(x, \text{self.lin_src}) = \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{bmatrix} \cdot \begin{bmatrix} 0.1 & 0.2 & 0.3 & 0.4 \\ 0.5 & 0.6 & 0.7 & 0.8 \\ 0.9 & 1.0 & 1.1 & 1.2 \end{bmatrix} = \begin{bmatrix} 4.2 & 4.8 & 5.4 & 6.0 \\ 9.9 & 11.4 & 12.9 & 14.4 \end{bmatrix} \end{equation}<p>输出形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>2</mn><mo separator="true">,</mo><mn>4</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(2, 4)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">4</span><span class="mclose">)</span></span></span></span>。</p></li><li><p><strong>调整形状：</strong><br>假设多头 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">H = 2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">2</span></span></span></span>，每头输出特征维度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">C = 2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">2</span></span></span></span>。将形状从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>2</mn><mo separator="true">,</mo><mn>4</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(2, 4)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">4</span><span class="mclose">)</span></span></span></span> 调整为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>2</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mn>2</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(2, 2, 2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">2</span><span class="mclose">)</span></span></span></span>：</p>\begin{equation} \text{view(-1, H, C)} = \begin{bmatrix} [[4.2, 4.8], [5.4, 6.0]] \\ [[9.9, 11.4], [12.9, 14.4]] \end{bmatrix} \end{equation} 表示每个节点有两个注意力头，每个头有 2 维特征。</li></ol><h3 id="总结"><a class="anchor" href="#总结">#</a> <strong>总结：</strong></h3><ul><li><code>torch.mm(x, self.lin_src)</code> 将输入特征与权重矩阵相乘，得到新的特征表示。</li><li><code>.view(-1, H, C)</code> 将结果重塑为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>H</mi><mo separator="true">,</mo><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, H, C)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.08125em">H</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mclose">)</span></span></span></span>，为每个节点的每个注意力头分配特征。</li><li>通过 <code>x_src</code> 和 <code>x_dst</code> 分别表示源节点和目标节点的特征，支持二部图和无向图。</li></ul><hr><p>alpha.unsqueeze (-1) 的含义</p><ol><li>基本功能：<br>unsqueeze (dim) 是 PyTorch 中用于在指定维度插入一个新轴（维度）的操作。<br>dim=-1 表示在最后一个维度新增一个轴。</li></ol><hr><p><code>torch_geometric.nn.MessagePassing</code> 是 PyTorch Geometric 中的一个核心基类，用于实现图神经网络（Graph Neural Network, GNN）中的消息传递机制。通过继承这个类，我们可以轻松定义各种基于消息传递的图神经网络模型。</p><hr><h3 id="messagepassing-的核心机制"><a class="anchor" href="#messagepassing-的核心机制">#</a> <strong><code>MessagePassing</code> 的核心机制</strong></h3><p>消息传递的核心思想是在图的边上计算信息，然后聚合到节点上。 <code>MessagePassing</code> 提供了以下主要的流程：</p><ol><li><strong>消息传递</strong>（ <code>message</code> ）：计算边的特征或从相邻节点收集的信息。</li><li><strong>消息聚合</strong>（ <code>aggregate</code> ）：将邻居节点的信息聚合到中心节点上。</li><li><strong>更新</strong>（ <code>update</code> ）：用聚合后的信息更新节点特征。</li><li><strong>传播</strong>（ <code>propagate</code> ）：协调消息传递流程，调用 <code>message</code> 、 <code>aggregate</code> 和 <code>update</code> 方法。</li></ol><hr><h3 id="messagepassing-的核心方法"><a class="anchor" href="#messagepassing-的核心方法">#</a> <strong><code>MessagePassing</code> 的核心方法</strong></h3><h4 id="1-初始化__init__"><a class="anchor" href="#1-初始化__init__">#</a> 1. <strong>初始化： <code>__init__</code></strong></h4><p><code>MessagePassing</code> 类初始化时可以通过 <code>aggr</code> 参数指定聚合方式：</p><ul><li><code>&quot;add&quot;</code> ：加和邻居消息（默认）。</li><li><code>&quot;mean&quot;</code> ：求平均。</li><li><code>&quot;max&quot;</code> ：取最大值。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyGNN</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(aggr=<span class="string">&#x27;mean&#x27;</span>)  <span class="comment"># 聚合方式为求平均</span></span><br></pre></td></tr></table></figure><h4 id="2-消息传播propagate"><a class="anchor" href="#2-消息传播propagate">#</a> 2. <strong>消息传播： <code>propagate</code></strong></h4><p><code>propagate</code> 是消息传递的入口。它需要以下关键参数：</p><ul><li><code>edge_index</code> ：边的索引。</li><li><code>x</code> ：节点特征。</li><li>可选参数：如 <code>edge_weight</code> （边的权重）。</li></ul><p><code>propagate</code> 会调用 <code>message</code> 、 <code>aggregate</code> 和 <code>update</code> 。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyGNN</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.propagate(edge_index, x=x)  <span class="comment"># 触发消息传递流程</span></span><br></pre></td></tr></table></figure><h4 id="3-消息生成message"><a class="anchor" href="#3-消息生成message">#</a> 3. <strong>消息生成： <code>message</code></strong></h4><p><code>message</code> 定义了如何生成消息，通常依赖边两端的特征（ <code>x_i</code> 和 <code>x_j</code> ），以及边的属性（如果有）。</p><ul><li><code>x_i</code> ：目标节点的特征（中心节点）。</li><li><code>x_j</code> ：源节点的特征（邻居节点）。</li><li><code>edge_attr</code> （可选）：边的属性。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyGNN</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">message</span>(<span class="params">self, x_j</span>):</span><br><span class="line">        <span class="keyword">return</span> x_j  <span class="comment"># 示例：直接返回邻居节点特征</span></span><br></pre></td></tr></table></figure><h4 id="4-消息聚合aggregate"><a class="anchor" href="#4-消息聚合aggregate">#</a> 4. <strong>消息聚合： <code>aggregate</code></strong></h4><p><code>aggregate</code> 定义了如何对接收到的消息进行聚合，通常使用的是初始化时指定的聚合方式。如果需要自定义，可以覆盖该方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyGNN</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">aggregate</span>(<span class="params">self, inputs, index</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.mean(inputs, dim=<span class="number">0</span>)  <span class="comment"># 示例：对所有邻居求平均</span></span><br></pre></td></tr></table></figure><h4 id="5-更新update"><a class="anchor" href="#5-更新update">#</a> 5. <strong>更新： <code>update</code></strong></h4><p><code>update</code> 定义了如何使用聚合后的特征更新节点特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyGNN</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        <span class="keyword">return</span> inputs  <span class="comment"># 示例：直接返回聚合后的特征</span></span><br></pre></td></tr></table></figure><hr><h3 id="完整示例自定义-gcn"><a class="anchor" href="#完整示例自定义-gcn">#</a> <strong>完整示例：自定义 GCN</strong></h3><p>以下是实现一个简单图卷积网络（Graph Convolutional Network, GCN）的示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> add_self_loops, degree</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GCNConv</span>(<span class="title class_ inherited__">MessagePassing</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(aggr=<span class="string">&#x27;add&#x27;</span>)  <span class="comment"># 使用加和作为聚合方式</span></span><br><span class="line">        <span class="variable language_">self</span>.linear = torch.nn.Linear(in_channels, out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        <span class="comment"># 添加自环</span></span><br><span class="line">        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算节点的度</span></span><br><span class="line">        row, col = edge_index</span><br><span class="line">        deg = degree(col, x.size(<span class="number">0</span>), dtype=x.dtype)</span><br><span class="line">        deg_inv_sqrt = deg.<span class="built_in">pow</span>(-<span class="number">0.5</span>)</span><br><span class="line">        deg_inv_sqrt[deg_inv_sqrt == <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算归一化因子</span></span><br><span class="line">        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 调用 propagate 进行消息传递</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.propagate(edge_index, x=x, norm=norm)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">message</span>(<span class="params">self, x_j, norm</span>):</span><br><span class="line">        <span class="comment"># 消息为归一化的特征</span></span><br><span class="line">        <span class="keyword">return</span> norm.view(-<span class="number">1</span>, <span class="number">1</span>) * x_j</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, aggr_out</span>):</span><br><span class="line">        <span class="comment"># 更新后的节点特征</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.linear(aggr_out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试</span></span><br><span class="line">x = torch.rand(<span class="number">4</span>, <span class="number">16</span>)  <span class="comment"># 4 个节点，每个节点 16 维特征</span></span><br><span class="line">edge_index = torch.tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">2</span>]])  <span class="comment"># 边的索引</span></span><br><span class="line"></span><br><span class="line">conv = GCNConv(<span class="number">16</span>, <span class="number">32</span>)  <span class="comment"># 输入 16 维，输出 32 维</span></span><br><span class="line">out = conv(x, edge_index)</span><br><span class="line"><span class="built_in">print</span>(out.shape)  <span class="comment"># 输出: torch.Size([4, 32])</span></span><br></pre></td></tr></table></figure><hr><h3 id="常见用法"><a class="anchor" href="#常见用法">#</a> <strong>常见用法</strong></h3><ul><li><strong>GCN</strong>: 使用加权和的消息传递。</li><li><strong>GAT</strong>: 在 <code>message</code> 方法中引入注意力机制。</li><li><strong>GraphSAGE</strong>: 在 <code>aggregate</code> 方法中自定义聚合方式（如均值或池化）。</li></ul><p>通过继承 <code>MessagePassing</code> ，可以高度灵活地实现各种图神经网络模型，同时复用其高效的计算框架和操作优化。</p><p>学到现在，我认为这个对细胞数据进行聚类的思想就是把相似的区域聚类在一起，不同的区域分开，主要的思想方法就是加强数据的隐藏信息，只不过每种方法采用的方式不同。最关键的一点就是利用邻居 spot 的信息</p><hr><p>原文中的代码 att_src 就是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>s</mi></msub><mrow><mo stretchy="false">(</mo><mi>k</mi><msup><mo stretchy="false">)</mo><mi>T</mi></msup></mrow></mrow><annotation encoding="application/x-tex">v_s{(k)^T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span></span></span></span></span>,att_dst 就是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>r</mi></msub><mrow><mo stretchy="false">(</mo><mi>k</mi><msup><mo stretchy="false">)</mo><mi>T</mi></msup></mrow></mrow><annotation encoding="application/x-tex">v_r{(k)^T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913309999999998em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.02778em">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03148em">k</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413309999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.13889em">T</span></span></span></span></span></span></span></span></span></span></span></span>, 看了半天差点被绕进去</p><hr><p>Constructs messages from node <code>j</code> to node <code>i</code> in analogy <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Θ</mi></mrow><annotation encoding="application/x-tex">\Theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord">Θ</span></span></span></span> to for each edge in <code>edge_index</code> . This function can take any argument as input which was initially passed to <code>propagate()</code> . Furthermore, tensors passed to propagate() can be mapped to the respective nodes and by appending <code>_i</code> or <code>_j</code> to the variable name, .e.g. <code>x_i</code> and <code>x_j</code> .</p><p>在 PyTorch Geometric 的 <code>MessagePassing</code> 框架中， <code>message</code> 方法中的参数是由 <code>self.propagate</code> 方法自动传递的。具体到你的代码， <code>x_j</code> 、 <code>alpha_j</code> 和 <code>alpha_i</code> 是从 <code>self.propagate</code> 调用中解析出来的，依据的是 <code>edge_index</code> 和传递的输入特征。下面我们详细分析这些参数的来源：</p><hr><h3 id="1-参数的来源和含义"><a class="anchor" href="#1-参数的来源和含义">#</a> <strong>1. 参数的来源和含义</strong></h3><h4 id="1-x_j"><a class="anchor" href="#1-x_j">#</a> <strong>(1) <code>x_j</code></strong></h4><p><code>x_j</code> 表示 <strong>从源节点传递过来的特征</strong>，由 <code>edge_index[0]</code> （源节点索引）指定：</p><ul><li>在 <code>self.propagate</code> 中，通过检查 <code>x</code> 的参数名， <code>x_j</code> 被解释为 <code>x[edge_index[0]]</code> ，即根据边的源节点索引提取的源节点特征。</li><li>例如， <code>edge_index[0] = [0, 1, 2]</code> 时， <code>x_j</code> 是第 0、1、2 个节点的特征。</li></ul><h4 id="2-alpha_j"><a class="anchor" href="#2-alpha_j">#</a> <strong>(2) <code>alpha_j</code></strong></h4><p><code>alpha_j</code> 表示 <strong>与源节点相关的注意力系数</strong>，由 <code>edge_index[0]</code> 提取：</p><ul><li>如果在调用 <code>self.propagate</code> 时传入了一个参数名为 <code>alpha</code> 的张量， <code>alpha_j</code> 会被解释为 <code>alpha[edge_index[0]]</code> 。</li><li>例如，如果 <code>alpha = [0.2, 0.5, 0.7]</code> 且 <code>edge_index[0] = [0, 1, 2]</code> ，那么 <code>alpha_j = [0.2, 0.5, 0.7]</code> 。</li></ul><h4 id="3-alpha_i"><a class="anchor" href="#3-alpha_i">#</a> <strong>(3) <code>alpha_i</code></strong></h4><p><code>alpha_i</code> 表示 <strong>与目标节点相关的注意力系数</strong>，由 <code>edge_index[1]</code> 提取：</p><ul><li>同样， <code>alpha_i</code> 来源于 <code>alpha[edge_index[1]]</code> 。</li><li>例如， <code>edge_index[1] = [2, 0, 1]</code> 时， <code>alpha_i</code> 是第 2、0、1 个节点的注意力系数。</li></ul><h4 id="4-其他参数"><a class="anchor" href="#4-其他参数">#</a> <strong>(4) 其他参数</strong></h4><ul><li><strong><code>index</code> </strong>: 对应于 <code>edge_index[1]</code> ，即目标节点索引。它告诉框架将消息聚合到哪些节点。</li><li><strong><code>ptr</code> </strong>: 用于稀疏张量（ <code>SparseTensor</code> ）的支持，用来更高效地管理边的分组。</li><li><strong><code>size_i</code> </strong>: 指定目标节点的数量，确保聚合操作的正确性。</li></ul><hr><h3 id="2-自动传递参数的机制"><a class="anchor" href="#2-自动传递参数的机制">#</a> <strong>2. 自动传递参数的机制</strong></h3><h4 id="1-selfpropagate-调用中的参数匹配"><a class="anchor" href="#1-selfpropagate-调用中的参数匹配">#</a> <strong>(1) <code>self.propagate</code> 调用中的参数匹配</strong></h4><p>在 <code>self.propagate(edge_index, x=x, alpha=alpha)</code> 中：</p><ul><li><code>x</code> 对应的特征被拆解为 <code>x_j</code> 和 <code>x_i</code> ，分别表示源节点和目标节点特征。</li><li><code>alpha</code> 被拆解为 <code>alpha_j</code> 和 <code>alpha_i</code> ，分别表示与源节点和目标节点相关的注意力系数。</li></ul><p>例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.propagate(edge_index, x=x, alpha=alpha)</span><br></pre></td></tr></table></figure><p>等价于：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.message(</span><br><span class="line">    x_j=x[edge_index[<span class="number">0</span>]],</span><br><span class="line">    alpha_j=alpha[edge_index[<span class="number">0</span>]],</span><br><span class="line">    alpha_i=alpha[edge_index[<span class="number">1</span>]],</span><br><span class="line">    index=edge_index[<span class="number">1</span>],</span><br><span class="line">    ptr=<span class="literal">None</span>,</span><br><span class="line">    size_i=<span class="literal">None</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="2-自动解包"><a class="anchor" href="#2-自动解包">#</a> <strong>(2) 自动解包</strong></h4><p><code>MessagePassing</code> 框架会根据 <code>message</code> 方法的参数名，自动解包传入的张量并映射到适当的索引位置。</p><hr><p>注意数据集 data 的 data.x 指的是 adata.X，也就是每个节点 (spot) 对应 features 的 gene 表达值；data.edge_index 指的是邻接关系。</p><p>对于这一行的代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KNN_list.append(pd.DataFrame(<span class="built_in">zip</span>([it]*indices.shape[<span class="number">1</span>],indices[it,:], distances[it,:])))</span><br></pre></td></tr></table></figure><p>这行代码的作用是将每个点（ <code>it</code> ）的邻居信息（包括邻居的索引和距离）以 <code>DataFrame</code> 的形式追加到 <code>KNN_list</code> 列表中。具体来说，它是构造一个包含当前点与其邻居的关系的 <code>DataFrame</code> 。</p><ol><li><p><strong><code>indices[it,:]</code> </strong>:</p><ul><li><code>indices</code> 是一个二维数组，表示每个点的邻居索引。 <code>indices[it,:]</code> 表示第 <code>it</code> 个点的所有邻居的索引。</li><li>假设 <code>indices[it,:]</code> 是一个一维数组，包含第 <code>it</code> 个点的所有邻居的索引，例如：[0, 3, 5, 6]。</li></ul></li><li><p><strong><code>distances[it,:]</code> </strong>:</p><ul><li><code>distances</code> 是一个二维数组，表示每个点到其邻居的距离。 <code>distances[it,:]</code> 表示第 <code>it</code> 个点到所有邻居的距离。</li><li>假设 <code>distances[it,:]</code> 是一个一维数组，包含第 <code>it</code> 个点到各个邻居的距离，例如：[0.1, 0.2, 0.4, 0.5]。</li></ul></li><li><p><strong><code>[it]*indices.shape[1]</code> </strong>:</p><ul><li><code>indices.shape[1]</code> 表示 <code>it</code> 点的邻居数量（即列数）。比如，如果 <code>indices[it,:]</code> 有 4 个元素，则 <code>indices.shape[1]</code> 是 4。</li><li><code>[it]*indices.shape[1]</code> 会生成一个列表，其中的每个元素都是 <code>it</code> （即当前点的索引）。比如， <code>[it]*4</code> 生成的列表是 <code>[it, it, it, it]</code> ，表示当前点与其 4 个邻居的连接。</li></ul></li><li><p><strong><code>zip([it]*indices.shape[1], indices[it,:], distances[it,:])</code> </strong>:</p><ul><li><code>zip</code> 将这三个列表打包成一个迭代器。每次迭代返回一个元组，包含当前点的索引、邻居的索引和邻居之间的距离。例如，如果 <code>it=0</code> ， <code>indices[it,:] = [0, 3, 5, 6]</code> 和 <code>distances[it,:] = [0.1, 0.2, 0.4, 0.5]</code> ，则 <code>zip</code> 生成的内容如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0.1</span>), (<span class="number">0</span>, <span class="number">3</span>, <span class="number">0.2</span>), (<span class="number">0</span>, <span class="number">5</span>, <span class="number">0.4</span>), (<span class="number">0</span>, <span class="number">6</span>, <span class="number">0.5</span>)]</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong><code>pd.DataFrame(zip([it]*indices.shape[1], indices[it,:], distances[it,:]))</code> </strong>:</p><ul><li><code>pd.DataFrame()</code> 将 <code>zip</code> 生成的元组转换为一个 <code>DataFrame</code> ，并自动为其分配列名（默认为 0, 1, 2）。例如，转换后的 <code>DataFrame</code> 可能是：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  <span class="number">0</span>  <span class="number">1</span>    <span class="number">2</span></span><br><span class="line"><span class="number">0</span>  <span class="number">0</span>  <span class="number">0</span>  <span class="number">0.1</span></span><br><span class="line"><span class="number">1</span>  <span class="number">0</span>  <span class="number">3</span>  <span class="number">0.2</span></span><br><span class="line"><span class="number">2</span>  <span class="number">0</span>  <span class="number">5</span>  <span class="number">0.4</span></span><br><span class="line"><span class="number">3</span>  <span class="number">0</span>  <span class="number">6</span>  <span class="number">0.5</span></span><br></pre></td></tr></table></figure>其中：<ul><li>第一列 ( <code>0</code> ) 是当前点的索引（即 <code>it</code> ）。</li><li>第二列 ( <code>1</code> ) 是邻居的索引（即 <code>indices[it,:]</code> ）。</li><li>第三列 ( <code>2</code> ) 是对应的距离（即 <code>distances[it,:]</code> ）。</li></ul></li></ul></li><li><p><strong><code>KNN_list.append(...)</code> </strong>:</p><ul><li>最后， <code>DataFrame</code> 被添加到 <code>KNN_list</code> 列表中。 <code>KNN_list</code> 最终将包含所有点与其邻居的连接信息。</li></ul></li></ol><p>这行代码的核心功能是为每个点创建一个 <code>DataFrame</code> ，该 <code>DataFrame</code> 包含当前点与其邻居的连接信息，并将这些 <code>DataFrame</code> 依次添加到 <code>KNN_list</code> 中。最终， <code>KNN_list</code> 会保存所有点的邻接信息，其中每个 <code>DataFrame</code> 包含一个点与其邻居的索引和距离。</p><hr><h1 id="tutorial-1-10x-visiumdlpfc-dataset"><a class="anchor" href="#tutorial-1-10x-visiumdlpfc-dataset">#</a> Tutorial 1： 10x Visium（DLPFC dataset）</h1><p>下载数据踩的坑：<br>我脑子有坑才用了上交的源而非清华源，同一个东西，一个下了 3 个小时，一个下了 15 分钟，真麻了</p><p>还有这操蛋的数据，非要用 R 语言下，结果下了半天发现不用下，下面记录一下自己是怎么解决这个问题的。</p><p>我遇到了与下面这个博主一模一样的问题：<br><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2FwcGxlXzc0MDU3ODM2L2FydGljbGUvZGV0YWlscy8xNDA3NzMzNDA=">网站</span></p><p>我甚至遇到的问题要更严重一点，可以看到这名博主的 snapshotDate 是：2024-04-29<br>然而我遇到的是<img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/STAGATE19.png" alt=""><br>显然这个博主的链接时挂掉了，我重新尝试下载这个链接的内容发现没有办法下载，然而这个更新内容居然是直接把 spe 的数据链接更改成了 sce 的数据链接，也就是说从 Spatial 的数据变成了 Single Cell 的数据，然后最恶心的是这个 Single Cell 的数据是提供下载的，但是没有提供如何将这个数据转换成 Spatial 数据的方式，我摸索了半天，由于不会 R 语言只得放弃转换 Single Cell 数据这条路。</p><p>然后我便查阅这个所谓的 fetch_data 是怎么运行的，于是在运行</p><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">?</span>fetch_data</span><br></pre></td></tr></table></figure><p>后我来到了这个网页看到了这一段话</p><blockquote><p>The initial version of spatialLIBD downloaded data only from <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0xpZWJlckluc3RpdHV0ZS9IdW1hblBpbG90">https://github.com/LieberInstitute/HumanPilot</span>.</p></blockquote><p>结果，踏破铁鞋无觅处，得来全不费工夫，它实际上是直接提供了 spatial 数据的：</p><p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0xpZWJlckluc3RpdHV0ZS9IdW1hblBpbG90L3RyZWUvbWFzdGVyLzEwWC8xNTE2NzY=">网址</span></p><p>事实上对于 spatial 文件夹的数据中的 csv 文件，也可以通过 python 去转换 txt 中的数据得到</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文件路径</span></span><br><span class="line">txt_file = <span class="string">&quot;tissue_positions_list.txt&quot;</span></span><br><span class="line">csv_file = <span class="string">&quot;tissue_positions_list.csv&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取 txt 文件，假设以逗号分隔</span></span><br><span class="line">df = pd.read_csv(txt_file, header=<span class="literal">None</span>)  <span class="comment"># 默认没有表头</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存为 CSV 文件</span></span><br><span class="line">df.to_csv(csv_file, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>对于 h5ad 的数据可以在 spatialLIBD 网站中直接下载获取，对于 groud_truth 数据也可以提供的网站中下载，这里就不赘述了</p><hr><p>在运行 pyG 的代码时出现了莫名其妙的错误，它提示我的图（意思是节点的引用超出了它本身的限制）有问题，</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">InternalError: Error at src/constructors/basic_constructors.c:75: Invalid (negative or too large) vertex ID. -- Invalid vertex ID</span><br></pre></td></tr></table></figure><p>于是我转回到 tensorflow 的那个版本去运行，结果发现版本太高了</p><p>下面是解决方案：<br><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1FJRkVJREtOL1NUQUdBVEUvaXNzdWVzLzIx">网站</span></p><p>结果无论是 pyG 的代码还是 tensorflow 的代码，始终没有办法解决图的问题，我使用了我找的数据和网上给出的数据都没有办法解决这个问题，后面再看看是怎么回事吧。</p><p>而且很奇怪的是 pyG 给出来的结果远远优于 tensorFlow 的结果，即便代码有差异也不应该差别这么大，例如 pyG 的 ARI=0.61 而 tensorflow 的仅有 0.44</p><p>这个文章现在复现了 1/10，各种问题层出不穷，光是找 DLFPC 的数据就花了好几天，这论文感觉有点管杀不管埋，有点逆天。</p><hr><p>先在 tensorflow 上跑的代码，感觉效果不好，等 pyG 整理好了去 pyG 跑一次</p><p>整理 pyG 时最开始用的是支持 GPU 的版本，结果调了半天 torch-sparse 总是不对，后来换成 CPU 的版本就行了，可能是我自己电脑的问题吧</p><p>整理完 pyG 发现跑不了这个模块的代码，理由是虽然本质上 pyG 和 tensorflow 版本是同一方法的不同实现，但是它的接口的变量没有同一，例如在 tensorflow 又 attention 的变量，但在 pyG 中没有设置，这真是管杀不管埋了，其实想要这个变量也很简单，重新写一下它 pyG 的代码就行了，但我现在只想快点结束这坨屎山代码，就不弄了，原理什么的已经很清楚了。</p><p>后面的几个 tutorial 有点不想弄了，本质上就是那几个函数在那捣鼓，具体看看 3D sptial domain 和 denoising 就暂时不弄了，反正毕业设计还得回来看。</p><p>不做了，弄下一篇去了，感觉继续复现下去也没有意义。</p><div class="tags"><a href="/tags/%E7%94%9F%E7%89%A9/" rel="tag"><i class="ic i-tag"></i> 生物</a> <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E7%B1%BB/" rel="tag"><i class="ic i-tag"></i> 学习笔记类</a> <a href="/tags/%E7%AE%97%E6%B3%95/" rel="tag"><i class="ic i-tag"></i> 算法</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2025-04-30 10:51:14" itemprop="dateModified" datetime="2025-04-30T10:51:14+08:00">2025-04-30</time> </span><span id="article/STAGATE/" class="item leancloud_visitors" data-flag-title="STAGATE" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>Lemon Sour <i class="ic i-at"><em>@</em></i></li><li class="link"><strong>本文链接：</strong> <a href="http://amentiraz.github.io/article/STAGATE/" title="STAGATE">http://amentiraz.github.io/article/STAGATE/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC96aC1DTg=="><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/note/%E6%94%BB%E5%A3%B3%E6%9C%BA%E5%8A%A8%E9%98%9FSAC/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;amentirazblogpic.oss-cn-hangzhou.aliyuncs.com&#x2F;blogpic&#x2F;%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925162904.jpg" title="攻壳机动队SAC"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 动漫</span><h3>攻壳机动队SAC</h3></a></div><div class="item right"><a href="/code/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;amentirazblogpic.oss-cn-hangzhou.aliyuncs.com&#x2F;blogpic&#x2F;%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925162851.png" title="PyTorch学习笔记"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> PyTorch</span><h3>PyTorch学习笔记</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#introduction"><span class="toc-number">2.</span> <span class="toc-text">introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#results"><span class="toc-number">3.</span> <span class="toc-text">Results</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#overview-of-stagate"><span class="toc-number">3.1.</span> <span class="toc-text">Overview of STAGATE</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#stagate-improves-the-identification-of-known-layers-on-the-human-dorsolateral-prefrontal-cortex"><span class="toc-number">3.2.</span> <span class="toc-text">STAGATE improves the identification of known layers on the human dorsolateral prefrontal cortex</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#stagate-enables-the-identification-of-tissue-structures-from-st-data-of-different-spatial-resolutions"><span class="toc-number">3.3.</span> <span class="toc-text">STAGATE enables the identification of tissue structures from ST data of different spatial resolutions.</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#attention-mechanism-and-cell-type-aware-module-help-to-better-charaterize-the-similarity-between-neighboring-spots"><span class="toc-number">3.4.</span> <span class="toc-text">Attention mechanism and cell type-aware module help to better charaterize the similarity between neighboring spots.</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#stagate-denoises-gene-expressions-for-better-characterizing-spatial-expression-patterns"><span class="toc-number">3.5.</span> <span class="toc-text">STAGATE denoises gene expressions for better characterizing spatial expression patterns.</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#violin-plot-%E7%9A%84%E7%BB%93%E6%9E%84"><span class="toc-number">3.5.1.</span> <span class="toc-text">Violin Plot 的结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#violin-plot-%E7%9A%84%E7%94%A8%E9%80%94"><span class="toc-number">3.5.2.</span> <span class="toc-text">Violin Plot 的用途</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#violin-plot-%E4%B8%8E%E5%85%B6%E4%BB%96%E5%9B%BE%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">3.5.3.</span> <span class="toc-text">Violin Plot 与其他图的区别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#the-usage-of-3d-snn-leads-to-better-extrction-of-3d-sptial-patterns"><span class="toc-number">3.6.</span> <span class="toc-text">The usage of 3D SNN leads to better extrction of 3D sptial patterns</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#discussion"><span class="toc-number">4.</span> <span class="toc-text">Discussion</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#methods"><span class="toc-number">5.</span> <span class="toc-text">Methods</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#construction-of-snn"><span class="toc-number">5.1.</span> <span class="toc-text">Construction of SNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#construction-of-cell-type-aware-snnoptional"><span class="toc-number">5.2.</span> <span class="toc-text">Construction of cell type-aware SNN(optional)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%8F%82%E6%95%B0%E5%85%B1%E4%BA%AB%E5%87%8F%E5%B0%91%E4%BA%86%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%87%AA%E7%94%B1%E5%BA%A6"><span class="toc-number">5.2.1.</span> <span class="toc-text">1. 参数共享减少了模型的自由度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%AF%B9%E7%A7%B0%E6%80%A7%E5%81%87%E8%AE%BE"><span class="toc-number">5.2.2.</span> <span class="toc-text">2. 对称性假设</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%90%86%E8%AE%BA%E6%94%AF%E6%8C%81"><span class="toc-number">5.2.3.</span> <span class="toc-text">3. 理论支持</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%AE%9E%E8%B7%B5%E6%95%88%E6%9E%9C"><span class="toc-number">5.2.4.</span> <span class="toc-text">4. 实践效果</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-stagate-%E7%9A%84%E7%89%B9%E6%AE%8A%E6%80%A7"><span class="toc-number">5.2.5.</span> <span class="toc-text">5. STAGATE 的特殊性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#identifying-differential-expressed-genes"><span class="toc-number">5.3.</span> <span class="toc-text">Identifying differential expressed genes</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E6%AD%A5%E9%AA%A4"><span class="toc-number">5.3.1.</span> <span class="toc-text">算法步骤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">5.3.2.</span> <span class="toc-text">核心思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">5.3.3.</span> <span class="toc-text">适用场景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8E%E5%85%B6%E4%BB%96%E6%96%B9%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-number">5.3.4.</span> <span class="toc-text">与其他方法的比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B"><span class="toc-number">5.3.5.</span> <span class="toc-text">示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">5.3.6.</span> <span class="toc-text">结论</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#identification-of-3d-spatial-domains-using-stagate"><span class="toc-number">5.4.</span> <span class="toc-text">Identification of 3D spatial domains using STAGATE</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-number">6.</span> <span class="toc-text">代码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#xavier-initialization"><span class="toc-number">6.0.1.</span> <span class="toc-text">Xavier Initialization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#nninitxavier_normal_-%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">6.0.2.</span> <span class="toc-text">nn.init.xavier_normal_ 的工作原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E7%AD%BE%E5%90%8D"><span class="toc-number">6.0.3.</span> <span class="toc-text">函数签名</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%82%E6%95%B0"><span class="toc-number">6.0.3.1.</span> <span class="toc-text">参数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B"><span class="toc-number">6.0.4.</span> <span class="toc-text">使用示例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-number">6.0.5.</span> <span class="toc-text">在模型中的应用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#xavier-initialization-%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="toc-number">6.0.6.</span> <span class="toc-text">Xavier Initialization 的优势</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%86%E8%A7%A3%E8%A7%A3%E6%9E%90"><span class="toc-number">6.0.7.</span> <span class="toc-text">拆解解析：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B4%E8%A7%82%E7%A4%BA%E4%BE%8B"><span class="toc-number">6.0.8.</span> <span class="toc-text">直观示例：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B"><span class="toc-number">6.0.8.1.</span> <span class="toc-text">计算过程：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">6.0.9.</span> <span class="toc-text">总结：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#messagepassing-%E7%9A%84%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6"><span class="toc-number">6.0.10.</span> <span class="toc-text">MessagePassing 的核心机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#messagepassing-%E7%9A%84%E6%A0%B8%E5%BF%83%E6%96%B9%E6%B3%95"><span class="toc-number">6.0.11.</span> <span class="toc-text">MessagePassing 的核心方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%88%9D%E5%A7%8B%E5%8C%96__init__"><span class="toc-number">6.0.11.1.</span> <span class="toc-text">1. 初始化： __init__</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E6%B6%88%E6%81%AF%E4%BC%A0%E6%92%ADpropagate"><span class="toc-number">6.0.11.2.</span> <span class="toc-text">2. 消息传播： propagate</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E6%B6%88%E6%81%AF%E7%94%9F%E6%88%90message"><span class="toc-number">6.0.11.3.</span> <span class="toc-text">3. 消息生成： message</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E6%B6%88%E6%81%AF%E8%81%9A%E5%90%88aggregate"><span class="toc-number">6.0.11.4.</span> <span class="toc-text">4. 消息聚合： aggregate</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-%E6%9B%B4%E6%96%B0update"><span class="toc-number">6.0.11.5.</span> <span class="toc-text">5. 更新： update</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E7%A4%BA%E4%BE%8B%E8%87%AA%E5%AE%9A%E4%B9%89-gcn"><span class="toc-number">6.0.12.</span> <span class="toc-text">完整示例：自定义 GCN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%94%A8%E6%B3%95"><span class="toc-number">6.0.13.</span> <span class="toc-text">常见用法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%8F%82%E6%95%B0%E7%9A%84%E6%9D%A5%E6%BA%90%E5%92%8C%E5%90%AB%E4%B9%89"><span class="toc-number">6.0.14.</span> <span class="toc-text">1. 参数的来源和含义</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-x_j"><span class="toc-number">6.0.14.1.</span> <span class="toc-text">(1) x_j</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-alpha_j"><span class="toc-number">6.0.14.2.</span> <span class="toc-text">(2) alpha_j</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-alpha_i"><span class="toc-number">6.0.14.3.</span> <span class="toc-text">(3) alpha_i</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E5%85%B6%E4%BB%96%E5%8F%82%E6%95%B0"><span class="toc-number">6.0.14.4.</span> <span class="toc-text">(4) 其他参数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%87%AA%E5%8A%A8%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0%E7%9A%84%E6%9C%BA%E5%88%B6"><span class="toc-number">6.0.15.</span> <span class="toc-text">2. 自动传递参数的机制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-selfpropagate-%E8%B0%83%E7%94%A8%E4%B8%AD%E7%9A%84%E5%8F%82%E6%95%B0%E5%8C%B9%E9%85%8D"><span class="toc-number">6.0.15.1.</span> <span class="toc-text">(1) self.propagate 调用中的参数匹配</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E8%87%AA%E5%8A%A8%E8%A7%A3%E5%8C%85"><span class="toc-number">6.0.15.2.</span> <span class="toc-text">(2) 自动解包</span></a></li></ol></li></ol></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#tutorial-1-10x-visiumdlpfc-dataset"><span class="toc-number">7.</span> <span class="toc-text">Tutorial 1： 10x Visium（DLPFC dataset）</span></a></li></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/article/scRNA%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" rel="bookmark" title="scRNA论文笔记">scRNA论文笔记</a></li><li><a href="/article/What-is-A-Cell-Type/" rel="bookmark" title="What_is_A_Cell_Type">What_is_A_Cell_Type</a></li><li><a href="/article/Cell-Review-What-is-a-cell-type-and-how-to-define-it/" rel="bookmark" title="Cell_Review_What_is_a_cell_type_and_how_to_define_it">Cell_Review_What_is_a_cell_type_and_how_to_define_it</a></li><li><a href="/article/Benchmarking-spatial-claustering-methods-with-spatially-resolved-transcriptomic-data/" rel="bookmark" title="Benchmarking-spatial-claustering-methods-with-spatially-resolved-transcriptomic-data">Benchmarking-spatial-claustering-methods-with-spatially-resolved-transcriptomic-data</a></li><li><a href="/article/%E8%AE%BA%E6%96%87ppt1/" rel="bookmark" title="论文ppt1">论文ppt1</a></li><li><a href="/article/Matching-Anything-by-Segmenting-Anything/" rel="bookmark" title="Matching_Anything_by_Segmenting_Anything">Matching_Anything_by_Segmenting_Anything</a></li><li><a href="/article/SpaGCN/" rel="bookmark" title="SpaGCN">SpaGCN</a></li><li class="active"><a href="/article/STAGATE/" rel="bookmark" title="STAGATE">STAGATE</a></li><li><a href="/article/MENDER/" rel="bookmark" title="MENDER">MENDER</a></li><li><a href="/article/scanpy%E6%95%B0%E6%8D%AE%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/" rel="bookmark" title="scanpy数据使用笔记">scanpy数据使用笔记</a></li><li><a href="/article/BayesSpace/" rel="bookmark" title="BayesSpace">BayesSpace</a></li><li><a href="/article/%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%B0%E5%BD%95/" rel="bookmark" title="数据集记录">数据集记录</a></li><li><a href="/article/DeepST/" rel="bookmark" title="DeepST">DeepST</a></li><li><a href="/article/EnSDD/" rel="bookmark" title="EnSDD">EnSDD</a></li><li><a href="/article/domain%E5%86%85%E5%AE%B9%E7%9A%84%E6%80%BB%E7%BB%93/" rel="bookmark" title="对spatial domain内容的总结">对spatial domain内容的总结</a></li><li><a href="/article/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3%E6%B1%87%E6%80%BB/" rel="bookmark" title="毕业设计文档汇总">毕业设计文档汇总</a></li><li><a href="/article/scPerturb/" rel="bookmark" title="scPerturb">scPerturb</a></li><li><a href="/GEARS/" rel="bookmark" title="GEARS">GEARS</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Lemon Sour" data-src="/images/avatar.jpg"><p class="name" itemprop="name">Lemon Sour</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">83</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">26</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">57</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL0FtZW50aXJheg==" title="https:&#x2F;&#x2F;github.com&#x2F;Amentiraz"><i class="ic i-github"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9kc2ZseS04" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;dsfly-8"><i class="ic i-zhihu"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTE1MTc2ODUzMzM=" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;1517685333"><i class="ic i-cloud-music"></i></span> <span class="exturl item email" data-url="bWFpbHRvOnZpb2xlbW9uQDE2My5jb20=" title="mailto:violemon@163.com"><i class="ic i-envelope"></i></span> <span class="exturl item bangumi" data-url="aHR0cHM6Ly9iYW5ndW1pLnR2L2FuaW1lL2xpc3QvNjY4MDE2" title="https:&#x2F;&#x2F;bangumi.tv&#x2F;anime&#x2F;list&#x2F;668016"><i class="ic i-bilibili"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-magic"></i>关于</a><ul class="submenu"><li class="item"><a href="/author/" rel="section"><i class="ic i-user"></i>本人</a></li></ul></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-cloud"></i>其它</a><ul class="submenu"><li class="item"><a href="/music/" rel="section"><i class="ic i-music"></i>音乐区</a></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>朋友</a></li></ul></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/note/%E6%94%BB%E5%A3%B3%E6%9C%BA%E5%8A%A8%E9%98%9FSAC/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/code/PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/article/" title="分类于 论文">论文</a></div><span><a href="/GEARS/" title="GEARS">GEARS</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/life/" title="分类于 生活">生活</a> <i class="ic i-angle-right"></i> <a href="/categories/life/%E6%97%85%E6%B8%B8/" title="分类于 旅游">旅游</a></div><span><a href="/life/%E9%87%8D%E5%BA%86%E4%B9%8B%E6%97%85/" title="重庆之旅">重庆之旅</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/code/" title="分类于 代码">代码</a> <i class="ic i-angle-right"></i> <a href="/categories/code/OI/" title="分类于 OI">OI</a></div><span><a href="/code/DP/" title="DP">DP</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/life/" title="分类于 生活">生活</a> <i class="ic i-angle-right"></i> <a href="/categories/life/%E6%BC%94%E5%A5%8F%E4%BC%9A/" title="分类于 演奏会">演奏会</a></div><span><a href="/life/MeetingJazz2025-04-26/" title="MeetingJazz2025-04-26">MeetingJazz2025-04-26</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/article/" title="分类于 论文">论文</a></div><span><a href="/article/DeepST/" title="DeepST">DeepST</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/life/" title="分类于 生活">生活</a> <i class="ic i-angle-right"></i> <a href="/categories/life/%E6%BC%94%E5%A5%8F%E4%BC%9A/" title="分类于 演奏会">演奏会</a></div><span><a href="/life/%E8%A7%92%E9%93%9C%E7%9C%9F%E5%AE%9E%E9%9F%B3%E4%B9%90%E4%BC%9A/" title="角铜真实音乐会">角铜真实音乐会</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/code/" title="分类于 代码">代码</a> <i class="ic i-angle-right"></i> <a href="/categories/code/OI/" title="分类于 OI">OI</a></div><span><a href="/code/Tarjan/" title="Tarjan">Tarjan</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/life/" title="分类于 生活">生活</a> <i class="ic i-angle-right"></i> <a href="/categories/life/%E6%80%9D%E8%80%83/" title="分类于 思考">思考</a></div><span><a href="/life/%E6%80%9D%E6%83%B3%E7%82%B9%E6%BB%B4/" title="思想点滴">思想点滴</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/life/" title="分类于 生活">生活</a> <i class="ic i-angle-right"></i> <a href="/categories/life/%E6%80%9D%E8%80%83/" title="分类于 思考">思考</a></div><span><a href="/life/%E5%AF%B9LGBT%E7%9A%84%E6%80%9D%E8%80%83/" title="对LGBT的思考">对LGBT的思考</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/article/" title="分类于 论文">论文</a> <i class="ic i-angle-right"></i> <a href="/categories/article/data/" title="分类于 data">data</a></div><span><a href="/article/%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%B0%E5%BD%95/" title="数据集记录">数据集记录</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Lemon Sour @ Amentiraz</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"article/STAGATE/",favicon:{show:"⁽⁽ଘ( ˊᵕˋ )ଓ⁾⁾",hide:"(つд⊂)"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,copy_tex:!0,katex:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->
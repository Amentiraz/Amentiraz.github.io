<!-- build time:Wed Jul 23 2025 15:58:45 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" href="http://amentiraz.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" href="http://amentiraz.github.io/atom.xml"><link rel="alternate" type="application/json" href="http://amentiraz.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="学习笔记类,计算机视觉"><link rel="canonical" href="http://amentiraz.github.io/article/Matching-Anything-by-Segmenting-Anything/"><title>Matching_Anything_by_Segmenting_Anything - 论文 | Amentiraz =</title><meta name="generator" content="Hexo 7.3.0"><script src="/assets/js/DPlayer.min.js"></script></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">Matching_Anything_by_Segmenting_Anything</h1><div class="meta"><span class="item" title="创建时间：2024-11-01 10:02:09"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2024-11-01T10:02:09+08:00">2024-11-01</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>41k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>37 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Amentiraz</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925162904.jpg"></li><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925162946.png"></li><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925162923.png"></li><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925162815.png"></li><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925124354.jpg"></li><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925162951.png"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/article/" itemprop="item" rel="index" title="分类于 论文"><span itemprop="name">论文</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://amentiraz.github.io/article/Matching-Anything-by-Segmenting-Anything/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Lemon Sour"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content=""></span><div class="body md" itemprop="articleBody"><p>小毕设要求实现的论文，还挺新<br>这是<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC83MDQ1MzMxNzY=">知乎上的归纳总结</span>，本文基本不会参考知乎上的那篇，准备先自己理解总结一遍再看看其他人怎么写的<br>原文地址和代码知乎上都有引用</p><span id="more"></span><h1 id="abstract"><a class="anchor" href="#abstract">#</a> Abstract</h1><p>Current methods predominantly rely on labeled domain-specific video datasets,which limits the cross-domain generalization of learned similarity embeddings.</p><p>MASA, a novel method for robust instance association learning, acapable of mathching any objects within videos across diverse domains without tracking labels.</p><p>它的算法大致是用 SAM 先跑个输出域，然后利用它设计的算法 MASA 去跟踪，这种联合的算法不需要先前目标示例，意思是即使在从未见过目标的情况下也能跟踪他，而且效果比标记的数据更好。</p><p>研究的问题是<strong> Multiple Object Tracking (MOT)</strong></p><h1 id="introduction"><a class="anchor" href="#introduction">#</a> Introduction</h1><p>先描述了一下现有方法的局限性：需要标注，普遍能力不强</p><p>他们模型的目标是设计一个方法能够匹配各种物体 (objects) 和领域 (regions)，然后叫这种方法与其它图像检测与分割的方法结合，帮助它们检测跟踪的目标</p><p>它们利用了 SAM 得到的丰富的物体外表特征与形状信息，使其与 extensive data transformation 结合，得到了很强的实例相关性</p><p><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/MatchingAnythingbySegementAnything1.jpg" alt=""></p><p>MASA adapter empowers the foundational models to track any objects they have detected, and show zero-shot tracking ability in complex domains.</p><p>Applying different geometric transformations to the same image gives automatic pixel-level correspondence in two views from the same image.</p><p>SAM's segmentation ability allows for the automatic grouping of pixels from the same instance, facilitating he conversion of pixel-levek to instance-levek correspondence.</p><p>根据上面两行的操作我们得到了一个 self-training pipeline，然后利用定义的 Adapter：MASA 去追踪检测到的物体。</p><p>更进一步，提出了一个 multi-task training pipeline that jointly performs the distillation of SAM's detection knowledge and instance similarity learing.</p><p>最后他们做了个 benchmark，体现出他们模型卓越的性能。</p><h1 id="related-work"><a class="anchor" href="#related-work">#</a> Related Work</h1><h2 id="learning-instance-level-association"><a class="anchor" href="#learning-instance-level-association">#</a> Learning Instance-level Association</h2><p>目前的方法分为 self-supervised 和 supervised 的策略，self-supervisied 的方法不能完整的开发出实例层面的数据，然而 supervised 的方法依赖于大量标记的数据，我们的方法 shows exceptional zero-shot association ability across diverse domains</p><h2 id="segment-and-track-anythin-models"><a class="anchor" href="#segment-and-track-anythin-models">#</a> Segment and Track Anythin Models</h2><p>在分割和追踪的方法中，例如 Deva,TAM and SAM-Track 等等，都面临 limitations，例如 poor mask progation quality due to domain gaps and the inability to handle multiple diverse objects or rapid objects entry and exit, common in scenarios like autonomous driving.</p><p>我们的方法聚焦于学习 universal association modules by leveraging SAM's rich instance segmentation knowledge.</p><h1 id="method"><a class="anchor" href="#method">#</a> Method</h1><h2 id="preliminaries-sam"><a class="anchor" href="#preliminaries-sam">#</a> Preliminaries: SAM</h2><p>SAM is composed of three modules:</p><ol><li><p>A heavy ViT-based backbone for feature extraction.(ViT-based backbone 是指使用 Vison Transformer 作为主干网络来提取图像特征的结构。ViT 是一种基于 Transformer 的视觉模型，最初由 Google 提出，它将图像分割为小块 (patches)，然后像处理序列数据一样，通过 Transformer 结构进行特征提取)</p></li><li><p>Prompt encoder: Modeling the positional information from the interactive points, box, or mask prompts.(这里是指多模态体现，可以接受不同类型的用户输入提示来指定需要分割的对象包括（点提示、框提示、文本提示，SAM 会将这些提示转化为 “提示嵌入”，并与图像嵌入结合，从而帮助模型定位并分割出目标区域。)</p></li><li><p>Mask decoder: A transformer-based decoder takes both the extracted image embedding with the concatenated output and prompt tokens for final mask prediction.（结合图像嵌入和提示嵌入并生成分割掩码）</p></li></ol><h2 id="matching-anythin-by-segmenting-anything"><a class="anchor" href="#matching-anythin-by-segmenting-anything">#</a> Matching Anythin by Segmenting Anything</h2><p>Our methods consists of two key components</p><ol><li><p>基于 SAM，我们得到了一个新的 pipeline:MASA，通过这个 pipeline，我们构建了一个为了 dense instance-level correspondence from a rich collection of unlabeled images 的彻底的监督方式。</p></li><li><p>我们构建了一个具有普遍性的 MASA adapter，使得能有效地 transform the features from a frozen detection or segmentation backbone for learning generalizable instance appearance representation.</p></li></ol><p>Byproduct: the distillation branch of the MASA adapter can also significantly improve the efficiency of segmenting everything.</p><h3 id="masa-pipeline"><a class="anchor" href="#masa-pipeline">#</a> MASA Pipeline</h3><p>现有的方法在复杂域的多实例的数据中分辨实例的表现并不好，为了解决这个问题提出了 MASA training pipeline。</p><p>核心的目标是增加两个方面的多样性：</p><ol><li>training image diversity</li><li>instance diversity</li></ol><p>我们通过两种不同的增强模拟了视频中外观的变化，得到了两种不同的视角</p>\begin{equation} \mathcal{L}_{\mathcal{C}}=-\sum_{q \in Q} \log \frac{e^{\frac{\operatorname{sim}\left(q, q^{+}\right)}{\tau}}}{e^{\frac{\operatorname{sim}\left(q, q^{+}\right)}{\tau}}+\sum_{q^{-} \in Q^{-}} e^{\frac{\operatorname{sim}\left(q, q^{-}\right)}{\tau}}}, \end{equation}<p>Here，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo>+</mo></mrow><annotation encoding="application/x-tex">{q+}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7777700000000001em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mord">+</span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo>−</mo></mrow><annotation encoding="application/x-tex">{q-}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7777700000000001em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">q</span><span class="mord">−</span></span></span></span></span> denote the positive and negative samples to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">{q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">q</span></span></span></span></span>, respectively. Positive samples are the same instance proposals being applied different <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">{\phi}({\cdot})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal">ϕ</span></span><span class="mopen">(</span><span class="mord"><span class="mord">⋅</span></span><span class="mclose">)</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>φ</mi><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">{\varphi}({\cdot})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal">φ</span></span><span class="mopen">(</span><span class="mord"><span class="mord">⋅</span></span><span class="mclose">)</span></span></span></span>. Negative samples are from different instances. Furthermore, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mo lspace="0em" rspace="0em">⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">sim({\cdot})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">m</span><span class="mopen">(</span><span class="mord"><span class="mord">⋅</span></span><span class="mclose">)</span></span></span></span> denotes the cosine similarity and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">{\tau}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.1132em">τ</span></span></span></span></span> is a temperature parameter, set to 0.07 in our experiment.</p><p>This contrastive learning formula pushes object embeddings belonging to the same instance closer while distancing embeddings from different instances.</p><p><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/MatchingAnythingbySegmentingAnything2.png" alt=""></p><p>说实话看了半天没看懂这个 MASA Pipeline 想干嘛，感觉它写的也模模糊糊的，后面看看代码再理解一下。</p><h3 id="masa-adapter"><a class="anchor" href="#masa-adapter">#</a> MASA Adapter</h3><p>MASA Adapter 在 frozen backbone features 上进行操作，然而不是所有的预处理后的特征都能在追踪目标上面有良好的表现，所以我们首先将这些 frozen backbone features 转换成 new features more suitable for tracking.</p><p>为了有效地学习 discriminative features for diffetent instances，有必要让在一个位置上的物体认识到其它位置上物体的外观，因此，我们使用了 deformable convolution 去生成 dynamic offsets and aggregate information across spatial locations and feature levels as:</p>\begin{equation} F(\mathcal{p})=\frac{1}{L}\sum_{j=1}^{L}\sum_{k=1}^{K}\mathcal{w}_k \cdot F^j (\mathcal{p}+\mathcal{p}_k+\Delta \mathcal{p}_k^j)\cdot \Delta m_k^j \end{equation}<p>where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal">L</span></span></span></span> represents the feature level, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.07153em">K</span></span></span></span> is the number of sampling locations for a convolutional kernel, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">w_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:-.02691em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">p_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> are the weight and predefined offsetfor the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span></span></span></span>-th location respectively, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><msubsup><mi mathvariant="script">p</mi><mi>k</mi><mi>j</mi></msubsup></mrow><annotation encoding="application/x-tex">\Delta \mathcal{p}_k^j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2438799999999999em;vertical-align:-.3013079999999999em"></span><span class="mord">Δ</span><span class="mord"><span class="mord"><span class="mord mathnormal">p</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.942572em"><span style="top:-2.3986920000000005em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span><span style="top:-3.1809080000000005em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3013079999999999em"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><msubsup><mi mathvariant="script">m</mi><mi>k</mi><mi>j</mi></msubsup></mrow><annotation encoding="application/x-tex">\Delta \mathcal{m}_k^j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2438799999999999em;vertical-align:-.3013079999999999em"></span><span class="mord">Δ</span><span class="mord"><span class="mord"><span class="mord mathnormal">m</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.942572em"><span style="top:-2.3986920000000005em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span><span style="top:-3.1809080000000005em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3013079999999999em"><span></span></span></span></span></span></span></span></span></span> are the learnable offset and modulation factor for the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span></span></span></span>-th location at the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.85396em;vertical-align:-.19444em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span></span></span></span>-th feature level.</p><p>Object Prior Distillation 作为任务的辅助手段，使用 RCNN detection head 去学习对于每个 instance 包含 SAM's mask prediction 的 dounding boxes，加强了模型的精确度并提高了速度。</p><p>The MASA adapter is optimized using a combination of detection and contractive losses as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">L</mi><mo>=</mo><msub><mi mathvariant="script">L</mi><mrow><mi>d</mi><mi>e</mi><mi>t</mi></mrow></msub><mo>+</mo><msub><mi mathvariant="script">L</mi><mi mathvariant="script">C</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal{L}=\mathcal{L}_{det}+\mathcal{L}_{\mathcal{C}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord"><span class="mord mathcal">L</span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.33610799999999996em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.83333em;vertical-align:-.15em"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.32833099999999993em"><span style="top:-2.5500000000000003em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:.05834em">C</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>.</p><h3 id="inference"><a class="anchor" href="#inference">#</a> Inference</h3><p>Figure 3 shows the test pipeline with our unified models.<br><img data-src="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/MatchingAnythingbySegmentingAnything3.png" alt=""></p><h4 id="detect-and-track-anythin"><a class="anchor" href="#detect-and-track-anythin">#</a> Detect and Track Anythin</h4><p>Remove the MASA detection head that was learned during training. The MASA adapter then solely serves as a tracker.</p><p>We use a simple bi-softmax nearest neighbor search for accurate instance matching.</p><h4 id="segment-and-track-anything"><a class="anchor" href="#segment-and-track-anything">#</a> Segment and Track Anything</h4><p>With SAM, we keep the detection head.</p><h4 id="testing-with-given-observations"><a class="anchor" href="#testing-with-given-observations">#</a> Testing with Given Observations</h4><p>When detections are obtained from sources other than the one the MASA adapter is build upon, Our MASA adapter serves as a tracking feature provider.</p><h1 id="experiments"><a class="anchor" href="#experiments">#</a> Experiments</h1><p>这部分及以后的部分就不深入写了，对于课题要求的任务没有太大的关系，后面会详细写一下代码是怎么运行。</p><h1 id="代码部分"><a class="anchor" href="#代码部分">#</a> 代码部分</h1><h2 id="环境"><a class="anchor" href="#环境">#</a> 环境</h2><p>由于是第一次接触如此大规模 CV 的项目，重新搭建环境耗费了我两天共超过 20 个小时的时间，但在这个过程中也是理解了环境搭建的种种规则，对于 conda 的指令等等也是有了质的理解与提升。我也是第一次看到自己的电脑 CPU，内存倏的一下直接跑满。<br>下面的视频是跑出来的效果。可以看到实际跑出来的视频对比原视频大小缩小了 10 倍，效果也是比较好的。</p><div id="dplayer0" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom:20px"></div><script>!function(){var n=new DPlayer({container:document.getElementById("dplayer0"),theme:"#FADFA3",video:{url:"/article/Matching-Anything-by-Segmenting-Anything/minions_rush_out_outputs.mp4"}});window.dplayers||(window.dplayers=[]),window.dplayers.push(n)}()</script><p>效果可由迅雷下载查看</p><h2 id="代码"><a class="anchor" href="#代码">#</a> 代码</h2><h3 id="video_demo_with_text"><a class="anchor" href="#video_demo_with_text">#</a> video_demo_with_text</h3><p>这是程序调用的主函数，具体的调用指令如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python demo/video_demo_with_text.py demo/minions_rush_out.mp4 --out demo_outputs/minions_rush_out_outputs.mp4 --masa_config configs/masa-gdino/masa_gdino_swinb_inference.py --masa_checkpoint saved_models/masa_models/gdino_masa.pth --texts <span class="string">&quot;yellow_minions&quot;</span> --score-thr 0.2 --unified --show_fps</span><br></pre></td></tr></table></figure><p>可以看到它的官方对参数的介绍：</p><ul><li><code>--texts</code> : the object class you want to track. If there are multiple classes, separate them like this: <code>&quot;giraffe . lion . zebra&quot;</code> .</li><li><code>--out</code> : the output video path.</li><li><code>--score-thr</code> : the threshold for the visualize object confidence.</li><li><code>--detector_type</code> : the detector type. We support <code>mmdet</code> and <code>yolo-world</code> (soon).</li><li><code>--unified</code> : whether to use the unified model.</li><li><code>--postprocessing</code> : whether to use the postprocessing. (reduce the jittering effect caused by the detector.)</li><li><code>--show_fps</code> : whether to show the fps.</li><li><code>--sam_mask</code> : whether to visualize the mask results generated by SAM.</li><li><code>--fp16</code> : whether to use fp16 mode.</li></ul><p>由于我以前一直是写 C++、Java 和 Matlab 的，对 python 的语法并不是很熟悉，也算是为了以后自己的研究生生活，接下来我会利用通义千问和 ChatGPT 对代码逐块的进行解析：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">os.environ[<span class="string">&quot;TOKENIZERS_PARALLELISM&quot;</span>] = <span class="string">&quot;false&quot;</span></span><br><span class="line">project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), <span class="string">&#x27;..&#x27;</span>))</span><br><span class="line">sys.path.insert(<span class="number">0</span>, project_root)</span><br></pre></td></tr></table></figure><p><code>os.environ</code> 是一个字典，用于访问和修改环境变量。<br><code>TOKENIZERS_PARALLELISM</code> 是一个特定的环境变量，用于控制 <code>Hugging Face</code> 的 <code>transformers</code> 库中的 <code>tokenizer</code> 是否启用多线程并行处理。<br>将其设置为 <code>&quot;false&quot;</code> 可以禁用并行处理。这在某些情况下是有用的，例如在多进程环境中，为了避免资源竞争或过度消耗 <code>CPU</code> 资源。</p><p><code>os.path.dirname(__file__)</code> 获取当前脚本文件所在的目录的绝对路径。<br><code>os.path.join(os.path.dirname(__file__), '..')</code> 获取当前脚本文件所在目录的父目录的绝对路径。<br><code>os.path.abspath(...)</code> 将路径转换为绝对路径。<br><code>project_root</code> 变量存储了项目的根目录路径。<br><code>sys.path</code> 是一个列表，其中包含 Python 解释器在导入模块时会搜索的路径。<br><code>sys.path.insert(0, project_root)</code> 将项目的根目录插入到 <code>sys.path</code> 列表的最前面，这样在导入模块时，Python 会优先从这个目录中查找模块。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    set_start_method(<span class="string">&#x27;spawn&#x27;</span>)</span><br><span class="line"><span class="keyword">except</span> RuntimeError:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p><code>set_start_method</code> 是 <code>multiprocessing</code> 模块中的一个函数，用于设置创建子进程的方法。<br><code>'spawn'</code> 是一种启动方法，它会在新的进程中重新启动 <code>Python</code> 解释器，并且只传递必要的信息来运行目标函数。这种方法适用于所有平台，包括 <code>Windows</code> 和 <code>macOS</code> 。</p><p><code>pass</code> 关键字表示在捕获到异常时不做任何处理，只是简单地忽略该异常。(在第一次跑这个代码时，电脑由于开了太多的窗口，结果一跑起代码直接死机，拉都拉不回来，我估计就是这个原因)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">visualize_frame</span>(<span class="params">args, visualizer, frame, track_result, frame_idx, fps=<span class="literal">None</span></span>):</span><br><span class="line">    visualizer.add_datasample(</span><br><span class="line">        name=<span class="string">&#x27;video_&#x27;</span> + <span class="built_in">str</span>(frame_idx),</span><br><span class="line">        image=frame[:, :, ::-<span class="number">1</span>],</span><br><span class="line">        data_sample=track_result[<span class="number">0</span>],</span><br><span class="line">        draw_gt=<span class="literal">False</span>,</span><br><span class="line">        show=<span class="literal">False</span>,</span><br><span class="line">        out_file=<span class="literal">None</span>,</span><br><span class="line">        pred_score_thr=args.score_thr,</span><br><span class="line">        fps=fps,)</span><br><span class="line">    frame = visualizer.get_image()</span><br><span class="line">    gc.collect()</span><br><span class="line">    <span class="keyword">return</span> frame</span><br></pre></td></tr></table></figure><ol><li><p><strong>调用 <code>visualizer.add_datasample</code> 方法</strong>:</p><ul><li>将当前帧的编号 <code>frame_idx</code> 作为名称，格式为 <code>'video_' + str(frame_idx)</code> 。</li><li>提供当前帧的图像数据 <code>frame</code> 给 <code>image</code> 参数，这里 <code>frame[:, :, ::-1]</code> 是将图像从 BGR 格式转换为 RGB 格式，因为 OpenCV 默认读取的图像是 BGR 格式的，而许多显示或处理函数需要的是 RGB 格式。</li><li>通过 <code>data_sample</code> 参数传递跟踪结果 <code>track_result[0]</code> ，这通常包含了在当前帧中检测到的对象及其位置信息。</li><li>设置 <code>draw_gt</code> 参数为 <code>False</code> ，意味着不会绘制真实标签（ground truth），通常用于预测或测试阶段。</li><li><code>show</code> 参数设为 <code>False</code> 表示不立即显示图像，可能是因为图像会被进一步处理或者保存。</li><li><code>out_file</code> 参数设为 <code>None</code> 表明不会将图像直接保存到文件中。</li><li><code>pred_score_thr</code> 参数用于设置预测得分的阈值，只有当对象的置信度评分超过此阈值时，才会在图像中标记出来。这个值是从 <code>args</code> 参数中获取的， <code>args</code> 通常是一个包含多个配置项的对象。</li><li><code>fps</code> 参数可选地提供视频的帧率信息，这对于某些类型的可视化可能是有用的。</li></ul></li><li><p><strong>获取并返回处理后的图像</strong>:</p><ul><li>使用 <code>visualizer.get_image()</code> 获取经过上述操作后更新的图像。</li><li>返回这个图像，这样可以在函数外部继续使用或保存它。</li></ul></li><li><p><strong>垃圾回收</strong>:</p><ul><li>调用 <code>gc.collect()</code> 进行垃圾回收，释放不再使用的内存。虽然 Python 有自动的垃圾回收机制，但在处理大量数据或长时间运行的应用程序中，显式调用垃圾回收可以帮助管理内存，特别是在循环处理视频帧等场景下。</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_args</span>():</span><br><span class="line"></span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&#x27;MASA video demo&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;video&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Video file&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--det_config&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Detector Config file&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--masa_config&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Masa Config file&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--det_checkpoint&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Detector Checkpoint file&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--masa_checkpoint&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Masa Checkpoint file&#x27;</span>)</span><br><span class="line">    parser.add_argument( <span class="string">&#x27;--device&#x27;</span>, default=<span class="string">&#x27;cuda:0&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Device used for inference&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--score-thr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.2</span>, <span class="built_in">help</span>=<span class="string">&#x27;Bbox score threshold&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--out&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;Output video file&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save_dir&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, <span class="built_in">help</span>=<span class="string">&#x27;Output for video frames&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--texts&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;text prompt&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--line_width&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">5</span>, <span class="built_in">help</span>=<span class="string">&#x27;Line width&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--unified&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Use unified model, which means the masa adapter is built upon the detector model.&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--detector_type&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;mmdet&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Choose detector type&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--fp16&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Activation fp16 mode&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--no-post&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Do not post-process the results &#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--show_fps&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Visualize the fps&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--sam_mask&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Use SAM to generate mask for segmentation tracking&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--sam_path&#x27;</span>,  <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;saved_models/pretrain_weights/sam_vit_h_4b8939.pth&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Default path for SAM models&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--sam_type&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;vit_h&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;Default type for SAM models&#x27;</span>)</span><br><span class="line">    parser.add_argument(</span><br><span class="line">        <span class="string">&#x27;--wait-time&#x27;</span>,</span><br><span class="line">        <span class="built_in">type</span>=<span class="built_in">float</span>,</span><br><span class="line">        default=<span class="number">1</span>,</span><br><span class="line">        <span class="built_in">help</span>=<span class="string">&#x27;The interval of show (s), 0 is block&#x27;</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    <span class="keyword">return</span> args</span><br></pre></td></tr></table></figure><p>这段代码实现的功能和上面提到的参数的功能差不多</p><p><code>parser.add_argument</code> 用于添加一个命令行参数。<br><code>help</code> 参数提供了该参数的简要说明。<br><code>default</code> 参数指定了该参数的默认值。<br><code>type</code> 参数指定了该参数的类型（如 <code>str</code> 、 <code>int</code> 、 <code>float</code> ）。<br><code>action='store_true'</code> 表示这是一个布尔标志，如果在命令行中出现该参数，则其值为 <code>True</code> ，否则为 <code>False</code> 。</p><p><code>parser.parse_args()</code> 解析命令行参数，并将它们存储在 args 对象中。<br><code>return args</code> 返回解析后的参数对象，以便在其他部分的代码中使用这些参数。</p><p>接下来就是 main 函数了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">args = parse_args()</span><br><span class="line">    <span class="keyword">assert</span> args.out, \</span><br><span class="line">        (<span class="string">&#x27;Please specify at least one operation (save the &#x27;</span></span><br><span class="line">         <span class="string">&#x27;video) with the argument &quot;--out&quot; &#x27;</span>)</span><br></pre></td></tr></table></figure><p>这行代码使用 assert 语句来确保 args.out 不为空。assert 语句的基本语法是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span> condition, message</span><br></pre></td></tr></table></figure><p><code>condition</code> 是一个布尔表达式，如果为 <code>False</code> ，则会引发 <code>AssertionError</code> 。<br><code>message</code> 是一个字符串，当 <code>condition</code> 为 <code>False</code> 时，会作为错误消息的一部分打印出来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># build the model from a config file and a checkpoint file</span></span><br><span class="line">    <span class="keyword">if</span> args.unified:</span><br><span class="line">        masa_model = init_masa(args.masa_config, args.masa_checkpoint, device=args.device)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        det_model = init_detector(args.det_config, args.det_checkpoint, palette=<span class="string">&#x27;random&#x27;</span>, device=args.device)</span><br><span class="line">        masa_model = init_masa(args.masa_config, args.masa_checkpoint, device=args.device)</span><br><span class="line">        <span class="comment"># build test pipeline</span></span><br><span class="line">        det_model.cfg.test_dataloader.dataset.pipeline[</span><br><span class="line">            <span class="number">0</span>].<span class="built_in">type</span> = <span class="string">&#x27;mmdet.LoadImageFromNDArray&#x27;</span></span><br><span class="line">        test_pipeline = Compose(det_model.cfg.test_dataloader.dataset.pipeline)</span><br></pre></td></tr></table></figure><p>我们可以看到在我们调用这个 python 文件是，我们的参数为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">--masa_config configs/masa-gdino/masa_gdino_swinb_inference.py --masa_checkpoint saved_models/masa_models/gdino_masa.pth</span><br></pre></td></tr></table></figure><h4 id="masa_gdino_swinb_inference"><a class="anchor" href="#masa_gdino_swinb_inference">#</a> masa_gdino_swinb_inference</h4><p>这个 config 定义了一系列的参数，非常的复杂而且难以完全的掌握，所以我直接引用了 AI 生成的对于这个代码的解释：<br>这段代码配置了一个复杂的深度学习模型，特别是用于目标检测和跟踪的任务。它使用了 MMDetection 框架，并且定义了多个组件来构建一个完整的模型。接下来，我会逐行解释这段代码的主要部分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">_base_ = [</span><br><span class="line">    <span class="string">&#x27;../../projects/grounding_dino/grounding_dino_swin-b_pretrain_mixeddata_masa.py&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;../default_runtime.py&#x27;</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>这行代码指定了基础配置文件，这些文件包含了预设的模型结构、数据集配置等。 <code>_base_</code> 关键字允许继承其他配置文件中的设置。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">default_scope = <span class="string">&#x27;mmdet&#x27;</span></span><br></pre></td></tr></table></figure><p>设置默认的作用域为 <code>mmdet</code> ，即 MMDetection。这有助于确保所有组件都正确地注册在这个框架下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">detector = _base_.model</span><br><span class="line">detector.pop(<span class="string">&#x27;data_preprocessor&#x27;</span>)</span><br><span class="line">detector[<span class="string">&#x27;init_cfg&#x27;</span>] = <span class="built_in">dict</span>(</span><br><span class="line">    <span class="built_in">type</span>=<span class="string">&#x27;Pretrained&#x27;</span>,</span><br><span class="line">    checkpoint= <span class="string">&#x27;saved_models/tsa_models/groundingdino_swinb_cogcoor_mmdet-55949c9c.pth&#x27;</span></span><br><span class="line">)</span><br><span class="line">detector[<span class="string">&#x27;type&#x27;</span>] = <span class="string">&#x27;GroundingDINOMasa&#x27;</span></span><br></pre></td></tr></table></figure><p>这部分代码从基础配置中加载了模型（ <code>detector</code> ），然后移除了 <code>data_preprocessor</code> 字段，替换成预训练权重的初始化配置，并设置了模型类型为 <code>GroundingDINOMasa</code> 。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">del</span> _base_.model</span><br></pre></td></tr></table></figure><p>删除了基础配置中的 <code>model</code> 字段，因为已经将其赋值给了 <code>detector</code> 变量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = <span class="built_in">dict</span>(</span><br><span class="line">    ...</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>这是整个模型的配置字典，包含了所有组件的定义。例如：</p><ul><li><code>type='MASA'</code> 定义了模型的整体类型。</li><li><code>freeze_detector=True</code> 表示冻结检测器的参数，不进行更新。</li><li><code>unified_backbone=True</code> 表示使用统一的主干网络。</li><li><code>load_public_dets = False</code> 是否加载公共的检测结果。</li><li><code>data_preprocessor</code> 配置了数据预处理的方式，包括归一化、填充等。</li><li><code>detector</code> 是之前定义的检测器配置。</li><li><code>masa_adapter</code> 包含了特征金字塔网络 (FPN) 和变形融合 (DeformFusion) 模块的配置。</li><li><code>rpn_head</code> 和 <code>roi_head</code> 分别配置了区域提议网络 (RPN) 和 ROI 头，用于生成候选框和进行最终的目标检测。</li><li><code>track_head</code> 和 <code>tracker</code> 配置了跟踪相关的头部和追踪器。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">inference_pipeline = [</span><br><span class="line">    ...</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>定义了推理时的数据处理流程，如调整图像大小、打包输入等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># runtime settings</span></span><br><span class="line">train_cfg = <span class="literal">None</span></span><br><span class="line">val_cfg = <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ValLoop&#x27;</span>)</span><br><span class="line">test_cfg = <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;TestLoop&#x27;</span>)</span><br></pre></td></tr></table></figure><p>这些是运行时的配置，分别对应训练、验证和测试阶段。这里没有指定训练配置，而验证和测试则指定了循环类型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">default_hooks = <span class="built_in">dict</span>(</span><br><span class="line">    ...</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>定义了一些默认的回调函数，比如日志记录、可视化、检查点保存等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vis_backends = [<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;LocalVisBackend&#x27;</span>)]</span><br><span class="line">visualizer = <span class="built_in">dict</span>(</span><br><span class="line">    <span class="built_in">type</span>=<span class="string">&#x27;MasaTrackLocalVisualizer&#x27;</span>, vis_backends=vis_backends, name=<span class="string">&#x27;visualizer&#x27;</span>)</span><br></pre></td></tr></table></figure><p>配置了可视化的后端和可视化器，用于在训练过程中展示中间结果或调试信息。</p><h5 id="fpn"><a class="anchor" href="#fpn">#</a> FPN</h5><p>然而我还是没有办法理解这个代码，对于其中的某些定义我用 AI 生成了一下：<br>FPN（Feature Pyramid Network，特征金字塔网络）是一种用于计算机视觉任务（尤其是目标检测和分割）的通用架构。它通过构建一个金字塔式的多尺度特征图来提高模型对不同大小目标的检测能力。FPN 的核心思想是在不同层次上利用特征图的信息，从而在不同的尺度上增强特征表达。</p><p>FPN 的基本结构</p><ol><li><p><strong>底部到顶部的路径（Bottom-up Pathway）</strong>:</p><ul><li>这个路径通常由标准的卷积网络（如 ResNet）组成，负责提取原始输入图像的特征。随着网络深度的增加，特征图的分辨率逐渐降低，但语义信息逐渐增强。</li><li>每个卷积层输出的特征图可以看作是不同尺度上的特征表示，这些特征图构成了 FPN 的基础。</li></ul></li><li><p><strong>顶部到底部的路径（Top-down Pathway）</strong>:</p><ul><li>顶部到底部的路径通过自顶向下的方式逐步融合来自底部到顶部路径的特征图。具体来说，它从最高层次的特征图开始，通过上采样（通常是最近邻插值或双线性插值）将特征图恢复到更高的分辨率。</li><li>在每个层次上，上采样的特征图与相应层次的底部到顶部路径的特征图进行逐元素相加（或级联），形成新的特征图。</li></ul></li><li><p><strong>横向连接（Lateral Connections）</strong>:</p><ul><li>横向连接用于将底部到顶部路径的高分辨率、低语义级别的特征图与顶部到底部路径的低分辨率、高语义级别的特征图结合起来。</li><li>通常，横向连接会先对底部到顶部路径的特征图进行 1x1 卷积，以减少通道数并匹配顶部到底部路径的特征图的维度，然后再进行逐元素相加。</li></ul></li></ol><p>FPN 的工作流程</p><ol><li><p><strong>特征提取</strong>:</p><ul><li>使用标准的卷积网络（如 ResNet）提取多尺度的特征图。假设我们有四个特征图 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>C</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>4</mn></msub><mo separator="true">,</mo><msub><mi>C</mi><mn>5</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">( C_2, C_3, C_4, C_5 )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>C</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">( C_2 )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 具有最高的分辨率，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>C</mi><mn>5</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">( C_5 )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 具有最低的分辨率。</li></ul></li><li><p><strong>顶部到底部的路径</strong>:</p><ul><li>从最顶层的特征图 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>C</mi><mn>5</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">( C_5 )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 开始，通过 1x1 卷积减少通道数，得到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>P</mi><mn>5</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">( P_5 )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。</li><li>对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>P</mi><mn>5</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">( P_5 )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 进行上采样，使其分辨率与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>C</mi><mn>4</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">( C_4 )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 相同，然后与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>C</mi><mn>4</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">( C_4 )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.07153em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 通过 1x1 卷积后的特征图逐元素相加，得到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>P</mi><mn>4</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">( P_4 )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。</li><li>同样的过程继续，依次得到 $(P_3) $ 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>P</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">( P_2 )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。</li></ul></li><li><p><strong>最终特征图</strong>:</p><ul><li>最终得到的特征图 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>P</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>P</mi><mn>3</mn></msub><mo separator="true">,</mo><msub><mi>P</mi><mn>4</mn></msub><mo separator="true">,</mo><msub><mi>P</mi><mn>5</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">( P_2, P_3, P_4, P_5 )</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.13889em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 构成了一个特征金字塔，每个层次的特征图都具有不同的分辨率和语义信息。</li><li>这些特征图可以用于后续的检测或分割任务，每个层次的特征图适用于不同大小的目标。</li></ul></li></ol><h5 id="deformfusion"><a class="anchor" href="#deformfusion">#</a> DeformFusion</h5><p><code>DeformFusion</code> 是一种用于特征融合的模块，通常在计算机视觉任务中用于增强模型的特征表示能力。与传统的特征融合方法不同， <code>DeformFusion</code> 引入了可变形卷积（Deformable Convolution）的概念，使得特征融合过程更加灵活和适应性强。以下是对 <code>DeformFusion</code> 的详细解释：</p><ol><li>可变形卷积（Deformable Convolution）</li></ol><p>可变形卷积是传统卷积的一种扩展，它允许卷积核在特征图上的位置是动态变化的，而不是固定在规则的网格上。这种动态变化的位置由偏移量（offsets）来控制，偏移量是通过一个额外的卷积层学习得到的。可变形卷积的主要优点是能够更好地捕捉不规则形状的物体和特征，从而提高模型的鲁棒性和准确性。</p><ol start="2"><li>DeformFusion 的概念</li></ol><p><code>DeformFusion</code> 是一种结合了可变形卷积的特征融合模块，它的主要目的是在不同层次的特征图之间进行更有效的信息交换和融合。具体来说， <code>DeformFusion</code> 通过以下步骤实现特征融合：</p><pre><code>1. **输入特征图**:
</code></pre><ul><li><code>DeformFusion</code> 接受多个不同层次的特征图作为输入。这些特征图通常来自不同的卷积层，具有不同的分辨率和语义信息。</li></ul><pre><code>2. **可变形卷积**:
</code></pre><ul><li>使用可变形卷积对输入特征图进行处理。可变形卷积通过学习偏移量，使得卷积核可以在特征图上动态地选择关键区域，从而更好地捕捉不规则形状的特征。</li></ul><pre><code>3. **特征融合**:
</code></pre><ul><li>将经过可变形卷积处理后的特征图进行融合。常见的融合方法包括逐元素相加、级联（concatenation）等。通过融合，不同层次的特征图可以互补，增强整体的特征表示能力。</li></ul><ol start="3"><li>DeformFusion 的配置</li></ol><p>在你的代码中， <code>DeformFusion</code> 的配置如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">masa_adapter = [</span><br><span class="line">    <span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&#x27;FPN&#x27;</span>,</span><br><span class="line">        in_channels=[<span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>],</span><br><span class="line">        out_channels=<span class="number">256</span>,</span><br><span class="line">        norm_cfg=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;SyncBN&#x27;</span>, requires_grad=<span class="literal">True</span>),</span><br><span class="line">        num_outs=<span class="number">5</span>),</span><br><span class="line">    <span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&#x27;DeformFusion&#x27;</span>,</span><br><span class="line">        in_channels=<span class="number">256</span>,</span><br><span class="line">        out_channels=<span class="number">256</span>,</span><br><span class="line">        num_blocks=<span class="number">3</span>)</span><br><span class="line">]</span><br></pre></td></tr></table></figure><ul><li><p><strong>FPN</strong>:</p><ul><li><code>type='FPN'</code> 表示这是一个特征金字塔网络（Feature Pyramid Network）。</li><li><code>in_channels=[256, 512, 1024]</code> 表示输入特征图的通道数。</li><li><code>out_channels=256</code> 表示输出特征图的通道数。</li><li><code>norm_cfg=dict(type='SyncBN', requires_grad=True)</code> 表示使用同步批量归一化（SyncBN），并且参数是可训练的。</li><li><code>num_outs=5</code> 表示输出的特征图层数。</li></ul></li><li><p><strong>DeformFusion</strong>:</p><ul><li><code>type='DeformFusion'</code> 表示这是一个可变形特征融合模块。</li><li><code>in_channels=256</code> 表示输入特征图的通道数。</li><li><code>out_channels=256</code> 表示输出特征图的通道数。</li><li><code>num_blocks=3</code> 表示使用 3 个可变形卷积块进行特征融合。</li></ul></li></ul><h5 id="区域提议网络rpn和roi头"><a class="anchor" href="#区域提议网络rpn和roi头">#</a> 区域提议网络 (RPN) 和 ROI 头</h5><p>区域提议网络（Region Proposal Network, RPN）和 ROI 头（Region of Interest Head）是目标检测任务中两个非常重要的组件，尤其是在两阶段检测器（如 Faster R-CNN）中。它们分别负责生成候选区域和进行目标分类与定位。下面是对这两个组件的详细解释：</p><ol><li>区域提议网络（RPN）</li></ol><p><strong>RPN</strong> 是一种用于生成候选区域（Region Proposals）的网络，这些候选区域是可能包含目标的矩形框。RPN 的主要任务是生成高质量的候选区域，这些区域随后会被传递给后续的网络进行进一步的处理。</p><p>工作流程</p><pre><code>1. **特征提取**：
    - RPN 通常接在卷积神经网络（如ResNet）的后面，输入是卷积网络提取的特征图。
    - 特征图的每个位置都会生成一组候选区域（锚框，Anchors）。

2. **锚框生成**：
    - 锚框是预先定义的一组矩形框，具有不同的尺度和宽高比。
    - 例如，一个特征图上的每个位置可能生成9个不同尺度和宽高比的锚框。

3. **分类和回归**：
    - RPN 对每个锚框进行分类和回归：
    - **分类**：判断每个锚框是否包含目标（前景或背景）。这通常通过一个二分类的全连接层实现。
    - **回归**：调整锚框的位置和大小，使其更接近真实的目标框。这通常通过一个回归层实现，输出四个参数（Δx, Δy, Δw, Δh），表示锚框相对于真实框的偏移量。

4. **非极大值抑制（NMS）**：
    - 生成的候选区域可能会有很多重叠的情况，因此需要进行非极大值抑制（Non-Maximum Suppression, NMS）来筛选出高质量的候选区域。
    - NMS 根据分类得分和重叠度（IOU）来保留得分最高的候选区域，去除重叠较大的区域。
</code></pre><p>优势</p><ul><li><strong>高效生成候选区域</strong>：RPN 通过卷积操作生成候选区域，计算效率高，适用于大规模数据集。</li><li><strong>与检测网络共享特征</strong>：RPN 和后续的检测网络可以共享卷积特征，减少了计算量。</li></ul><ol start="2"><li>ROI 头（Region of Interest Head）</li></ol><p><strong>ROI 头</strong> 是用于对候选区域进行分类和精确定位的网络组件。它接收 RPN 生成的候选区域，并对其进行进一步处理，最终输出目标类别和精确的边界框。</p><p>工作流程</p><pre><code>1. **ROI池化（ROI Pooling）**：
    - 将RPN生成的候选区域映射到特征图上，并进行池化操作，将不同大小的候选区域统一到固定大小的特征图。
    - 常见的池化方法有ROI Pooling和ROI Align。

2. **特征提取**：
    - 对池化后的特征图进行进一步的卷积操作，提取更高级的特征。

3. **分类和回归**：
    - **分类**：通过一个全连接层对每个候选区域进行分类，输出目标类别的概率分布。
    - **回归**：通过另一个全连接层对每个候选区域进行回归，输出精确的边界框坐标。

4. **非极大值抑制（NMS）**：
    - 对分类和回归后的结果进行NMS，去除重叠较大的边界框，保留得分最高的目标框。
</code></pre><p>配置示例</p><p>在你的代码中， <code>rpn_head</code> 和 <code>roi_head</code> 的配置如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">rpn_head=<span class="built_in">dict</span>(</span><br><span class="line">    <span class="built_in">type</span>=<span class="string">&#x27;RPNHead&#x27;</span>,</span><br><span class="line">    in_channels=<span class="number">256</span>,</span><br><span class="line">    feat_channels=<span class="number">256</span>,</span><br><span class="line">    anchor_generator=<span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&#x27;AnchorGenerator&#x27;</span>,</span><br><span class="line">        scales=[<span class="number">8</span>],</span><br><span class="line">        ratios=[<span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">2.0</span>],</span><br><span class="line">        strides=[<span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">128</span>]),</span><br><span class="line">    bbox_coder=<span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&#x27;DeltaXYWHBBoxCoder&#x27;</span>,</span><br><span class="line">        target_means=[<span class="number">.0</span>, <span class="number">.0</span>, <span class="number">.0</span>, <span class="number">.0</span>],</span><br><span class="line">        target_stds=[<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]),</span><br><span class="line">    loss_cls=<span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&#x27;CrossEntropyLoss&#x27;</span>, use_sigmoid=<span class="literal">True</span>, loss_weight=<span class="number">1.0</span>),</span><br><span class="line">    loss_bbox=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;SmoothL1Loss&#x27;</span>, beta=<span class="number">1.0</span> / <span class="number">9.0</span>, loss_weight=<span class="number">1.0</span>)</span><br><span class="line">),</span><br><span class="line"></span><br><span class="line">roi_head=<span class="built_in">dict</span>(</span><br><span class="line">    <span class="built_in">type</span>=<span class="string">&#x27;StandardRoIHead&#x27;</span>,</span><br><span class="line">    bbox_roi_extractor=<span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&#x27;SingleRoIExtractor&#x27;</span>,</span><br><span class="line">        roi_layer=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;RoIAlign&#x27;</span>, output_size=<span class="number">7</span>, sampling_ratio=<span class="number">0</span>),</span><br><span class="line">        out_channels=<span class="number">256</span>,</span><br><span class="line">        featmap_strides=[<span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>]),</span><br><span class="line">    bbox_head=<span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&#x27;Shared2FCBBoxHead&#x27;</span>,</span><br><span class="line">        in_channels=<span class="number">256</span>,</span><br><span class="line">        fc_out_channels=<span class="number">1024</span>,</span><br><span class="line">        roi_feat_size=<span class="number">7</span>,</span><br><span class="line">        num_classes=<span class="number">1</span>,</span><br><span class="line">        bbox_coder=<span class="built_in">dict</span>(</span><br><span class="line">            <span class="built_in">type</span>=<span class="string">&#x27;DeltaXYWHBBoxCoder&#x27;</span>,</span><br><span class="line">            target_means=[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">            target_stds=[<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.2</span>]),</span><br><span class="line">        reg_class_agnostic=<span class="literal">True</span>,</span><br><span class="line">        loss_cls=<span class="built_in">dict</span>(</span><br><span class="line">            <span class="built_in">type</span>=<span class="string">&#x27;CrossEntropyLoss&#x27;</span>, use_sigmoid=<span class="literal">False</span>, loss_weight=<span class="number">1.0</span>),</span><br><span class="line">        loss_bbox=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;L1Loss&#x27;</span>, loss_weight=<span class="number">1.0</span>))</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ul><li><p><strong>RPN Head</strong>：</p><ul><li><code>type='RPNHead'</code> ：表示这是一个 RPN 头部。</li><li><code>in_channels=256</code> 和 <code>feat_channels=256</code> ：输入和特征图的通道数。</li><li><code>anchor_generator</code> ：定义了锚框的生成方式，包括尺度、宽高比和步幅。</li><li><code>bbox_coder</code> ：定义了边界框编码和解码的方式。</li><li><code>loss_cls</code> 和 <code>loss_bbox</code> ：定义了分类和回归的损失函数。</li></ul></li><li><p><strong>ROI Head</strong>：</p><ul><li><code>type='StandardRoIHead'</code> ：表示这是一个标准的 ROI 头部。</li><li><code>bbox_roi_extractor</code> ：定义了 ROI 池化的方式，包括池化层的类型、输出大小和特征图的步幅。</li><li><code>bbox_head</code> ：定义了边界框头部，包括全连接层的输出通道数、ROI 特征的大小、类别数、边界框编码方式和损失函数。</li></ul></li></ul><p>总结</p><ul><li><strong>RPN</strong>：负责生成高质量的候选区域，通过分类和回归操作调整锚框的位置和大小。</li><li><strong>ROI Head</strong>：对候选区域进行进一步的分类和精确定位，输出最终的目标类别和边界框。</li></ul><h4 id="gdino_masapth"><a class="anchor" href="#gdino_masapth">#</a> gdino_masa.pth</h4><p>至于这个参数，我也不知道这是个啥，只有一些推测：</p><ul><li>文件扩展名 .pth：<ul><li>.pth 是 PyTorch 模型权重文件的标准扩展名。这种文件通常包含模型的参数（权重和偏置），有时还包括优化器的状态和其他元数据。</li></ul></li><li>文件内容：<ul><li>文件内容是二进制格式，包含模型的权重和偏置等参数。<br>这些参数是通过训练过程学习到的，用于初始化模型，使其在特定任务上表现良好。</li></ul></li></ul><h4 id="init_masa"><a class="anchor" href="#init_masa">#</a> init_masa</h4><p>这段代码定义了一个函数 <code>init_masa</code> ，用于从配置文件初始化一个统一的 MASA 检测器模型。该函数接受多个参数，包括配置文件路径、预训练权重文件路径、颜色调色板、设备以及配置选项。下面是对这段代码的逐行解释：</p><h5 id="函数定义和参数"><a class="anchor" href="#函数定义和参数">#</a> 函数定义和参数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_masa</span>(<span class="params"></span></span><br><span class="line"><span class="params">    config: <span class="type">Union</span>[<span class="built_in">str</span>, Path, Config],</span></span><br><span class="line"><span class="params">    checkpoint: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    palette: <span class="built_in">str</span> = <span class="string">&quot;none&quot;</span>,</span></span><br><span class="line"><span class="params">    device: <span class="built_in">str</span> = <span class="string">&quot;cuda:0&quot;</span>,</span></span><br><span class="line"><span class="params">    cfg_options: <span class="type">Optional</span>[<span class="built_in">dict</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; nn.Module:</span><br></pre></td></tr></table></figure><ul><li><strong><code>config</code> </strong>：配置文件路径、 <code>Path</code> 对象或 <code>Config</code> 对象。</li><li><strong><code>checkpoint</code> </strong>：预训练权重文件路径。如果为 <code>None</code> ，模型将不会加载任何权重。</li><li><strong><code>palette</code> </strong>：用于可视化的颜色调色板，默认为 <code>&quot;none&quot;</code> 。</li><li><strong><code>device</code> </strong>：模型将要部署的设备，默认为 <code>&quot;cuda:0&quot;</code> 。</li><li><strong><code>cfg_options</code> </strong>：用于覆盖配置文件中某些设置的字典。</li></ul><h5 id="文档字符串"><a class="anchor" href="#文档字符串">#</a> 文档字符串</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Initialize a unified masa detector from config file.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">    config (str, :obj:`Path`, or :obj:`mmengine.Config`): Config file path,</span></span><br><span class="line"><span class="string">        :obj:`Path`, or the config object.</span></span><br><span class="line"><span class="string">    checkpoint (str, optional): Checkpoint path. If left as None, the model</span></span><br><span class="line"><span class="string">        will not load any weights.</span></span><br><span class="line"><span class="string">    palette (str): Color palette used for visualization. If palette</span></span><br><span class="line"><span class="string">        is stored in checkpoint, use checkpoint&#x27;s palette first, otherwise</span></span><br><span class="line"><span class="string">        use externally passed palette. Currently, supports &#x27;coco&#x27;, &#x27;voc&#x27;,</span></span><br><span class="line"><span class="string">        &#x27;citys&#x27; and &#x27;random&#x27;. Defaults to none.</span></span><br><span class="line"><span class="string">    device (str): The device where the anchors will be put on.</span></span><br><span class="line"><span class="string">        Defaults to cuda:0.</span></span><br><span class="line"><span class="string">    cfg_options (dict, optional): Options to override some settings in</span></span><br><span class="line"><span class="string">        the used config.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    nn.Module: The constructed detector.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><h5 id="处理配置文件"><a class="anchor" href="#处理配置文件">#</a> 处理配置文件</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(config, (<span class="built_in">str</span>, Path)):</span><br><span class="line">    config = Config.fromfile(config)</span><br><span class="line"><span class="keyword">elif</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(config, Config):</span><br><span class="line">    <span class="keyword">raise</span> TypeError(</span><br><span class="line">        <span class="string">&quot;config must be a filename or Config object, &quot;</span> <span class="string">f&quot;but got <span class="subst">&#123;<span class="built_in">type</span>(config)&#125;</span>&quot;</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure><ul><li>检查 <code>config</code> 是否为字符串或 <code>Path</code> 对象，如果是，则使用 <code>Config.fromfile</code> 方法读取配置文件。</li><li>如果 <code>config</code> 不是 <code>Config</code> 对象，抛出类型错误。</li></ul><h5 id="处理配置选项"><a class="anchor" href="#处理配置选项">#</a> 处理配置选项</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">with_backbone = config.model.get(<span class="string">&quot;backbone&quot;</span>, <span class="literal">False</span>)</span><br><span class="line"><span class="keyword">if</span> with_backbone:</span><br><span class="line">    <span class="keyword">if</span> cfg_options <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        config.merge_from_dict(cfg_options)</span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&quot;init_cfg&quot;</span> <span class="keyword">in</span> config.model.backbone:</span><br><span class="line">        config.model.backbone.init_cfg = <span class="literal">None</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">if</span> cfg_options <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        config.merge_from_dict(cfg_options)</span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&quot;init_cfg&quot;</span> <span class="keyword">in</span> config.model.detector.backbone:</span><br><span class="line">        config.model.detector.backbone.init_cfg = <span class="literal">None</span></span><br></pre></td></tr></table></figure><ul><li>检查配置文件中是否有 <code>backbone</code> 部分。</li><li>如果有 <code>backbone</code> 部分，且 <code>cfg_options</code> 不为 <code>None</code> ，则将 <code>cfg_options</code> 合并到配置文件中。</li><li>如果 <code>cfg_options</code> 为 <code>None</code> 且 <code>backbone</code> 部分中有 <code>init_cfg</code> ，则将其设置为 <code>None</code> 。</li><li>如果没有 <code>backbone</code> 部分，处理 <code>detector</code> 部分，逻辑类似。</li></ul><h5 id="初始化默认作用域"><a class="anchor" href="#初始化默认作用域">#</a> 初始化默认作用域</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scope = config.get(<span class="string">&quot;default_scope&quot;</span>, <span class="string">&quot;mmdet&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> scope <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    init_default_scope(config.get(<span class="string">&quot;default_scope&quot;</span>, <span class="string">&quot;mmdet&quot;</span>))</span><br></pre></td></tr></table></figure><ul><li>获取配置文件中的默认作用域，默认为 <code>&quot;mmdet&quot;</code> 。</li><li>如果存在默认作用域，初始化默认作用域。</li></ul><h5 id="构建模型"><a class="anchor" href="#构建模型">#</a> 构建模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = MODELS.build(config.model)</span><br><span class="line">model = revert_sync_batchnorm(model)</span><br></pre></td></tr></table></figure><ul><li>使用 <code>MODELS.build</code> 方法根据配置文件构建模型。</li><li>将模型中的同步批量归一化层转换为普通的批量归一化层。</li></ul><h5 id="加载预训练权重"><a class="anchor" href="#加载预训练权重">#</a> 加载预训练权重</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> checkpoint <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    warnings.simplefilter(<span class="string">&quot;once&quot;</span>)</span><br><span class="line">    warnings.warn(<span class="string">&quot;checkpoint is None, use COCO classes by default.&quot;</span>)</span><br><span class="line">    model.dataset_meta = &#123;<span class="string">&quot;classes&quot;</span>: get_classes(<span class="string">&quot;coco&quot;</span>)&#125;</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    checkpoint = load_checkpoint(model, checkpoint, map_location=<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    checkpoint_meta = checkpoint.get(<span class="string">&quot;meta&quot;</span>, &#123;&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;dataset_meta&quot;</span> <span class="keyword">in</span> checkpoint_meta:</span><br><span class="line">        model.dataset_meta = &#123;</span><br><span class="line">            k.lower(): v <span class="keyword">for</span> k, v <span class="keyword">in</span> checkpoint_meta[<span class="string">&quot;dataset_meta&quot;</span>].items()</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&quot;CLASSES&quot;</span> <span class="keyword">in</span> checkpoint_meta:</span><br><span class="line">        classes = checkpoint_meta[<span class="string">&quot;CLASSES&quot;</span>]</span><br><span class="line">        model.dataset_meta = &#123;<span class="string">&quot;classes&quot;</span>: classes&#125;</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        warnings.simplefilter(<span class="string">&quot;once&quot;</span>)</span><br><span class="line">        warnings.warn(</span><br><span class="line">            <span class="string">&quot;dataset_meta or class names are not saved in the &quot;</span></span><br><span class="line">            <span class="string">&quot;checkpoint&#x27;s meta data, use COCO classes by default.&quot;</span></span><br><span class="line">        )</span><br><span class="line">        model.dataset_meta = &#123;<span class="string">&quot;classes&quot;</span>: get_classes(<span class="string">&quot;coco&quot;</span>)&#125;</span><br></pre></td></tr></table></figure><ul><li>如果 <code>checkpoint</code> 为 <code>None</code> ，发出警告并使用 COCO 数据集的类别。</li><li>否则，加载预训练权重文件，并从权重文件的元数据中获取数据集元信息（如类别和调色板）。</li></ul><h5 id="设置调色板"><a class="anchor" href="#设置调色板">#</a> 设置调色板</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> palette != <span class="string">&quot;none&quot;</span>:</span><br><span class="line">    model.dataset_meta[<span class="string">&quot;palette&quot;</span>] = palette</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;palette&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> model.dataset_meta:</span><br><span class="line">        warnings.warn(</span><br><span class="line">            <span class="string">&quot;palette does not exist, random is used by default. &quot;</span></span><br><span class="line">            <span class="string">&quot;You can also set the palette to customize.&quot;</span></span><br><span class="line">        )</span><br><span class="line">        model.dataset_meta[<span class="string">&quot;palette&quot;</span>] = <span class="string">&quot;random&quot;</span></span><br></pre></td></tr></table></figure><ul><li>如果 <code>palette</code> 不为 <code>&quot;none&quot;</code> ，设置模型的调色板。</li><li>如果 <code>palette</code> 为 <code>&quot;none&quot;</code> 且模型的元信息中没有调色板，发出警告并使用随机调色板。</li></ul><h5 id="保存配置和设置设备"><a class="anchor" href="#保存配置和设置设备">#</a> 保存配置和设置设备</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.cfg = config  <span class="comment"># save the config in the model for convenience</span></span><br><span class="line">model.to(device)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure><ul><li>将配置文件保存到模型中，便于后续使用。</li><li>将模型移动到指定的设备上。</li><li>将模型设置为评估模式。</li></ul><h5 id="返回模型"><a class="anchor" href="#返回模型">#</a> 返回模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><ul><li>返回初始化好的模型。</li></ul><h5 id="总结"><a class="anchor" href="#总结">#</a> 总结</h5><p><code>init_masa</code> 函数的主要功能是从配置文件和预训练权重文件中初始化一个 MASA 检测器模型，并设置相关参数（如调色板、设备等），返回一个准备好的模型对象。这个函数在实际使用中可以帮助用户快速加载和配置模型，以便进行目标检测任务。</p><hr><p>好的现在回到 video_demo_with_text 这个代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.sam_mask:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Loading SAM model...&#x27;</span>)</span><br><span class="line">    device = args.device</span><br><span class="line">    sam_model = sam_model_registry[args.sam_type](args.sam_path)</span><br><span class="line">    sam_predictor = SamPredictor(sam_model.to(device))</span><br></pre></td></tr></table></figure><p>这段代码的主要功能是根据命令行参数 args.sam_mask 判断是否需要加载一个名为 SAM（Segment Anything Model）的模型。如果需要加载，它会执行一系列操作来初始化和配置 SAM 模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">video_reader = mmcv.VideoReader(args.video)</span><br><span class="line">video_writer = <span class="literal">None</span></span><br></pre></td></tr></table></figure><p>使用 mmcv 的 VideoReader 类读取视频文件，每一帧将依次处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#### parsing the text input</span></span><br><span class="line">    texts = args.texts</span><br><span class="line">    <span class="keyword">if</span> texts <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        masa_test_pipeline = build_test_pipeline(masa_model.cfg, with_text=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        masa_test_pipeline = build_test_pipeline(masa_model.cfg)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> texts <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        masa_model.cfg.visualizer[<span class="string">&#x27;texts&#x27;</span>] = texts</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        masa_model.cfg.visualizer[<span class="string">&#x27;texts&#x27;</span>] = det_model.dataset_meta[<span class="string">&#x27;classes&#x27;</span>]</span><br></pre></td></tr></table></figure><p>这段代码的主要功能是解析文本输入，并根据是否存在文本输入来构建测试管道和配置模型的可视化器。下面是对这段代码的逐行解释：</p><ul><li><p><strong>获取文本输入</strong>：从命令行参数 <code>args</code> 中获取 <code>texts</code> ，这是一个可能包含用户提供的文本列表的变量。</p></li><li><p><strong>构建测试管道</strong>：</p><ul><li>如果 <code>texts</code> 不为 <code>None</code> ，即用户提供了文本输入，调用 <code>build_test_pipeline</code> 函数并传入 <code>masa_model.cfg</code> 和 <code>with_text=True</code> 参数，构建一个支持文本输入的测试管道。</li><li>如果 <code>texts</code> 为 <code>None</code> ，即用户没有提供文本输入，调用 <code>build_test_pipeline</code> 函数并传入 <code>masa_model.cfg</code> 参数，构建一个不支持文本输入的测试管道。</li></ul></li><li><p><strong>配置可视化器</strong>：</p><ul><li>如果 <code>texts</code> 不为 <code>None</code> ，即用户提供了文本输入，将 <code>texts</code> 赋值给 <code>masa_model.cfg.visualizer['texts']</code> ，这样可视化器将使用用户提供的文本。</li><li>如果 <code>texts</code> 为 <code>None</code> ，即用户没有提供文本输入，将 <code>det_model.dataset_meta['classes']</code> 赋值给 <code>masa_model.cfg.visualizer['texts']</code> ，这样可视化器将使用数据集中定义的类别名称。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># init visualizer</span></span><br><span class="line">    masa_model.cfg.visualizer[<span class="string">&#x27;save_dir&#x27;</span>] = args.save_dir</span><br><span class="line">    masa_model.cfg.visualizer[<span class="string">&#x27;line_width&#x27;</span>] = args.line_width</span><br><span class="line">    <span class="keyword">if</span> args.sam_mask:</span><br><span class="line">        masa_model.cfg.visualizer[<span class="string">&#x27;alpha&#x27;</span>] = <span class="number">0.5</span></span><br><span class="line">    visualizer = VISUALIZERS.build(masa_model.cfg.visualizer)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.out:</span><br><span class="line">        fourcc = cv2.VideoWriter_fourcc(*<span class="string">&#x27;mp4v&#x27;</span>)</span><br><span class="line">        video_writer = cv2.VideoWriter(</span><br><span class="line">            args.out, fourcc, video_reader.fps,</span><br><span class="line">            (video_reader.width, video_reader.height))</span><br></pre></td></tr></table></figure><p>这段代码的主要功能是初始化可视化器，并根据命令行参数配置可视化器的属性。此外，如果指定了输出视频文件，还会初始化视频写入器。下面是对这段代码的逐行解释：</p><ul><li><p><strong>设置保存目录</strong>：将命令行参数 <code>args.save_dir</code> 的值赋给 <code>masa_model.cfg.visualizer['save_dir']</code> ，指定可视化结果的保存目录。</p></li><li><p><strong>设置线条宽度</strong>：将命令行参数 <code>args.line_width</code> 的值赋给 <code>masa_model.cfg.visualizer['line_width']</code> ，指定绘制边界框时的线条宽度。</p></li><li><p><strong>设置透明度</strong>：如果命令行参数 <code>args.sam_mask</code> 为 <code>True</code> ，将 <code>masa_model.cfg.visualizer['alpha']</code> 设置为 <code>0.5</code> ，表示在绘制分割掩码时使用的透明度。</p></li><li><p><strong>构建可视化器</strong>：使用 <code>VISUALIZERS.build</code> 方法根据 <code>masa_model.cfg.visualizer</code> 配置构建一个可视化器对象 <code>visualizer</code> 。 <code>VISUALIZERS</code> 是一个注册表，包含了多种可视化器的构建方法。</p></li><li><p><strong>初始化视频写入器</strong>：</p><ul><li>如果命令行参数 <code>args.out</code> 不为 <code>None</code> ，表示需要将处理后的视频保存到指定的输出文件。</li><li><code>fourcc = cv2.VideoWriter_fourcc(*'mp4v')</code> ：设置视频编解码器为 <code>mp4v</code> 。</li><li><code>video_writer = cv2.VideoWriter(args.out, fourcc, video_reader.fps, (video_reader.width, video_reader.height))</code> ：创建一个 <code>cv2.VideoWriter</code> 对象 <code>video_writer</code> ，用于将处理后的帧写入输出视频文件。参数包括输出文件路径、编解码器、帧率（从 <code>video_reader</code> 获取）、视频宽度和高度（从 <code>video_reader</code> 获取）。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">frame_idx = <span class="number">0</span></span><br><span class="line">    instances_list = []</span><br><span class="line">    frames = []</span><br><span class="line">    fps_list = []</span><br><span class="line">    <span class="keyword">for</span> frame <span class="keyword">in</span> track_iter_progress((video_reader, <span class="built_in">len</span>(video_reader))):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># unified models mean that masa build upon and reuse the foundation model&#x27;s backbone features for tracking</span></span><br><span class="line">        <span class="keyword">if</span> args.unified:</span><br><span class="line">            track_result = inference_masa(masa_model, frame,</span><br><span class="line">                                          frame_id=frame_idx,</span><br><span class="line">                                          video_len=<span class="built_in">len</span>(video_reader),</span><br><span class="line">                                          test_pipeline=masa_test_pipeline,</span><br><span class="line">                                          text_prompt=texts,</span><br><span class="line">                                          fp16=args.fp16,</span><br><span class="line">                                          detector_type=args.detector_type,</span><br><span class="line">                                          show_fps=args.show_fps)</span><br><span class="line">            <span class="keyword">if</span> args.show_fps:</span><br><span class="line">                track_result, fps = track_result</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> args.detector_type == <span class="string">&#x27;mmdet&#x27;</span>:</span><br><span class="line">                result = inference_detector(det_model, frame,</span><br><span class="line">                                            text_prompt=texts,</span><br><span class="line">                                            test_pipeline=test_pipeline,</span><br><span class="line">                                            fp16=args.fp16)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Perfom inter-class NMS to remove nosiy detections</span></span><br><span class="line">            det_bboxes, keep_idx = batched_nms(boxes=result.pred_instances.bboxes,</span><br><span class="line">                                               scores=result.pred_instances.scores,</span><br><span class="line">                                               idxs=result.pred_instances.labels,</span><br><span class="line">                                               class_agnostic=<span class="literal">True</span>,</span><br><span class="line">                                               nms_cfg=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;nms&#x27;</span>,</span><br><span class="line">                                                             iou_threshold=<span class="number">0.5</span>,</span><br><span class="line">                                                             class_agnostic=<span class="literal">True</span>,</span><br><span class="line">                                                             split_thr=<span class="number">100000</span>))</span><br><span class="line"></span><br><span class="line">            det_bboxes = torch.cat([det_bboxes,</span><br><span class="line">                                            result.pred_instances.scores[keep_idx].unsqueeze(<span class="number">1</span>)],</span><br><span class="line">                                               dim=<span class="number">1</span>)</span><br><span class="line">            det_labels = result.pred_instances.labels[keep_idx]</span><br><span class="line"></span><br><span class="line">            track_result = inference_masa(masa_model, frame, frame_id=frame_idx,</span><br><span class="line">                                          video_len=<span class="built_in">len</span>(video_reader),</span><br><span class="line">                                          test_pipeline=masa_test_pipeline,</span><br><span class="line">                                          det_bboxes=det_bboxes,</span><br><span class="line">                                          det_labels=det_labels,</span><br><span class="line">                                          fp16=args.fp16,</span><br><span class="line">                                          show_fps=args.show_fps)</span><br><span class="line">            <span class="keyword">if</span> args.show_fps:</span><br><span class="line">                track_result, fps = track_result</span><br><span class="line"></span><br><span class="line">        frame_idx += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;masks&#x27;</span> <span class="keyword">in</span> track_result[<span class="number">0</span>].pred_track_instances:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(track_result[<span class="number">0</span>].pred_track_instances.masks) &gt;<span class="number">0</span>:</span><br><span class="line">                track_result[<span class="number">0</span>].pred_track_instances.masks = torch.stack(track_result[<span class="number">0</span>].pred_track_instances.masks, dim=<span class="number">0</span>)</span><br><span class="line">                track_result[<span class="number">0</span>].pred_track_instances.masks = track_result[<span class="number">0</span>].pred_track_instances.masks.cpu().numpy()</span><br><span class="line"></span><br><span class="line">        track_result[<span class="number">0</span>].pred_track_instances.bboxes = track_result[<span class="number">0</span>].pred_track_instances.bboxes.to(torch.float32)</span><br><span class="line">        instances_list.append(track_result.to(<span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line">        frames.append(frame)</span><br><span class="line">        <span class="keyword">if</span> args.show_fps:</span><br><span class="line">            fps_list.append(fps)</span><br></pre></td></tr></table></figure><p>这段代码的主要功能是处理视频流中的每一帧，进行目标检测和跟踪，并将结果存储起来。以下是逐行解释：</p><h4 id="初始化变量"><a class="anchor" href="#初始化变量">#</a> 初始化变量</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">frame_idx = <span class="number">0</span></span><br><span class="line">instances_list = []</span><br><span class="line">frames = []</span><br><span class="line">fps_list = []</span><br></pre></td></tr></table></figure><ul><li><strong><code>frame_idx</code> </strong>：初始化帧索引为 0，用于记录当前处理的帧编号。</li><li><strong><code>instances_list</code> </strong>：初始化一个空列表，用于存储每帧的跟踪结果。</li><li><strong><code>frames</code> </strong>：初始化一个空列表，用于存储每帧的原始图像。</li><li><strong><code>fps_list</code> </strong>：初始化一个空列表，用于存储每帧的处理速度（FPS）。</li></ul><h4 id="处理视频流"><a class="anchor" href="#处理视频流">#</a> 处理视频流</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> frame <span class="keyword">in</span> track_iter_progress((video_reader, <span class="built_in">len</span>(video_reader))):</span><br></pre></td></tr></table></figure><ul><li><strong><code>track_iter_progress</code> </strong>：一个函数，用于跟踪视频读取进度。 <code>video_reader</code> 是视频读取器对象， <code>len(video_reader)</code> 是视频的总帧数。</li></ul><h4 id="统一模型处理"><a class="anchor" href="#统一模型处理">#</a> 统一模型处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.unified:</span><br><span class="line">    track_result = inference_masa(masa_model, frame,</span><br><span class="line">                                  frame_id=frame_idx,</span><br><span class="line">                                  video_len=<span class="built_in">len</span>(video_reader),</span><br><span class="line">                                  test_pipeline=masa_test_pipeline,</span><br><span class="line">                                  text_prompt=texts,</span><br><span class="line">                                  fp16=args.fp16,</span><br><span class="line">                                  detector_type=args.detector_type,</span><br><span class="line">                                  show_fps=args.show_fps)</span><br><span class="line">    <span class="keyword">if</span> args.show_fps:</span><br><span class="line">        track_result, fps = track_result</span><br></pre></td></tr></table></figure><ul><li><strong>条件判断</strong>：如果命令行参数 <code>args.unified</code> 为 <code>True</code> ，表示使用统一模型进行处理。</li><li><strong><code>inference_masa</code> </strong>：调用 <code>inference_masa</code> 函数进行目标检测和跟踪。参数包括：<ul><li><code>masa_model</code> ：模型对象。</li><li><code>frame</code> ：当前帧的图像。</li><li><code>frame_id</code> ：当前帧的索引。</li><li><code>video_len</code> ：视频的总帧数。</li><li><code>test_pipeline</code> ：测试管道。</li><li><code>text_prompt</code> ：文本提示。</li><li><code>fp16</code> ：是否使用半精度浮点数。</li><li><code>detector_type</code> ：检测器类型。</li><li><code>show_fps</code> ：是否显示 FPS。</li></ul></li><li><strong>处理 FPS</strong>：如果 <code>args.show_fps</code> 为 <code>True</code> ， <code>track_result</code> 将包含 FPS 信息，将其分离出来。</li></ul><h4 id="非统一模型处理"><a class="anchor" href="#非统一模型处理">#</a> 非统一模型处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">if</span> args.detector_type == <span class="string">&#x27;mmdet&#x27;</span>:</span><br><span class="line">        result = inference_detector(det_model, frame,</span><br><span class="line">                                    text_prompt=texts,</span><br><span class="line">                                    test_pipeline=test_pipeline,</span><br><span class="line">                                    fp16=args.fp16)</span><br></pre></td></tr></table></figure><ul><li><strong>条件判断</strong>：如果命令行参数 <code>args.unified</code> 为 <code>False</code> ，表示使用非统一模型进行处理。</li><li><strong><code>inference_detector</code> </strong>：调用 <code>inference_detector</code> 函数进行目标检测。参数包括：<ul><li><code>det_model</code> ：检测模型对象。</li><li><code>frame</code> ：当前帧的图像。</li><li><code>text_prompt</code> ：文本提示。</li><li><code>test_pipeline</code> ：测试管道。</li><li><code>fp16</code> ：是否使用半精度浮点数。</li></ul></li></ul><h4 id="执行非极大值抑制nms"><a class="anchor" href="#执行非极大值抑制nms">#</a> 执行非极大值抑制（NMS）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">det_bboxes, keep_idx = batched_nms(boxes=result.pred_instances.bboxes,</span><br><span class="line">                                   scores=result.pred_instances.scores,</span><br><span class="line">                                   idxs=result.pred_instances.labels,</span><br><span class="line">                                   class_agnostic=<span class="literal">True</span>,</span><br><span class="line">                                   nms_cfg=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;nms&#x27;</span>,</span><br><span class="line">                                                iou_threshold=<span class="number">0.5</span>,</span><br><span class="line">                                                class_agnostic=<span class="literal">True</span>,</span><br><span class="line">                                                split_thr=<span class="number">100000</span>))</span><br></pre></td></tr></table></figure><ul><li><strong><code>batched_nms</code> </strong>：执行非极大值抑制（NMS），去除冗余的检测框。参数包括：<ul><li><code>boxes</code> ：检测框的坐标。</li><li><code>scores</code> ：检测框的置信度分数。</li><li><code>idxs</code> ：检测框的类别标签。</li><li><code>class_agnostic</code> ：是否进行类别无关的 NMS。</li><li><code>nms_cfg</code> ：NMS 的配置参数，包括类型、IoU 阈值等。</li></ul></li></ul><h4 id="更新检测结果"><a class="anchor" href="#更新检测结果">#</a> 更新检测结果</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">det_bboxes = torch.cat([det_bboxes,</span><br><span class="line">                        result.pred_instances.scores[keep_idx].unsqueeze(<span class="number">1</span>)],</span><br><span class="line">                       dim=<span class="number">1</span>)</span><br><span class="line">det_labels = result.pred_instances.labels[keep_idx]</span><br></pre></td></tr></table></figure><ul><li><strong>更新检测框</strong>：将保留的检测框和对应的置信度分数拼接在一起。</li><li><strong>更新标签</strong>：保留的检测框对应的类别标签。</li></ul><h4 id="进行目标跟踪"><a class="anchor" href="#进行目标跟踪">#</a> 进行目标跟踪</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">track_result = inference_masa(masa_model, frame, frame_id=frame_idx,</span><br><span class="line">                              video_len=<span class="built_in">len</span>(video_reader),</span><br><span class="line">                              test_pipeline=masa_test_pipeline,</span><br><span class="line">                              det_bboxes=det_bboxes,</span><br><span class="line">                              det_labels=det_labels,</span><br><span class="line">                              fp16=args.fp16,</span><br><span class="line">                              show_fps=args.show_fps)</span><br><span class="line"><span class="keyword">if</span> args.show_fps:</span><br><span class="line">    track_result, fps = track_result</span><br></pre></td></tr></table></figure><ul><li><strong><code>inference_masa</code> </strong>：调用 <code>inference_masa</code> 函数进行目标跟踪。参数包括：<ul><li><code>masa_model</code> ：模型对象。</li><li><code>frame</code> ：当前帧的图像。</li><li><code>frame_id</code> ：当前帧的索引。</li><li><code>video_len</code> ：视频的总帧数。</li><li><code>test_pipeline</code> ：测试管道。</li><li><code>det_bboxes</code> ：检测框的坐标。</li><li><code>det_labels</code> ：检测框的类别标签。</li><li><code>fp16</code> ：是否使用半精度浮点数。</li><li><code>show_fps</code> ：是否显示 FPS。</li></ul></li><li><strong>处理 FPS</strong>：如果 <code>args.show_fps</code> 为 <code>True</code> ， <code>track_result</code> 将包含 FPS 信息，将其分离出来。</li></ul><h4 id="更新帧索引"><a class="anchor" href="#更新帧索引">#</a> 更新帧索引</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">frame_idx += <span class="number">1</span></span><br></pre></td></tr></table></figure><ul><li><strong>更新帧索引</strong>：将帧索引加 1，表示处理下一帧。</li></ul><h4 id="处理跟踪结果"><a class="anchor" href="#处理跟踪结果">#</a> 处理跟踪结果</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="string">&#x27;masks&#x27;</span> <span class="keyword">in</span> track_result[<span class="number">0</span>].pred_track_instances:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(track_result[<span class="number">0</span>].pred_track_instances.masks) &gt; <span class="number">0</span>:</span><br><span class="line">        track_result[<span class="number">0</span>].pred_track_instances.masks = torch.stack(track_result[<span class="number">0</span>].pred_track_instances.masks, dim=<span class="number">0</span>)</span><br><span class="line">        track_result[<span class="number">0</span>].pred_track_instances.masks = track_result[<span class="number">0</span>].pred_track_instances.masks.cpu().numpy()</span><br></pre></td></tr></table></figure><ul><li><strong>检查掩码</strong>：如果跟踪结果中包含掩码，并且掩码数量大于 0，将掩码堆叠成一个张量，并将其移动到 CPU 上转换为 NumPy 数组。</li></ul><h4 id="更新检测框的数据类型"><a class="anchor" href="#更新检测框的数据类型">#</a> 更新检测框的数据类型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">track_result[<span class="number">0</span>].pred_track_instances.bboxes = track_result[<span class="number">0</span>].pred_track_instances.bboxes.to(torch.float32)</span><br></pre></td></tr></table></figure><ul><li><strong>转换数据类型</strong>：将检测框的坐标转换为 <code>float32</code> 类型。</li></ul><h4 id="存储结果"><a class="anchor" href="#存储结果">#</a> 存储结果</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">instances_list.append(track_result.to(<span class="string">&#x27;cpu&#x27;</span>))</span><br><span class="line">frames.append(frame)</span><br><span class="line"><span class="keyword">if</span> args.show_fps:</span><br><span class="line">    fps_list.append(fps)</span><br></pre></td></tr></table></figure><ul><li><strong>存储跟踪结果</strong>：将当前帧的跟踪结果（转换为 CPU 上的张量）添加到 <code>instances_list</code> 中。</li><li><strong>存储原始帧</strong>：将当前帧的原始图像添加到 <code>frames</code> 中。</li><li><strong>存储 FPS</strong>：如果 <code>args.show_fps</code> 为 <code>True</code> ，将当前帧的 FPS 添加到 <code>fps_list</code> 中。</li></ul><h4 id="总结-2"><a class="anchor" href="#总结-2">#</a> 总结</h4><p>这段代码的主要功能是处理视频流中的每一帧，进行目标检测和跟踪，并将结果存储起来。具体步骤包括：</p><ol><li><strong>初始化变量</strong>：初始化帧索引、结果列表、帧列表和 FPS 列表。</li><li><strong>处理视频流</strong>：遍历视频的每一帧。</li><li><strong>统一模型处理</strong>：如果使用统一模型，调用 <code>inference_masa</code> 进行检测和跟踪。</li><li><strong>非统一模型处理</strong>：如果使用非统一模型，先调用 <code>inference_detector</code> 进行检测，再执行 NMS 去除冗余检测框，最后调用 <code>inference_masa</code> 进行跟踪。</li><li><strong>更新帧索引</strong>：增加帧索引。</li><li><strong>处理跟踪结果</strong>：处理跟踪结果中的掩码和检测框。</li><li><strong>存储结果</strong>：将当前帧的跟踪结果、原始帧和 FPS 存储起来。</li></ol><p>那么问题来了， <code>inference_masa</code> 是什么？</p><h4 id="inference_masa"><a class="anchor" href="#inference_masa">#</a> inference_masa</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">inference_masa</span>(<span class="params"></span></span><br><span class="line"><span class="params">    model: nn.Module,</span></span><br><span class="line"><span class="params">    img: np.ndarray,</span></span><br><span class="line"><span class="params">    frame_id: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">    video_len: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">    test_pipeline: <span class="type">Optional</span>[Compose] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    text_prompt=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    custom_entities: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    det_bboxes=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    det_labels=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    fp16=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    detector_type=<span class="string">&quot;mmdet&quot;</span>,</span></span><br><span class="line"><span class="params">    show_fps=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; SampleList:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Inference image(s) with the masa model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        model (nn.Module): The loaded mot model.</span></span><br><span class="line"><span class="string">        img (np.ndarray): Loaded image.</span></span><br><span class="line"><span class="string">        frame_id (int): frame id.</span></span><br><span class="line"><span class="string">        video_len (int): demo video length</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        SampleList: The tracking data samples.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    data = <span class="built_in">dict</span>(</span><br><span class="line">        img=[img.astype(np.float32)],</span><br><span class="line">        <span class="comment"># img=[img.astype(np.uint8)],</span></span><br><span class="line">        frame_id=[frame_id],</span><br><span class="line">        ori_shape=[img.shape[:<span class="number">2</span>]],</span><br><span class="line">        img_id=[frame_id + <span class="number">1</span>],</span><br><span class="line">        ori_video_length=[video_len],</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> text_prompt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> detector_type == <span class="string">&quot;mmdet&quot;</span>:</span><br><span class="line">            data[<span class="string">&quot;text&quot;</span>] = [text_prompt]</span><br><span class="line">            data[<span class="string">&quot;custom_entities&quot;</span>] = [custom_entities]</span><br><span class="line">        <span class="keyword">elif</span> detector_type == <span class="string">&quot;yolo-world&quot;</span>:</span><br><span class="line">            data[<span class="string">&quot;texts&quot;</span>] = [text_prompt]</span><br><span class="line">            data[<span class="string">&quot;custom_entities&quot;</span>] = [custom_entities]</span><br><span class="line"></span><br><span class="line">    data = test_pipeline(data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward the model</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        data = default_collate([data])</span><br><span class="line">        <span class="keyword">if</span> det_bboxes <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            data[<span class="string">&quot;data_samples&quot;</span>][<span class="number">0</span>].video_data_samples[<span class="number">0</span>].det_bboxes = det_bboxes</span><br><span class="line">            data[<span class="string">&quot;data_samples&quot;</span>][<span class="number">0</span>].video_data_samples[<span class="number">0</span>].det_labels = det_labels</span><br><span class="line">        <span class="comment"># measure FPS ##</span></span><br><span class="line">        <span class="keyword">if</span> show_fps:</span><br><span class="line">            start = time.time()</span><br><span class="line">            <span class="keyword">with</span> autocast(enabled=fp16):</span><br><span class="line">                result = model.test_step(data)[<span class="number">0</span>]</span><br><span class="line">            end = time.time()</span><br><span class="line">            fps = <span class="number">1</span> / (end - start)</span><br><span class="line">            <span class="keyword">return</span> result, fps</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">with</span> autocast(enabled=fp16):</span><br><span class="line">                result = model.test_step(data)[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><p>这段代码定义了一个函数 <code>inference_masa</code> ，用于使用 MASA 模型对图像进行推理，返回跟踪数据样本。函数接受多个参数，包括模型、图像、帧 ID、视频长度、测试管道、文本提示、自定义实体、检测框、标签、是否使用半精度浮点数、检测器类型和是否显示 FPS。下面是对这段代码的详细解释：</p><h5 id="函数定义和参数-2"><a class="anchor" href="#函数定义和参数-2">#</a> 函数定义和参数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">inference_masa</span>(<span class="params"></span></span><br><span class="line"><span class="params">    model: nn.Module,</span></span><br><span class="line"><span class="params">    img: np.ndarray,</span></span><br><span class="line"><span class="params">    frame_id: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">    video_len: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">    test_pipeline: <span class="type">Optional</span>[Compose] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    text_prompt=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    custom_entities: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    det_bboxes=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    det_labels=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    fp16=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    detector_type=<span class="string">&quot;mmdet&quot;</span>,</span></span><br><span class="line"><span class="params">    show_fps=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; SampleList:</span><br></pre></td></tr></table></figure><ul><li><strong><code>model</code> </strong>：已经加载的目标跟踪模型。</li><li><strong><code>img</code> </strong>：输入的图像，类型为 <code>np.ndarray</code> 。</li><li><strong><code>frame_id</code> </strong>：当前帧的 ID。</li><li><strong><code>video_len</code> </strong>：视频的总帧数。</li><li><strong><code>test_pipeline</code> </strong>：测试数据处理管道，可选参数。</li><li><strong><code>text_prompt</code> </strong>：文本提示，可选参数。</li><li><strong><code>custom_entities</code> </strong>：是否使用自定义实体，可选参数，默认为 <code>False</code> 。</li><li><strong><code>det_bboxes</code> </strong>：预检测的边界框，可选参数。</li><li><strong><code>det_labels</code> </strong>：预检测的标签，可选参数。</li><li><strong><code>fp16</code> </strong>：是否使用半精度浮点数，可选参数，默认为 <code>False</code> 。</li><li><strong><code>detector_type</code> </strong>：检测器类型，可选参数，默认为 <code>&quot;mmdet&quot;</code> 。</li><li><strong><code>show_fps</code> </strong>：是否显示 FPS，可选参数，默认为 <code>False</code> 。</li></ul><h5 id="函数文档字符串"><a class="anchor" href="#函数文档字符串">#</a> 函数文档字符串</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Inference image(s) with the masa model.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Args:</span></span><br><span class="line"><span class="string">    model (nn.Module): The loaded mot model.</span></span><br><span class="line"><span class="string">    img (np.ndarray): Loaded image.</span></span><br><span class="line"><span class="string">    frame_id (int): frame id.</span></span><br><span class="line"><span class="string">    video_len (int): demo video length</span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">    SampleList: The tracking data samples.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure><ul><li><strong>文档字符串</strong>：描述了函数的功能、参数和返回值。</li></ul><h5 id="准备数据"><a class="anchor" href="#准备数据">#</a> 准备数据</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">data = <span class="built_in">dict</span>(</span><br><span class="line">    img=[img.astype(np.float32)],</span><br><span class="line">    <span class="comment"># img=[img.astype(np.uint8)],</span></span><br><span class="line">    frame_id=[frame_id],</span><br><span class="line">    ori_shape=[img.shape[:<span class="number">2</span>]],</span><br><span class="line">    img_id=[frame_id + <span class="number">1</span>],</span><br><span class="line">    ori_video_length=[video_len],</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ul><li><strong>数据字典</strong>：准备输入数据的字典。<ul><li><code>img</code> ：将图像转换为 <code>float32</code> 类型，并放入列表中。</li><li><code>frame_id</code> ：当前帧的 ID。</li><li><code>ori_shape</code> ：图像的原始形状（高度和宽度）。</li><li><code>img_id</code> ：图像的唯一标识符，通常是帧 ID 加 1。</li><li><code>ori_video_length</code> ：视频的总帧数。</li></ul></li></ul><h5 id="添加文本提示"><a class="anchor" href="#添加文本提示">#</a> 添加文本提示</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> text_prompt <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">if</span> detector_type == <span class="string">&quot;mmdet&quot;</span>:</span><br><span class="line">        data[<span class="string">&quot;text&quot;</span>] = [text_prompt]</span><br><span class="line">        data[<span class="string">&quot;custom_entities&quot;</span>] = [custom_entities]</span><br><span class="line">    <span class="keyword">elif</span> detector_type == <span class="string">&quot;yolo-world&quot;</span>:</span><br><span class="line">        data[<span class="string">&quot;texts&quot;</span>] = [text_prompt]</span><br><span class="line">        data[<span class="string">&quot;custom_entities&quot;</span>] = [custom_entities]</span><br></pre></td></tr></table></figure><ul><li><strong>条件判断</strong>：如果提供了文本提示，根据检测器类型（ <code>mmdet</code> 或 <code>yolo-world</code> ）将文本提示和自定义实体添加到数据字典中。</li></ul><h5 id="应用测试管道"><a class="anchor" href="#应用测试管道">#</a> 应用测试管道</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = test_pipeline(data)</span><br></pre></td></tr></table></figure><ul><li><strong>测试管道</strong>：使用 <code>test_pipeline</code> 对数据进行预处理。</li></ul><h5 id="前向传播模型"><a class="anchor" href="#前向传播模型">#</a> 前向传播模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    data = default_collate([data])</span><br><span class="line">    <span class="keyword">if</span> det_bboxes <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        data[<span class="string">&quot;data_samples&quot;</span>][<span class="number">0</span>].video_data_samples[<span class="number">0</span>].det_bboxes = det_bboxes</span><br><span class="line">        data[<span class="string">&quot;data_samples&quot;</span>][<span class="number">0</span>].video_data_samples[<span class="number">0</span>].det_labels = det_labels</span><br></pre></td></tr></table></figure><ul><li><strong>禁用梯度计算</strong>：使用 <code>torch.no_grad()</code> 禁用梯度计算，减少内存消耗。</li><li><strong>数据整理</strong>：使用 <code>default_collate</code> 将数据整理成模型所需的格式。</li><li><strong>添加检测框</strong>：如果提供了检测框和标签，将它们添加到数据样本中。</li></ul><h5 id="测量fps"><a class="anchor" href="#测量fps">#</a> 测量 FPS</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> show_fps:</span><br><span class="line">    start = time.time()</span><br><span class="line">    <span class="keyword">with</span> autocast(enabled=fp16):</span><br><span class="line">        result = model.test_step(data)[<span class="number">0</span>]</span><br><span class="line">    end = time.time()</span><br><span class="line">    fps = <span class="number">1</span> / (end - start)</span><br><span class="line">    <span class="keyword">return</span> result, fps</span><br></pre></td></tr></table></figure><ul><li><strong>测量开始时间</strong>：如果 <code>show_fps</code> 为 <code>True</code> ，记录前向传播的开始时间。</li><li><strong>前向传播</strong>：使用 <code>autocast</code> 自动选择精度（如果 <code>fp16</code> 为 <code>True</code> ，则使用半精度浮点数）进行前向传播。</li><li><strong>测量结束时间</strong>：记录前向传播的结束时间。</li><li><strong>计算 FPS</strong>：计算并返回 FPS。</li><li><strong>返回结果和 FPS</strong>：返回推理结果和 FPS。</li></ul><h5 id="不测量fps"><a class="anchor" href="#不测量fps">#</a> 不测量 FPS</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">with</span> autocast(enabled=fp16):</span><br><span class="line">        result = model.test_step(data)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure><ul><li><strong>前向传播</strong>：如果不测量 FPS，直接进行前向传播。</li><li><strong>返回结果</strong>：返回推理结果。</li></ul><h5 id="总结-3"><a class="anchor" href="#总结-3">#</a> 总结</h5><p>这段代码的主要功能是使用 MASA 模型对图像进行推理，返回跟踪数据样本。具体步骤包括：</p><ol><li><strong>准备数据</strong>：将图像和相关信息组织成数据字典。</li><li><strong>添加文本提示</strong>：如果提供了文本提示，根据检测器类型将其添加到数据字典中。</li><li><strong>应用测试管道</strong>：使用测试管道对数据进行预处理。</li><li><strong>前向传播模型</strong>：禁用梯度计算，整理数据，进行前向传播。</li><li><strong>测量 FPS</strong>：如果需要，测量并返回 FPS。</li><li><strong>返回结果</strong>：返回推理结果和（可选的）FPS。</li></ol><p>希望这些解释能帮助你更好地理解这段代码的功能和作用。如果你有任何进一步的问题，欢迎随时提问！</p><hr><p>让我们再次回到 video_demo-with_text 的代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> args.no_post:</span><br><span class="line">    instances_list = filter_and_update_tracks(instances_list, (frame.shape[<span class="number">1</span>], frame.shape[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.sam_mask:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Start to generate mask using SAM!&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> idx, (frame, track_result) <span class="keyword">in</span> tqdm.tqdm(<span class="built_in">enumerate</span>(<span class="built_in">zip</span>(frames, instances_list))):</span><br><span class="line">        track_result = track_result.to(device)</span><br><span class="line">        track_result[<span class="number">0</span>].pred_track_instances.instances_id = track_result[<span class="number">0</span>].pred_track_instances.instances_id.to(device)</span><br><span class="line">        track_result[<span class="number">0</span>].pred_track_instances = track_result[<span class="number">0</span>].pred_track_instances[(track_result[<span class="number">0</span>].pred_track_instances.scores.<span class="built_in">float</span>() &gt; args.score_thr).to(device)]</span><br><span class="line">        input_boxes = track_result[<span class="number">0</span>].pred_track_instances.bboxes</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(input_boxes) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        sam_predictor.set_image(frame)</span><br><span class="line">        transformed_boxes = sam_predictor.transform.apply_boxes_torch(input_boxes, frame.shape[:<span class="number">2</span>])</span><br><span class="line">        masks, _, _ = sam_predictor.predict_torch(</span><br><span class="line">            point_coords=<span class="literal">None</span>,</span><br><span class="line">            point_labels=<span class="literal">None</span>,</span><br><span class="line">            boxes=transformed_boxes,</span><br><span class="line">            multimask_output=<span class="literal">False</span>,</span><br><span class="line">        )</span><br><span class="line">        track_result[<span class="number">0</span>].pred_track_instances.masks = masks.squeeze(<span class="number">1</span>).cpu().numpy()</span><br><span class="line">        instances_list[idx] = track_result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.out:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Start to visualize the results...&#x27;</span>)</span><br><span class="line">    num_cores = <span class="built_in">max</span>(<span class="number">1</span>, <span class="built_in">min</span>(os.cpu_count() - <span class="number">1</span>, <span class="number">16</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; cores for visualization&#x27;</span>.<span class="built_in">format</span>(num_cores))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.show_fps:</span><br><span class="line">        <span class="keyword">with</span> Pool(processes=num_cores) <span class="keyword">as</span> pool:</span><br><span class="line"></span><br><span class="line">            frames = pool.starmap(</span><br><span class="line">                visualize_frame, [(args, visualizer, frame, track_result.to(<span class="string">&#x27;cpu&#x27;</span>), idx, fps) <span class="keyword">for</span> idx, (frame, fps, track_result) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(frames, fps_list, instances_list))]</span><br><span class="line">            )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">with</span> Pool(processes=num_cores) <span class="keyword">as</span> pool:</span><br><span class="line">            frames = pool.starmap(</span><br><span class="line">                visualize_frame, [(args, visualizer, frame, track_result.to(<span class="string">&#x27;cpu&#x27;</span>), idx) <span class="keyword">for</span> idx, (frame, track_result) <span class="keyword">in</span></span><br><span class="line">                                  <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(frames, instances_list))]</span><br><span class="line">            )</span><br><span class="line">    <span class="keyword">for</span> frame <span class="keyword">in</span> frames:</span><br><span class="line">        <span class="keyword">if</span> args.out:</span><br><span class="line">            video_writer.write(frame[:, :, ::-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> video_writer:</span><br><span class="line">    video_writer.release()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Done&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这段代码的主要功能是在完成目标检测和跟踪后，进行后处理、生成掩码、可视化结果，并将结果保存到输出视频文件中。下面是逐段解释：</p><h5 id="后处理跟踪结果"><a class="anchor" href="#后处理跟踪结果">#</a> 后处理跟踪结果</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> args.no_post:</span><br><span class="line">    instances_list = filter_and_update_tracks(instances_list, (frame.shape[<span class="number">1</span>], frame.shape[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><ul><li><strong>条件判断</strong>：如果命令行参数 <code>args.no_post</code> 为 <code>False</code> ，表示需要进行后处理。</li><li><strong>后处理</strong>：调用 <code>filter_and_update_tracks</code> 函数对 <code>instances_list</code> 进行过滤和更新。参数包括：<ul><li><code>instances_list</code> ：所有帧的跟踪结果列表。</li><li><code>(frame.shape[1], frame.shape[0])</code> ：当前帧的宽度和高度。</li></ul></li></ul><h5 id="使用sam生成掩码"><a class="anchor" href="#使用sam生成掩码">#</a> 使用 SAM 生成掩码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.sam_mask:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Start to generate mask using SAM!&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> idx, (frame, track_result) <span class="keyword">in</span> tqdm.tqdm(<span class="built_in">enumerate</span>(<span class="built_in">zip</span>(frames, instances_list))):</span><br><span class="line">        track_result = track_result.to(device)</span><br><span class="line">        track_result[<span class="number">0</span>].pred_track_instances.instances_id = track_result[<span class="number">0</span>].pred_track_instances.instances_id.to(device)</span><br><span class="line">        track_result[<span class="number">0</span>].pred_track_instances = track_result[<span class="number">0</span>].pred_track_instances[(track_result[<span class="number">0</span>].pred_track_instances.scores.<span class="built_in">float</span>() &gt; args.score_thr).to(device)]</span><br><span class="line">        input_boxes = track_result[<span class="number">0</span>].pred_track_instances.bboxes</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(input_boxes) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        sam_predictor.set_image(frame)</span><br><span class="line">        transformed_boxes = sam_predictor.transform.apply_boxes_torch(input_boxes, frame.shape[:<span class="number">2</span>])</span><br><span class="line">        masks, _, _ = sam_predictor.predict_torch(</span><br><span class="line">            point_coords=<span class="literal">None</span>,</span><br><span class="line">            point_labels=<span class="literal">None</span>,</span><br><span class="line">            boxes=transformed_boxes,</span><br><span class="line">            multimask_output=<span class="literal">False</span>,</span><br><span class="line">        )</span><br><span class="line">        track_result[<span class="number">0</span>].pred_track_instances.masks = masks.squeeze(<span class="number">1</span>).cpu().numpy()</span><br><span class="line">        instances_list[idx] = track_result</span><br></pre></td></tr></table></figure><ul><li><strong>条件判断</strong>：如果命令行参数 <code>args.sam_mask</code> 为 <code>True</code> ，表示需要生成掩码。</li><li><strong>生成掩码</strong>：<ul><li><strong>遍历帧</strong>：使用 <code>tqdm</code> 显示进度条，遍历所有帧和对应的跟踪结果。</li><li><strong>移动数据到设备</strong>：将 <code>track_result</code> 移动到指定设备（通常是 GPU）。</li><li><strong>过滤低置信度实例</strong>：仅保留置信度高于 <code>args.score_thr</code> 的实例。</li><li><strong>获取检测框</strong>：提取检测框 <code>input_boxes</code> 。</li><li><strong>跳过无检测框的帧</strong>：如果当前帧没有检测框，跳过该帧。</li><li><strong>设置图像</strong>：使用 <code>sam_predictor.set_image</code> 设置当前帧的图像。</li><li><strong>变换检测框</strong>：使用 <code>sam_predictor.transform.apply_boxes_torch</code> 变换检测框。</li><li><strong>生成掩码</strong>：调用 <code>sam_predictor.predict_torch</code> 生成掩码。</li><li><strong>更新掩码</strong>：将生成的掩码添加到 <code>track_result</code> 中，并更新 <code>instances_list</code> 。</li></ul></li></ul><h5 id="可视化结果"><a class="anchor" href="#可视化结果">#</a> 可视化结果</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.out:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Start to visualize the results...&#x27;</span>)</span><br><span class="line">    num_cores = <span class="built_in">max</span>(<span class="number">1</span>, <span class="built_in">min</span>(os.cpu_count() - <span class="number">1</span>, <span class="number">16</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Using &#123;&#125; cores for visualization&#x27;</span>.<span class="built_in">format</span>(num_cores))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.show_fps:</span><br><span class="line">        <span class="keyword">with</span> Pool(processes=num_cores) <span class="keyword">as</span> pool:</span><br><span class="line">            frames = pool.starmap(</span><br><span class="line">                visualize_frame, [(args, visualizer, frame, track_result.to(<span class="string">&#x27;cpu&#x27;</span>), idx, fps) <span class="keyword">for</span> idx, (frame, fps, track_result) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(frames, fps_list, instances_list))]</span><br><span class="line">            )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">with</span> Pool(processes=num_cores) <span class="keyword">as</span> pool:</span><br><span class="line">            frames = pool.starmap(</span><br><span class="line">                visualize_frame, [(args, visualizer, frame, track_result.to(<span class="string">&#x27;cpu&#x27;</span>), idx) <span class="keyword">for</span> idx, (frame, track_result) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(frames, instances_list))]</span><br><span class="line">            )</span><br><span class="line">    <span class="keyword">for</span> frame <span class="keyword">in</span> frames:</span><br><span class="line">        <span class="keyword">if</span> args.out:</span><br><span class="line">            video_writer.write(frame[:, :, ::-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><ul><li><strong>条件判断</strong>：如果命令行参数 <code>args.out</code> 不为 <code>None</code> ，表示需要将结果保存到输出视频文件。</li><li><strong>多进程可视化</strong>：<ul><li><strong>确定核心数</strong>：计算可用的核心数，最多使用 16 个核心。</li><li><strong>显示核心数</strong>：打印使用的核芯数。</li><li><strong>创建进程池</strong>：使用 <code>Pool</code> 创建多进程池。</li><li><strong>调用可视化函数</strong>：<ul><li>如果 <code>args.show_fps</code> 为 <code>True</code> ，调用 <code>visualize_frame</code> 函数，传递 <code>args</code> 、 <code>visualizer</code> 、 <code>frame</code> 、 <code>track_result</code> 、 <code>idx</code> 和 <code>fps</code> 。</li><li>如果 <code>args.show_fps</code> 为 <code>False</code> ，调用 <code>visualize_frame</code> 函数，传递 <code>args</code> 、 <code>visualizer</code> 、 <code>frame</code> 、 <code>track_result</code> 和 <code>idx</code> 。</li></ul></li><li><strong>写入视频</strong>：遍历处理后的帧，将每一帧写入视频文件。注意 <code>frame[:, :, ::-1]</code> 是将图像从 RGB 格式转换为 BGR 格式，因为 OpenCV 使用 BGR 格式。</li></ul></li></ul><h5 id="释放视频写入器"><a class="anchor" href="#释放视频写入器">#</a> 释放视频写入器</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> video_writer:</span><br><span class="line">    video_writer.release()</span><br></pre></td></tr></table></figure><ul><li><strong>释放资源</strong>：如果 <code>video_writer</code> 不为 <code>None</code> ，释放视频写入器资源。</li></ul><h5 id="完成"><a class="anchor" href="#完成">#</a> 完成</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Done&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>打印完成信息</strong>：打印 “Done” 表示处理完成。</li></ul><h5 id="总结-4"><a class="anchor" href="#总结-4">#</a> 总结</h5><p>这段代码的主要功能是：</p><ol><li><strong>后处理跟踪结果</strong>：如果需要，对跟踪结果进行过滤和更新。</li><li><strong>生成掩码</strong>：如果需要，使用 SAM 模型生成掩码并更新跟踪结果。</li><li><strong>可视化结果</strong>：使用多进程并行处理，将跟踪结果可视化并保存到输出视频文件中。</li><li><strong>释放资源</strong>：释放视频写入器资源。</li><li><strong>打印完成信息</strong>：打印处理完成的信息。</li></ol><p>希望这些解释能帮助你更好地理解这段代码的功能和作用。如果你有任何进一步的问题，欢迎随时提问！</p><h2 id="后记"><a class="anchor" href="#后记">#</a> 后记</h2><p>至此针对这个文件的操作的代码已经全部解析完毕，很正常的是看上去我现在完全没有搞懂它究竟怎么实现的，所以会继续针对论文结合代码进行一边梳理，估计那个时候就能全部搞懂了。</p><div class="tags"><a href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E7%B1%BB/" rel="tag"><i class="ic i-tag"></i> 学习笔记类</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" rel="tag"><i class="ic i-tag"></i> 计算机视觉</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2025-04-30 10:51:14" itemprop="dateModified" datetime="2025-04-30T10:51:14+08:00">2025-04-30</time> </span><span id="article/Matching-Anything-by-Segmenting-Anything/" class="item leancloud_visitors" data-flag-title="Matching_Anything_by_Segmenting_Anything" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>Lemon Sour <i class="ic i-at"><em>@</em></i></li><li class="link"><strong>本文链接：</strong> <a href="http://amentiraz.github.io/article/Matching-Anything-by-Segmenting-Anything/" title="Matching_Anything_by_Segmenting_Anything">http://amentiraz.github.io/article/Matching-Anything-by-Segmenting-Anything/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC96aC1DTg=="><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/code/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;amentirazblogpic.oss-cn-hangzhou.aliyuncs.com&#x2F;blogpic&#x2F;%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925124354.jpg" title="深度学习学习笔记"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 编程语言</span><h3>深度学习学习笔记</h3></a></div><div class="item right"><a href="/article/SpaGCN/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;amentirazblogpic.oss-cn-hangzhou.aliyuncs.com&#x2F;blogpic&#x2F;%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925162904.jpg" title="SpaGCN"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 论文</span><h3>SpaGCN</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#introduction"><span class="toc-number">2.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#related-work"><span class="toc-number">3.</span> <span class="toc-text">Related Work</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#learning-instance-level-association"><span class="toc-number">3.1.</span> <span class="toc-text">Learning Instance-level Association</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#segment-and-track-anythin-models"><span class="toc-number">3.2.</span> <span class="toc-text">Segment and Track Anythin Models</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#method"><span class="toc-number">4.</span> <span class="toc-text">Method</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#preliminaries-sam"><span class="toc-number">4.1.</span> <span class="toc-text">Preliminaries: SAM</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#matching-anythin-by-segmenting-anything"><span class="toc-number">4.2.</span> <span class="toc-text">Matching Anythin by Segmenting Anything</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#masa-pipeline"><span class="toc-number">4.2.1.</span> <span class="toc-text">MASA Pipeline</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#masa-adapter"><span class="toc-number">4.2.2.</span> <span class="toc-text">MASA Adapter</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#inference"><span class="toc-number">4.2.3.</span> <span class="toc-text">Inference</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#detect-and-track-anythin"><span class="toc-number">4.2.3.1.</span> <span class="toc-text">Detect and Track Anythin</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#segment-and-track-anything"><span class="toc-number">4.2.3.2.</span> <span class="toc-text">Segment and Track Anything</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#testing-with-given-observations"><span class="toc-number">4.2.3.3.</span> <span class="toc-text">Testing with Given Observations</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#experiments"><span class="toc-number">5.</span> <span class="toc-text">Experiments</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E9%83%A8%E5%88%86"><span class="toc-number">6.</span> <span class="toc-text">代码部分</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83"><span class="toc-number">6.1.</span> <span class="toc-text">环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-number">6.2.</span> <span class="toc-text">代码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#video_demo_with_text"><span class="toc-number">6.2.1.</span> <span class="toc-text">video_demo_with_text</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#masa_gdino_swinb_inference"><span class="toc-number">6.2.1.1.</span> <span class="toc-text">masa_gdino_swinb_inference</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#fpn"><span class="toc-number">6.2.1.1.1.</span> <span class="toc-text">FPN</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#deformfusion"><span class="toc-number">6.2.1.1.2.</span> <span class="toc-text">DeformFusion</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8C%BA%E5%9F%9F%E6%8F%90%E8%AE%AE%E7%BD%91%E7%BB%9Crpn%E5%92%8Croi%E5%A4%B4"><span class="toc-number">6.2.1.1.3.</span> <span class="toc-text">区域提议网络 (RPN) 和 ROI 头</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#gdino_masapth"><span class="toc-number">6.2.1.2.</span> <span class="toc-text">gdino_masa.pth</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#init_masa"><span class="toc-number">6.2.1.3.</span> <span class="toc-text">init_masa</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E5%AE%9A%E4%B9%89%E5%92%8C%E5%8F%82%E6%95%B0"><span class="toc-number">6.2.1.3.1.</span> <span class="toc-text">函数定义和参数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%87%E6%A1%A3%E5%AD%97%E7%AC%A6%E4%B8%B2"><span class="toc-number">6.2.1.3.2.</span> <span class="toc-text">文档字符串</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">6.2.1.3.3.</span> <span class="toc-text">处理配置文件</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E9%85%8D%E7%BD%AE%E9%80%89%E9%A1%B9"><span class="toc-number">6.2.1.3.4.</span> <span class="toc-text">处理配置选项</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E9%BB%98%E8%AE%A4%E4%BD%9C%E7%94%A8%E5%9F%9F"><span class="toc-number">6.2.1.3.5.</span> <span class="toc-text">初始化默认作用域</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.2.1.3.6.</span> <span class="toc-text">构建模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%9D%83%E9%87%8D"><span class="toc-number">6.2.1.3.7.</span> <span class="toc-text">加载预训练权重</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E8%B0%83%E8%89%B2%E6%9D%BF"><span class="toc-number">6.2.1.3.8.</span> <span class="toc-text">设置调色板</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98%E9%85%8D%E7%BD%AE%E5%92%8C%E8%AE%BE%E7%BD%AE%E8%AE%BE%E5%A4%87"><span class="toc-number">6.2.1.3.9.</span> <span class="toc-text">保存配置和设置设备</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.2.1.3.10.</span> <span class="toc-text">返回模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">6.2.1.3.11.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%98%E9%87%8F"><span class="toc-number">6.2.1.4.</span> <span class="toc-text">初始化变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E8%A7%86%E9%A2%91%E6%B5%81"><span class="toc-number">6.2.1.5.</span> <span class="toc-text">处理视频流</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%9F%E4%B8%80%E6%A8%A1%E5%9E%8B%E5%A4%84%E7%90%86"><span class="toc-number">6.2.1.6.</span> <span class="toc-text">统一模型处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%9E%E7%BB%9F%E4%B8%80%E6%A8%A1%E5%9E%8B%E5%A4%84%E7%90%86"><span class="toc-number">6.2.1.7.</span> <span class="toc-text">非统一模型处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6nms"><span class="toc-number">6.2.1.8.</span> <span class="toc-text">执行非极大值抑制（NMS）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9B%B4%E6%96%B0%E6%A3%80%E6%B5%8B%E7%BB%93%E6%9E%9C"><span class="toc-number">6.2.1.9.</span> <span class="toc-text">更新检测结果</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9B%E8%A1%8C%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA"><span class="toc-number">6.2.1.10.</span> <span class="toc-text">进行目标跟踪</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9B%B4%E6%96%B0%E5%B8%A7%E7%B4%A2%E5%BC%95"><span class="toc-number">6.2.1.11.</span> <span class="toc-text">更新帧索引</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E8%B7%9F%E8%B8%AA%E7%BB%93%E6%9E%9C"><span class="toc-number">6.2.1.12.</span> <span class="toc-text">处理跟踪结果</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9B%B4%E6%96%B0%E6%A3%80%E6%B5%8B%E6%A1%86%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">6.2.1.13.</span> <span class="toc-text">更新检测框的数据类型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%9C"><span class="toc-number">6.2.1.14.</span> <span class="toc-text">存储结果</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-2"><span class="toc-number">6.2.1.15.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#inference_masa"><span class="toc-number">6.2.1.16.</span> <span class="toc-text">inference_masa</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E5%AE%9A%E4%B9%89%E5%92%8C%E5%8F%82%E6%95%B0-2"><span class="toc-number">6.2.1.16.1.</span> <span class="toc-text">函数定义和参数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E6%96%87%E6%A1%A3%E5%AD%97%E7%AC%A6%E4%B8%B2"><span class="toc-number">6.2.1.16.2.</span> <span class="toc-text">函数文档字符串</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE"><span class="toc-number">6.2.1.16.3.</span> <span class="toc-text">准备数据</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0%E6%96%87%E6%9C%AC%E6%8F%90%E7%A4%BA"><span class="toc-number">6.2.1.16.4.</span> <span class="toc-text">添加文本提示</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E6%B5%8B%E8%AF%95%E7%AE%A1%E9%81%93"><span class="toc-number">6.2.1.16.5.</span> <span class="toc-text">应用测试管道</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.2.1.16.6.</span> <span class="toc-text">前向传播模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B5%8B%E9%87%8Ffps"><span class="toc-number">6.2.1.16.7.</span> <span class="toc-text">测量 FPS</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%8D%E6%B5%8B%E9%87%8Ffps"><span class="toc-number">6.2.1.16.8.</span> <span class="toc-text">不测量 FPS</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-3"><span class="toc-number">6.2.1.16.9.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%90%8E%E5%A4%84%E7%90%86%E8%B7%9F%E8%B8%AA%E7%BB%93%E6%9E%9C"><span class="toc-number">6.2.1.16.10.</span> <span class="toc-text">后处理跟踪结果</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8sam%E7%94%9F%E6%88%90%E6%8E%A9%E7%A0%81"><span class="toc-number">6.2.1.16.11.</span> <span class="toc-text">使用 SAM 生成掩码</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8F%AF%E8%A7%86%E5%8C%96%E7%BB%93%E6%9E%9C"><span class="toc-number">6.2.1.16.12.</span> <span class="toc-text">可视化结果</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%87%8A%E6%94%BE%E8%A7%86%E9%A2%91%E5%86%99%E5%85%A5%E5%99%A8"><span class="toc-number">6.2.1.16.13.</span> <span class="toc-text">释放视频写入器</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%8C%E6%88%90"><span class="toc-number">6.2.1.16.14.</span> <span class="toc-text">完成</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-4"><span class="toc-number">6.2.1.16.15.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%8E%E8%AE%B0"><span class="toc-number">6.3.</span> <span class="toc-text">后记</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/article/scRNA%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" rel="bookmark" title="scRNA论文笔记">scRNA论文笔记</a></li><li><a href="/article/What-is-A-Cell-Type/" rel="bookmark" title="What_is_A_Cell_Type">What_is_A_Cell_Type</a></li><li><a href="/article/Cell-Review-What-is-a-cell-type-and-how-to-define-it/" rel="bookmark" title="Cell_Review_What_is_a_cell_type_and_how_to_define_it">Cell_Review_What_is_a_cell_type_and_how_to_define_it</a></li><li><a href="/article/Benchmarking-spatial-claustering-methods-with-spatially-resolved-transcriptomic-data/" rel="bookmark" title="Benchmarking-spatial-claustering-methods-with-spatially-resolved-transcriptomic-data">Benchmarking-spatial-claustering-methods-with-spatially-resolved-transcriptomic-data</a></li><li><a href="/article/%E8%AE%BA%E6%96%87ppt1/" rel="bookmark" title="论文ppt1">论文ppt1</a></li><li class="active"><a href="/article/Matching-Anything-by-Segmenting-Anything/" rel="bookmark" title="Matching_Anything_by_Segmenting_Anything">Matching_Anything_by_Segmenting_Anything</a></li><li><a href="/article/SpaGCN/" rel="bookmark" title="SpaGCN">SpaGCN</a></li><li><a href="/article/STAGATE/" rel="bookmark" title="STAGATE">STAGATE</a></li><li><a href="/article/MENDER/" rel="bookmark" title="MENDER">MENDER</a></li><li><a href="/article/scanpy%E6%95%B0%E6%8D%AE%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/" rel="bookmark" title="scanpy数据使用笔记">scanpy数据使用笔记</a></li><li><a href="/article/BayesSpace/" rel="bookmark" title="BayesSpace">BayesSpace</a></li><li><a href="/article/%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%B0%E5%BD%95/" rel="bookmark" title="数据集记录">数据集记录</a></li><li><a href="/article/DeepST/" rel="bookmark" title="DeepST">DeepST</a></li><li><a href="/article/EnSDD/" rel="bookmark" title="EnSDD">EnSDD</a></li><li><a href="/article/domain%E5%86%85%E5%AE%B9%E7%9A%84%E6%80%BB%E7%BB%93/" rel="bookmark" title="对spatial domain内容的总结">对spatial domain内容的总结</a></li><li><a href="/article/%E6%AF%95%E4%B8%9A%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3%E6%B1%87%E6%80%BB/" rel="bookmark" title="毕业设计文档汇总">毕业设计文档汇总</a></li><li><a href="/article/scPerturb/" rel="bookmark" title="scPerturb">scPerturb</a></li><li><a href="/GEARS/" rel="bookmark" title="GEARS">GEARS</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Lemon Sour" data-src="/images/avatar.jpg"><p class="name" itemprop="name">Lemon Sour</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">83</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">26</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">57</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL0FtZW50aXJheg==" title="https:&#x2F;&#x2F;github.com&#x2F;Amentiraz"><i class="ic i-github"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9kc2ZseS04" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;dsfly-8"><i class="ic i-zhihu"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTE1MTc2ODUzMzM=" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;1517685333"><i class="ic i-cloud-music"></i></span> <span class="exturl item email" data-url="bWFpbHRvOnZpb2xlbW9uQDE2My5jb20=" title="mailto:violemon@163.com"><i class="ic i-envelope"></i></span> <span class="exturl item bangumi" data-url="aHR0cHM6Ly9iYW5ndW1pLnR2L2FuaW1lL2xpc3QvNjY4MDE2" title="https:&#x2F;&#x2F;bangumi.tv&#x2F;anime&#x2F;list&#x2F;668016"><i class="ic i-bilibili"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-magic"></i>关于</a><ul class="submenu"><li class="item"><a href="/author/" rel="section"><i class="ic i-user"></i>本人</a></li></ul></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-cloud"></i>其它</a><ul class="submenu"><li class="item"><a href="/music/" rel="section"><i class="ic i-music"></i>音乐区</a></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>朋友</a></li></ul></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/code/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/article/SpaGCN/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/life/" title="分类于 生活">生活</a> <i class="ic i-angle-right"></i> <a href="/categories/life/%E6%80%9D%E8%80%83/" title="分类于 思考">思考</a></div><span><a href="/life/%E5%85%B3%E4%BA%8E%E9%9D%A2%E5%AD%94%E7%9A%84%E5%90%AB%E4%B9%89/" title="关于面孔的含义">关于面孔的含义</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/note/" title="分类于 影视书籍">影视书籍</a> <i class="ic i-angle-right"></i> <a href="/categories/note/%E4%B9%A6/" title="分类于 书">书</a></div><span><a href="/%E8%BF%98%E5%8E%9F%E4%B8%8E%E7%BB%99%E4%BA%88%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" title="还原与给予读书笔记">还原与给予读书笔记</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/note/" title="分类于 影视书籍">影视书籍</a> <i class="ic i-angle-right"></i> <a href="/categories/note/%E5%8A%A8%E6%BC%AB/" title="分类于 动漫">动漫</a></div><span><a href="/note/%E6%94%BB%E5%A3%B3%E6%9C%BA%E5%8A%A8%E9%98%9FSAC/" title="攻壳机动队SAC">攻壳机动队SAC</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/life/" title="分类于 生活">生活</a> <i class="ic i-angle-right"></i> <a href="/categories/life/%E6%80%9D%E8%80%83/" title="分类于 思考">思考</a></div><span><a href="/life/%E7%B2%BE%E7%A5%9E%E5%88%86%E6%9E%90%E4%B8%AD%E7%9A%84%E5%80%92%E9%94%99/" title="精神分析中的倒错">精神分析中的倒错</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/code/" title="分类于 代码">代码</a> <i class="ic i-angle-right"></i> <a href="/categories/code/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" title="分类于 数学建模">数学建模</a></div><span><a href="/code/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%A7%E4%BD%9C%E4%B8%9A/" title="分布式大作业">分布式大作业</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/code/" title="分类于 代码">代码</a> <i class="ic i-angle-right"></i> <a href="/categories/code/OI/" title="分类于 OI">OI</a></div><span><a href="/code/DP/" title="DP">DP</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/life/" title="分类于 生活">生活</a> <i class="ic i-angle-right"></i> <a href="/categories/life/%E6%BC%94%E5%A5%8F%E4%BC%9A/" title="分类于 演奏会">演奏会</a></div><span><a href="/life/%E8%A7%82%E9%83%91%E6%99%9F%E6%B2%B3%E6%BC%94%E5%A5%8F%E4%BC%9A%E6%9C%89%E6%84%9F/" title="观郑晟河演奏会有感">观郑晟河演奏会有感</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/article/" title="分类于 论文">论文</a></div><span><a href="/article/DeepST/" title="DeepST">DeepST</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/life/" title="分类于 生活">生活</a></div><span><a href="/life/2024%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/" title="2024年终总结">2024年终总结</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/note/" title="分类于 影视书籍">影视书籍</a> <i class="ic i-angle-right"></i> <a href="/categories/note/%E4%B9%A6/" title="分类于 书">书</a></div><span><a href="/note/%E3%80%8A%E6%83%85%E7%88%B1%E7%8E%B0%E8%B1%A1%E5%AD%A6%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" title="《情爱现象学》读书笔记">《情爱现象学》读书笔记</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Lemon Sour @ Amentiraz</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"article/Matching-Anything-by-Segmenting-Anything/",favicon:{show:"⁽⁽ଘ( ˊᵕˋ )ଓ⁾⁾",hide:"(つд⊂)"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,copy_tex:!0,katex:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->
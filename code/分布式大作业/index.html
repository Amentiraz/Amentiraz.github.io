<!-- build time:Sun Oct 26 2025 10:52:08 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" href="http://amentiraz.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" href="http://amentiraz.github.io/atom.xml"><link rel="alternate" type="application/json" href="http://amentiraz.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="代码,分布式"><link rel="canonical" href="http://amentiraz.github.io/code/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%A7%E4%BD%9C%E4%B8%9A/"><title>分布式大作业 - 数学建模 - 代码 | Amentiraz =</title><meta name="generator" content="Hexo 7.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">分布式大作业</h1><div class="meta"><span class="item" title="创建时间：2024-06-10 14:23:11"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2024-06-10T14:23:11+08:00">2024-06-10</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>18k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>17 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Amentiraz</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925124513.png"></li><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/wallhaven-e7pwdw.jpg"></li><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925124522.jpg"></li><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925124332.png"></li><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925124604.jpg"></li><li class="item" data-background-image="https://amentirazblogpic.oss-cn-hangzhou.aliyuncs.com/blogpic/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925162815.png"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/code/" itemprop="item" rel="index" title="分类于 代码"><span itemprop="name">代码</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/code/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/" itemprop="item" rel="index" title="分类于 数学建模"><span itemprop="name">数学建模</span></a><meta itemprop="position" content="2"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://amentiraz.github.io/code/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%A7%E4%BD%9C%E4%B8%9A/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Lemon Sour"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content=""></span><div class="body md" itemprop="articleBody"><p>配环境比写代码难一万倍 QAQ</p><span id="more"></span><p>不要使用 Docker 配置多节点环境！</p><p>不要使用 Docker 配置多节点环境！</p><p>不要使用 Docker 配置多节点环境！</p><p>如果你要使用 docker 请使用老师给的第二个 pdf 文件上的方案也就是配置单节点的环境。这个方案是可行的。但我并没有走这个方案，因为配多节点的时候我的系统环境产生了不可名状的变化，导致我配置单节点时仍然报错，所以这篇博客是针对本地配置 Hadoop 的文章</p><p>在整个问题中，你会遇到非常多次的需要下载老版本的情况，请认准 release archives 字样，它会带你去旧版本的下载界面，你会遇到多种多样的报错，请在报错时尝试清空 namenode 和 datanode 里面的文件重新配置。</p><h1 id="环境配置遇到的问题及解决方案"><a class="anchor" href="#环境配置遇到的问题及解决方案">#</a> 环境配置遇到的问题及解决方案</h1><h2 id="无法解压targz文件"><a class="anchor" href="#无法解压targz文件">#</a> 无法解压 tar.gz 文件？</h2><p>在<strong>打开管理员模式的命令提示符</strong>中，使用指令 tar -zxvf fileName.tar.gz</p><h2 id="nodemanager启动时遇到错误"><a class="anchor" href="#nodemanager启动时遇到错误">#</a> NodeManager 启动时遇到错误</h2><p>NodeManager 启动时遇到了一个 java.lang.ExceptionInInitializerError<br>原因是 JAVA 版本太高了，我用的是 java22，请重新下载 JAVA8 即 1.8 的版本<br>GPT 解释：特别是 Java 9 及其以上版本引入了模块系统（Jigsaw 项目），导致一些反射操作变得不可访问。而许多 Hadoop 的库和依赖项（比如 Guice 和 CGLIB）在设计时没有考虑到这些新的限制<br><span class="exturl" data-url="aHR0cHM6Ly93d3cub3JhY2xlLmNvbS9qYXZhL3RlY2hub2xvZ2llcy9qYXZhc2UvamF2YXNlLWpkazgtZG93bmxvYWRzLmh0bWw=">JAVA1.8 下载地址</span></p><h2 id="pyspark指令报错"><a class="anchor" href="#pyspark指令报错">#</a> pyspark 指令报错</h2><p>你的 Python 版本太高了<br>我这里直接采用了老师的那个版本<br><span class="exturl" data-url="aHR0cHM6Ly93d3cucHl0aG9uLm9yZy9mdHAvcHl0aG9uLzMuNi4zL3B5dGhvbi0zLjYuMy1hbWQ2NC5leGU=">python3.6.3</span></p><h2 id="卡在running-job后不动了"><a class="anchor" href="#卡在running-job后不动了">#</a> 卡在 running job 后不动了</h2><p>修改 xml 里面的配置，包括 yarn-site、hdfs-site、core-site、mapred-site，后面会给出我的配置和详细的信息。</p><h2 id="显示不了中文字符"><a class="anchor" href="#显示不了中文字符">#</a> 显示不了中文字符</h2><p>在控制面板的时钟与区域 -&gt; 区域 -&gt; 管理 -&gt; 更改系统区域设置 -&gt; 选用 beta 版<br>重启电脑即可</p><h1 id="环境配置"><a class="anchor" href="#环境配置">#</a> 环境配置</h1><p>Hadoop 3.0.0<br>python 3.6.3<br>Java 1.8<br>maven 3.9.7<br>系统变量：<img data-src="1.png" alt=""></p><p>我的主机名是 LAPTOP-1A91HHJ4, 如果你要查看自己的主机名可在命令指示符中输入 'hostname'，即可得到主机名</p><h2 id="core-siteyml"><a class="anchor" href="#core-siteyml">#</a> core-site.yml</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line">  you may not use this file except in compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to in writing, software</span><br><span class="line">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License for the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h2 id="hdfs-siteyml"><a class="anchor" href="#hdfs-siteyml">#</a> hdfs-site.yml</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line">  you may not use this file except in compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to in writing, software</span><br><span class="line">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License for the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">       &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;file:///C:/Hadoop/data/namenode&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;file:///C:/Hadoop/data/datanode&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;LAPTOP-1A91HHJ4:9089&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.datanode.http.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;LAPTOP-1A91HHJ4:9088&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h2 id="yarn-site"><a class="anchor" href="#yarn-site">#</a> yarn-site</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line">  you may not use this file except in compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to in writing, software</span><br><span class="line">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License for the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    	&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">    	&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      	&lt;name&gt;yarn.nodemanager.auxservices.mapreduce.shuffle.class&lt;/name&gt;  </span><br><span class="line">	&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;LAPTOP-1A91HHJ4&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.bind-host&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;0.0.0.0&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;20480&lt;/value&gt; &lt;!-- 根据你的集群配置调整 --&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;2048&lt;/value&gt; &lt;!-- 根据你的集群配置调整 --&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;4&lt;/value&gt; &lt;!-- 根据你的集群配置调整 --&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;2.1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.scheduler.maximum-allocation-vcores&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;4&lt;/value&gt; &lt;!-- 根据你的集群配置调整 --&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;LAPTOP-1A91HHJ4:8032&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;LAPTOP-1A91HHJ4:8030&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;LAPTOP-1A91HHJ4:8031&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;LAPTOP-1A91HHJ4:8033&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;LAPTOP-1A91HHJ4:8088&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h2 id="mapred-site"><a class="anchor" href="#mapred-site">#</a> mapred-site</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line">  you may not use this file except in compliance with the License.</span><br><span class="line">  You may obtain a copy of the License at</span><br><span class="line"></span><br><span class="line">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="line"></span><br><span class="line">  Unless required by applicable law or agreed to in writing, software</span><br><span class="line">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line">  See the License for the specific language governing permissions and</span><br><span class="line">  limitations under the License. See accompanying LICENSE file.</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!--</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;--&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">      &lt;name&gt;mapreduce.job.tracker&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;hdfs://LAPTOP-1A91HHJ4:8001&lt;/value&gt;</span><br><span class="line">      &lt;final&gt;true&lt;/final&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;LAPTOP-1A91HHJ4:10020&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;LAPTOP-1A91HHJ4:19888&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>由于我走了很多的弯路，可能这上面的配置多了很多不必要的东西，但一定是可以跑通的。</p><p>如果遇到了类似端口占用的报错请直接删除它，例如报错：Port in use:0.0.0.0:8042, 首先检查占用端口的进程：<br>'netstat -ano | findstr :8042'<br>找到他的进程 ID，输入指令:'taskill /PID yourIdNum /F' 即可</p><h1 id="问题重述"><a class="anchor" href="#问题重述">#</a> 问题重述</h1><p>一 实验目的<br>1. 学习基于 MapReduce 框架的分布式计算程序设计方法。<br>2. 学习基于 Spark 框架的分布式计算程序设计方法。<br>二 实验题目<br>题目 1<br>输入文件为学生成绩信息，包含了必修课与选修课成绩，格式如下：<br>班级 1, 姓名 1, 科目 1, 必修，成绩 1 <code>&lt;br&gt;</code> （注： <code>&lt;br&gt;</code> 为换行符）<br>班级 2, 姓名 2, 科目 1, 必修，成绩 2 <code>&lt;br&gt;</code><br>班级 1, 姓名 1, 科目 2, 选修，成绩 3 <code>&lt;br&gt;</code><br>………., ………, ………, ……… <code>&lt;br&gt;</code></p><p>编写两个 Hadoop 平台上的 MapReduce 程序，分别实现如下功能：<br>1. 计算每个学生必修课的平均成绩。<br>2. 按科目统计每个班的平均成绩。<br>题目 2<br>输入文件的每一行为具有父子 / 父女 / 母子 / 母女 / 关系的一对人名，例如：<br>Tim, Andy <code>&lt;br&gt;</code><br>Harry, Alice <code>&lt;br&gt;</code><br>Mark, Louis <code>&lt;br&gt;</code><br>Andy, Joseph <code>&lt;br&gt;</code><br>……….., ………… <code>&lt;br&gt;</code><br>假定不会出现重名现象。<br>编写 Hadoop 平台上的 MapReduce 程序，找出所有具有 grandchild-grandparent 关系的人名组。<br>题目 3<br>输入文件为学生成绩信息，包含了必修课与选修课成绩，格式如下：<br>班级 1, 姓名 1, 科目 1, 必修，成绩 1 <code>&lt;br&gt;</code> （注： <code>&lt;br&gt;</code> 为换行符）<br>班级 2, 姓名 2, 科目 1, 必修，成绩 2 <code>&lt;br&gt;</code><br>班级 1, 姓名 1, 科目 2, 选修，成绩 3 <code>&lt;br&gt;</code><br>………., ………, ………, ……… <code>&lt;br&gt;</code><br>编写一个 Spark 程序，同时实现如下功能：</p><ol><li>计算每个学生必修课的平均成绩。</li><li>统计学生必修课平均成绩在：'90<sub>100,80</sub>89,70<sub>79,60</sub>69 和 60 分以下 ' 这 5 个分数段的人数。</li></ol><h1 id="具体实现"><a class="anchor" href="#具体实现">#</a> 具体实现</h1><h2 id="题目1"><a class="anchor" href="#题目1">#</a> 题目 1</h2><h3 id="问题1"><a class="anchor" href="#问题1">#</a> 问题 1</h3><h4 id="配置pom"><a class="anchor" href="#配置pom">#</a> 配置 pom</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;</span><br><span class="line">         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span><br><span class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line"></span><br><span class="line">    &lt;groupId&gt;com.ls&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;StuAvg&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;3.3.3&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line"></span><br><span class="line">    &lt;properties&gt;</span><br><span class="line">        &lt;maven.compiler.source&gt;22&lt;/maven.compiler.source&gt;</span><br><span class="line">        &lt;maven.compiler.target&gt;22&lt;/maven.compiler.target&gt;</span><br><span class="line">        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;</span><br><span class="line">    &lt;/properties&gt;</span><br><span class="line"></span><br><span class="line">    &lt;build&gt;</span><br><span class="line">        &lt;finalName&gt;StuAvg&lt;/finalName&gt;</span><br><span class="line">    &lt;/build&gt;</span><br><span class="line"></span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure><p>剩下的配置文件与之类似，不再赘述</p><h4 id="代码"><a class="anchor" href="#代码">#</a> 代码</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">package com.ls;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.io.DoubleWritable;</span><br><span class="line">import org.apache.hadoop.io.LongWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.Job;</span><br><span class="line">import org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line">import org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">public class StuAvg &#123;</span><br><span class="line"></span><br><span class="line">    public static class StuMap extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt; &#123;</span><br><span class="line">        @Override</span><br><span class="line">        protected void map (LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            String line = value.toString();</span><br><span class="line">            String[] field = line.split(&quot;,&quot;);</span><br><span class="line">            if ( field.length == 5 &amp;&amp; field[3].equals(&quot;必修&quot;)) &#123;</span><br><span class="line">                String Name = field[1] ;</span><br><span class="line">                long score = Long.parseLong(field[4]);</span><br><span class="line">                context.write(new Text(Name), new LongWritable(score));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class StuReduce extends Reducer&lt;Text, LongWritable, Text, DoubleWritable&gt; &#123;</span><br><span class="line">        @Override</span><br><span class="line">        protected void reduce(Text key, Iterable&lt;LongWritable&gt; values, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            long sum = 0;</span><br><span class="line">            int count = 0;</span><br><span class="line"></span><br><span class="line">            for (LongWritable val : values) &#123;</span><br><span class="line">                sum += val.get();</span><br><span class="line">                count++;</span><br><span class="line">            &#125;</span><br><span class="line">            if (count &gt; 0) &#123;</span><br><span class="line">                double average = (double) sum / (double) count;</span><br><span class="line">                context.write(key, new DoubleWritable(average));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        Configuration conf = new Configuration();</span><br><span class="line">        Job job = Job.getInstance(conf);</span><br><span class="line">        job.setJarByClass(StuMap.class);</span><br><span class="line">        job.setMapperClass(StuMap.class);</span><br><span class="line">        job.setReducerClass(StuReduce.class);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(LongWritable.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(DoubleWritable.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, new Path(args[0]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(args[1]));</span><br><span class="line"></span><br><span class="line">        System.exit(job.waitForCompletion(true) ? 0 : 1);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="问题2"><a class="anchor" href="#问题2">#</a> 问题 2</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">package com.ls;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.io.DoubleWritable;</span><br><span class="line">import org.apache.hadoop.io.LongWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.Job;</span><br><span class="line">import org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line">import org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">public class ClassAvg &#123;</span><br><span class="line"></span><br><span class="line">    public static class Map extends Mapper&lt;LongWritable, Text, Text, LongWritable&gt; &#123;</span><br><span class="line">        @Override</span><br><span class="line">        protected void map (LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            String line = value.toString();</span><br><span class="line">            String[] field = line.split(&quot;,&quot;);</span><br><span class="line">            if ( field.length == 5 ) &#123;</span><br><span class="line">                String Name = field[0]+&quot;_&quot;+field[2] ;</span><br><span class="line">                long score = Long.parseLong(field[4]);</span><br><span class="line">                context.write(new Text(Name), new LongWritable(score));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class Reduce extends Reducer&lt;Text, LongWritable, Text, DoubleWritable&gt; &#123;</span><br><span class="line">        @Override</span><br><span class="line">        protected void reduce(Text key, Iterable&lt;LongWritable&gt; values, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            long sum = 0;</span><br><span class="line">            int count = 0;</span><br><span class="line"></span><br><span class="line">            for (LongWritable val : values) &#123;</span><br><span class="line">                sum += val.get();</span><br><span class="line">                count++ ;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            double average = (double) sum / (double) count;</span><br><span class="line">            context.write(key, new DoubleWritable(average));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        Configuration conf = new Configuration();</span><br><span class="line">        Job job = Job.getInstance(conf);</span><br><span class="line">        job.setJarByClass(Map.class);</span><br><span class="line">        job.setMapperClass(Map.class);</span><br><span class="line">        job.setReducerClass(Reduce.class);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(LongWritable.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(DoubleWritable.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, new Path(args[0]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(args[1]));</span><br><span class="line"></span><br><span class="line">        System.exit(job.waitForCompletion(true) ? 0 : 1);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="题目2"><a class="anchor" href="#题目2">#</a> 题目 2</h2><h3 id="代码-2"><a class="anchor" href="#代码-2">#</a> 代码</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">package com.ls;</span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.io.DoubleWritable;</span><br><span class="line">import org.apache.hadoop.io.LongWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.Job;</span><br><span class="line">import org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line">import org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">public class GrandPC &#123;</span><br><span class="line">    public static class Map extends Mapper&lt;LongWritable, Text, Text, Text&gt; &#123;</span><br><span class="line">        @Override</span><br><span class="line">        protected void map (LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            String line = value.toString();</span><br><span class="line">            String[] names = line.split(&quot;,&quot;);</span><br><span class="line">            String child = names[0].trim()+&quot;_child&quot;;</span><br><span class="line">            String grand = names[1].trim()+&quot;_parent&quot;;</span><br><span class="line">            context.write(new Text(names[0].trim()), new Text(grand));</span><br><span class="line">            context.write(new Text(names[1].trim()), new Text(child));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static class Reduce extends Reducer&lt;Text, Text, Text, Text&gt; &#123;</span><br><span class="line">        @Override</span><br><span class="line">        protected void reduce (Text key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">            String grand = key.toString();</span><br><span class="line">            ArrayList&lt;String&gt; parents = new ArrayList&lt;&gt;() ;</span><br><span class="line">            ArrayList&lt;String&gt; children = new ArrayList&lt;&gt;() ;</span><br><span class="line">            for (Text value : values) &#123;</span><br><span class="line">                String node = value.toString();</span><br><span class="line">                String [] name = node.split(&quot;_&quot;) ;</span><br><span class="line">                if ( name[1].equals(&quot;child&quot;) ) &#123;</span><br><span class="line">                    children.add(name[0].trim());</span><br><span class="line">                &#125;</span><br><span class="line">                else if ( name[1].equals(&quot;parent&quot;) ) &#123;</span><br><span class="line">                    parents.add(name[0].trim());</span><br><span class="line">                &#125;</span><br><span class="line">                else &#123;</span><br><span class="line">                    continue ;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            for (String child : children) &#123;</span><br><span class="line">                for (String parent : parents) &#123;</span><br><span class="line">                    context.write(new Text(child), new Text(parent));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        Configuration conf = new Configuration();</span><br><span class="line">        Job job = Job.getInstance(conf);</span><br><span class="line">        job.setJarByClass(Map.class);</span><br><span class="line">        job.setMapperClass(Map.class);</span><br><span class="line">        job.setReducerClass(Reduce.class);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(Text.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">        FileInputFormat.setInputPaths(job, new Path(args[0]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(args[1]));</span><br><span class="line"></span><br><span class="line">        System.exit(job.waitForCompletion(true) ? 0 : 1);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="思路"><a class="anchor" href="#思路">#</a> 思路</h3><p>思路是输入的数据例如 child,parent，我们将它变为两组输出，一组为 child,parentParent, 一组为 parent,childChild。在 map 阶段，若对于同一 KEY 有多个值，我们将值划分为 Parent 组和 Child 组一一匹配作为祖先 - 孩子组输出。</p><h2 id="题目3"><a class="anchor" href="#题目3">#</a> 题目 3</h2><h3 id="代码-3"><a class="anchor" href="#代码-3">#</a> 代码</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># -*- coding: gb18030 -*-</span><br><span class="line"></span><br><span class="line">from pyspark import SparkConf, SparkContext</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">conf = SparkConf().setMaster(&quot;local&quot;).setAppName(&quot;gradecount&quot;)</span><br><span class="line">sc = SparkContext(conf = conf)</span><br><span class="line">grades = sc.textFile(&quot;/spark/grades.txt&quot;)</span><br><span class="line"> </span><br><span class="line">def f(x):</span><br><span class="line">    if(x &gt;= 90 and x &lt;= 100):</span><br><span class="line">        return (&quot;90-100&quot;)</span><br><span class="line">    if(x &gt;= 80 and x &lt; 90):</span><br><span class="line">        return (&quot;80-89&quot;) </span><br><span class="line">    if(x &gt;= 70 and x &lt; 80):</span><br><span class="line">        return (&quot;70-79&quot;) </span><br><span class="line">    if(x &gt;= 60 and x &lt; 70):</span><br><span class="line">        return (&quot;60-69&quot;) </span><br><span class="line">    if(x &lt; 60):</span><br><span class="line">        return (&quot;0-59&quot;) </span><br><span class="line">grades = grades.filter(lambda line: &quot;必修&quot; in line)</span><br><span class="line"></span><br><span class="line">name_grade_pairs = grades.map(lambda line: (line.split(&quot;,&quot;)[1], (int(line.split(&quot;,&quot;)[4]), 1)))</span><br><span class="line"># name_grade_pairs.saveAsTextFile(&quot;name_grade_pairs&quot;)</span><br><span class="line"></span><br><span class="line">avg_grades = name_grade_pairs.reduceByKey(lambda x1, x2: (x1[0] + x2[0], x1[1] + x2[1])).mapValues(lambda x: int(x[0] / x[1])).sortBy(lambda x: x[1], ascending=True)</span><br><span class="line">avg_grades.saveAsTextFile(&quot;/avg_grades&quot;)</span><br><span class="line"></span><br><span class="line">interval_grades = avg_grades.map(lambda x: (f(x[1]), 1))</span><br><span class="line">interval_stu_nums = interval_grades.reduceByKey(lambda x, y: (x + y)).sortByKey()</span><br><span class="line">interval_stu_nums.saveAsTextFile(&quot;/interval_stu_nums&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="具体指令"><a class="anchor" href="#具体指令">#</a> 具体指令</h1><h2 id="打开hadoop"><a class="anchor" href="#打开hadoop">#</a> 打开 hadoop</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-all</span><br></pre></td></tr></table></figure><h2 id="stuavg"><a class="anchor" href="#stuavg">#</a> StuAvg</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mvn clean</span><br><span class="line">mvn package</span><br><span class="line"></span><br><span class="line">hadoop fs -mkdir /StuAvg</span><br><span class="line">hadoop fs -put grades.txt /StuAvg</span><br><span class="line">hadoop jar ./target/StuAvg.jar com.ls.StuAvg /StuAvg/grades.txt /output1</span><br><span class="line"></span><br><span class="line">hadoop fs -ls /output1</span><br><span class="line">hadoop fs -cat /output1/part-r-00000</span><br><span class="line">hadoop fs -rm -r /output1</span><br></pre></td></tr></table></figure><h2 id="classavg"><a class="anchor" href="#classavg">#</a> ClassAvg</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mvn clean</span><br><span class="line">mvn package</span><br><span class="line"></span><br><span class="line">hadoop fs -mkdir /ClassAvg</span><br><span class="line">hadoop fs -put grades.txt /ClassAvg</span><br><span class="line">hadoop jar ./target/ClassAvg.jar com.ls.ClassAvg /ClassAvg/grades.txt /output2</span><br><span class="line"></span><br><span class="line">hadoop fs -ls /output2</span><br><span class="line">hadoop fs -cat /output2/part-r-00000</span><br><span class="line">hadoop fs -rm -r /output2</span><br></pre></td></tr></table></figure><h2 id="grandpc"><a class="anchor" href="#grandpc">#</a> GrandPC</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mvn clean</span><br><span class="line">mvn package</span><br><span class="line"></span><br><span class="line">hadoop fs -mkdir /GrandPC</span><br><span class="line">hadoop fs -put child-parent.txt /GrandPC</span><br><span class="line">hadoop jar ./target/GrandPC.jar com.ls.GrandPC /GrandPC/child-parent.txt /output3</span><br><span class="line"></span><br><span class="line">hadoop fs -ls /output3</span><br><span class="line">hadoop fs -cat /output3/part-r-00000</span><br><span class="line">hadoop fs -rm -r /output3</span><br></pre></td></tr></table></figure><h2 id="spark"><a class="anchor" href="#spark">#</a> Spark</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">start-dfs </span><br><span class="line"></span><br><span class="line">hadoop fs -mkdir /spark</span><br><span class="line">hadoop fs -put C:\Users\11523\Desktop\Spark\grades.txt /spark</span><br><span class="line"></span><br><span class="line">pyspark</span><br><span class="line"></span><br><span class="line">spark-submit Spark.py</span><br><span class="line"></span><br><span class="line">hadoop fs -cat /interval_stu_nums/part-00000</span><br><span class="line">hadoop fs -cat /avg_grades/part-00000</span><br></pre></td></tr></table></figure><h1 id="实际效果"><a class="anchor" href="#实际效果">#</a> 实际效果</h1><h2 id="stuavg-2"><a class="anchor" href="#stuavg-2">#</a> StuAvg</h2><p><img data-src="2.png" alt=""></p><h2 id="classavg-2"><a class="anchor" href="#classavg-2">#</a> ClassAvg</h2><p><img data-src="3.png" alt=""></p><h2 id="grandpc-2"><a class="anchor" href="#grandpc-2">#</a> GrandPC</h2><p><img data-src="4.png" alt=""></p><h2 id="spark-2"><a class="anchor" href="#spark-2">#</a> Spark</h2><p><img data-src="5.png" alt=""><br><img data-src="6.png" alt=""></p><div class="tags"><a href="/tags/%E4%BB%A3%E7%A0%81/" rel="tag"><i class="ic i-tag"></i> 代码</a> <a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" rel="tag"><i class="ic i-tag"></i> 分布式</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2025-04-30 11:20:12" itemprop="dateModified" datetime="2025-04-30T11:20:12+08:00">2025-04-30</time> </span><span id="code/分布式大作业/" class="item leancloud_visitors" data-flag-title="分布式大作业" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>Lemon Sour <i class="ic i-at"><em>@</em></i></li><li class="link"><strong>本文链接：</strong> <a href="http://amentiraz.github.io/code/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%A7%E4%BD%9C%E4%B8%9A/" title="分布式大作业">http://amentiraz.github.io/code/分布式大作业/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC96aC1DTg=="><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/life/%E6%88%96%E8%AE%B8%E6%88%91%E4%BB%AC%E6%B0%B8%E8%BF%9C%E6%97%A0%E6%B3%95%E8%8E%B7%E5%BE%97%E5%B9%B3%E9%9D%99/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;amentirazblogpic.oss-cn-hangzhou.aliyuncs.com&#x2F;blogpic&#x2F;%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925124341.png" title="或许我们永远无法获得平静"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 思考</span><h3>或许我们永远无法获得平静</h3></a></div><div class="item right"><a href="/life/%E5%AF%B9LGBT%E7%9A%84%E6%80%9D%E8%80%83/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;amentirazblogpic.oss-cn-hangzhou.aliyuncs.com&#x2F;blogpic&#x2F;%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240925124403.png" title="对LGBT的思考"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 思考</span><h3>对LGBT的思考</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">1.</span> <span class="toc-text">环境配置遇到的问题及解决方案</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%A0%E6%B3%95%E8%A7%A3%E5%8E%8Btargz%E6%96%87%E4%BB%B6"><span class="toc-number">1.1.</span> <span class="toc-text">无法解压 tar.gz 文件？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#nodemanager%E5%90%AF%E5%8A%A8%E6%97%B6%E9%81%87%E5%88%B0%E9%94%99%E8%AF%AF"><span class="toc-number">1.2.</span> <span class="toc-text">NodeManager 启动时遇到错误</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pyspark%E6%8C%87%E4%BB%A4%E6%8A%A5%E9%94%99"><span class="toc-number">1.3.</span> <span class="toc-text">pyspark 指令报错</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%A1%E5%9C%A8running-job%E5%90%8E%E4%B8%8D%E5%8A%A8%E4%BA%86"><span class="toc-number">1.4.</span> <span class="toc-text">卡在 running job 后不动了</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%98%BE%E7%A4%BA%E4%B8%8D%E4%BA%86%E4%B8%AD%E6%96%87%E5%AD%97%E7%AC%A6"><span class="toc-number">1.5.</span> <span class="toc-text">显示不了中文字符</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="toc-number">2.</span> <span class="toc-text">环境配置</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#core-siteyml"><span class="toc-number">2.1.</span> <span class="toc-text">core-site.yml</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hdfs-siteyml"><span class="toc-number">2.2.</span> <span class="toc-text">hdfs-site.yml</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#yarn-site"><span class="toc-number">2.3.</span> <span class="toc-text">yarn-site</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mapred-site"><span class="toc-number">2.4.</span> <span class="toc-text">mapred-site</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E9%87%8D%E8%BF%B0"><span class="toc-number">3.</span> <span class="toc-text">问题重述</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.</span> <span class="toc-text">具体实现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%98%E7%9B%AE1"><span class="toc-number">4.1.</span> <span class="toc-text">题目 1</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%981"><span class="toc-number">4.1.1.</span> <span class="toc-text">问题 1</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEpom"><span class="toc-number">4.1.1.1.</span> <span class="toc-text">配置 pom</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81"><span class="toc-number">4.1.1.2.</span> <span class="toc-text">代码</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%982"><span class="toc-number">4.1.2.</span> <span class="toc-text">问题 2</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%98%E7%9B%AE2"><span class="toc-number">4.2.</span> <span class="toc-text">题目 2</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81-2"><span class="toc-number">4.2.1.</span> <span class="toc-text">代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%B7%AF"><span class="toc-number">4.2.2.</span> <span class="toc-text">思路</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%98%E7%9B%AE3"><span class="toc-number">4.3.</span> <span class="toc-text">题目 3</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81-3"><span class="toc-number">4.3.1.</span> <span class="toc-text">代码</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E6%8C%87%E4%BB%A4"><span class="toc-number">5.</span> <span class="toc-text">具体指令</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%93%E5%BC%80hadoop"><span class="toc-number">5.1.</span> <span class="toc-text">打开 hadoop</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#stuavg"><span class="toc-number">5.2.</span> <span class="toc-text">StuAvg</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#classavg"><span class="toc-number">5.3.</span> <span class="toc-text">ClassAvg</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#grandpc"><span class="toc-number">5.4.</span> <span class="toc-text">GrandPC</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#spark"><span class="toc-number">5.5.</span> <span class="toc-text">Spark</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%99%85%E6%95%88%E6%9E%9C"><span class="toc-number">6.</span> <span class="toc-text">实际效果</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#stuavg-2"><span class="toc-number">6.1.</span> <span class="toc-text">StuAvg</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#classavg-2"><span class="toc-number">6.2.</span> <span class="toc-text">ClassAvg</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#grandpc-2"><span class="toc-number">6.3.</span> <span class="toc-text">GrandPC</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#spark-2"><span class="toc-number">6.4.</span> <span class="toc-text">Spark</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/code/%E5%B1%82%E6%AC%A1%E5%88%86%E6%9E%90%E6%B3%95/" rel="bookmark" title="层次分析法">层次分析法</a></li><li><a href="/code/TOPSIS%E6%B3%95/" rel="bookmark" title="TOPSIS法">TOPSIS法</a></li><li><a href="/code/TOPSIS-MATLAB/" rel="bookmark" title="TOPSIS-MATLAB">TOPSIS-MATLAB</a></li><li><a href="/code/%E6%8F%92%E5%80%BC%E7%AE%97%E6%B3%95/" rel="bookmark" title="插值算法">插值算法</a></li><li><a href="/code/%E5%88%86%E5%B8%83%E5%BC%8FMOM%E4%BD%9C%E4%B8%9A/" rel="bookmark" title="分布式MOM作业">分布式MOM作业</a></li><li class="active"><a href="/code/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%A7%E4%BD%9C%E4%B8%9A/" rel="bookmark" title="分布式大作业">分布式大作业</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Lemon Sour" data-src="/images/avatar.jpg"><p class="name" itemprop="name">Lemon Sour</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">93</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">26</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">57</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL0FtZW50aXJheg==" title="https:&#x2F;&#x2F;github.com&#x2F;Amentiraz"><i class="ic i-github"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9kc2ZseS04" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;dsfly-8"><i class="ic i-zhihu"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTE1MTc2ODUzMzM=" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;1517685333"><i class="ic i-cloud-music"></i></span> <span class="exturl item email" data-url="bWFpbHRvOnZpb2xlbW9uQDE2My5jb20=" title="mailto:violemon@163.com"><i class="ic i-envelope"></i></span> <span class="exturl item bangumi" data-url="aHR0cHM6Ly9iYW5ndW1pLnR2L2FuaW1lL2xpc3QvNjY4MDE2" title="https:&#x2F;&#x2F;bangumi.tv&#x2F;anime&#x2F;list&#x2F;668016"><i class="ic i-bilibili"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-magic"></i>关于</a><ul class="submenu"><li class="item"><a href="/author/" rel="section"><i class="ic i-user"></i>本人</a></li></ul></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-cloud"></i>其它</a><ul class="submenu"><li class="item"><a href="/music/" rel="section"><i class="ic i-music"></i>音乐区</a></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>朋友</a></li></ul></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/life/%E6%88%96%E8%AE%B8%E6%88%91%E4%BB%AC%E6%B0%B8%E8%BF%9C%E6%97%A0%E6%B3%95%E8%8E%B7%E5%BE%97%E5%B9%B3%E9%9D%99/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/life/%E5%AF%B9LGBT%E7%9A%84%E6%80%9D%E8%80%83/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/article/" title="分类于 论文">论文</a></div><span><a href="/article/Matching-Anything-by-Segmenting-Anything/" title="Matching_Anything_by_Segmenting_Anything">Matching_Anything_by_Segmenting_Anything</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/article/" title="分类于 论文">论文</a> <i class="ic i-angle-right"></i> <a href="/categories/article/data/" title="分类于 data">data</a></div><span><a href="/article/%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%B0%E5%BD%95/" title="数据集记录">数据集记录</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/other/" title="分类于 其它">其它</a> <i class="ic i-angle-right"></i> <a href="/categories/other/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93/" title="分类于 工作总结">工作总结</a></div><span><a href="/code-report-2025y9m19d/" title="code_report_2025y9m19d">code_report_2025y9m19d</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/life/" title="分类于 生活">生活</a> <i class="ic i-angle-right"></i> <a href="/categories/life/%E6%BC%94%E5%A5%8F%E4%BC%9A/" title="分类于 演奏会">演奏会</a></div><span><a href="/life/MeetingJazz2025-06-01/" title="MeetingJazz2025-06-01">MeetingJazz2025-06-01</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/note/" title="分类于 影视书籍">影视书籍</a> <i class="ic i-angle-right"></i> <a href="/categories/note/%E5%8A%A8%E6%BC%AB/" title="分类于 动漫">动漫</a></div><span><a href="/note/%E8%93%9D%E8%89%B2%E6%81%90%E6%83%A7-%E8%A7%82%E5%90%8E%E6%84%9F/" title="《蓝色恐惧》观后感">《蓝色恐惧》观后感</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/life/" title="分类于 生活">生活</a> <i class="ic i-angle-right"></i> <a href="/categories/life/%E6%BC%94%E5%A5%8F%E4%BC%9A/" title="分类于 演奏会">演奏会</a></div><span><a href="/kanekoayano/" title="kanekoayano">kanekoayano</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/code/%E4%BF%9D%E7%A0%94%E5%A4%8D%E8%AF%95%E5%A4%8D%E4%B9%A0%E6%80%BB%E6%8B%AC/" title="保研复试复习总括">保研复试复习总括</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/life/" title="分类于 生活">生活</a> <i class="ic i-angle-right"></i> <a href="/categories/life/%E6%BC%94%E5%A5%8F%E4%BC%9A/" title="分类于 演奏会">演奏会</a></div><span><a href="/life/%E8%A7%82%E9%83%91%E6%99%9F%E6%B2%B3%E6%BC%94%E5%A5%8F%E4%BC%9A%E6%9C%89%E6%84%9F/" title="观郑晟河演奏会有感">观郑晟河演奏会有感</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/article/" title="分类于 论文">论文</a></div><span><a href="/article/Benchmarking-spatial-claustering-methods-with-spatially-resolved-transcriptomic-data/" title="Benchmarking-spatial-claustering-methods-with-spatially-resolved-transcriptomic-data">Benchmarking-spatial-claustering-methods-with-spatially-resolved-transcriptomic-data</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/life/" title="分类于 生活">生活</a> <i class="ic i-angle-right"></i> <a href="/categories/life/%E4%BC%BC%E6%B0%B4%E6%B5%81%E5%B9%B4/" title="分类于 似水流年">似水流年</a></div><span><a href="/life/%E4%BD%A0%E6%80%BB%E8%83%BD%E6%AF%81%E7%81%AD%E4%B8%80%E5%88%87/" title="你总能毁灭一切">你总能毁灭一切</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2010 – <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Lemon Sour @ Amentiraz</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"code/分布式大作业/",favicon:{show:"⁽⁽ଘ( ˊᵕˋ )ଓ⁾⁾",hide:"(つд⊂)"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->